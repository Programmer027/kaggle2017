{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This was the best 'serious' submission I did, and would have gotten #29 if I had picked it..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed medians\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2133\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2134\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2135\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4433)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4279)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/src/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:13742)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/src/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:13696)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Dtechnical_30'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mset\u001b[0;34m(self, item, value, check)\u001b[0m\n\u001b[1;32m   3667\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3668\u001b[0;31m             \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3669\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2135\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2136\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4433)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4279)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/src/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:13742)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/src/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:13696)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Dtechnical_30'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-323ae8ae05e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallinput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m \u001b[0myptrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataPrep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeepinput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbacky_fset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;31m#yptrain_prep = tmp.run(yptrain)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-323ae8ae05e6>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, df)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'timestamp'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocday\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallinput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-323ae8ae05e6>\u001b[0m in \u001b[0;36mprocday\u001b[0;34m(self, day_in)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'D'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m                 \u001b[0mday\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mday\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mday\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_prev'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprevinput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mday_in\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeepcols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   2417\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2418\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2419\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2421\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   2484\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2485\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2486\u001b[0;31m         \u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2488\u001b[0m         \u001b[0;31m# check if we are modifying a copy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   1498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1499\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1500\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1501\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mset\u001b[0;34m(self, item, value, check)\u001b[0m\n\u001b[1;32m   3669\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3670\u001b[0m             \u001b[0;31m# This item wasn't present, just insert at end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3671\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3672\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3673\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36minsert\u001b[0;34m(self, loc, item, value, allow_duplicates)\u001b[0m\n\u001b[1;32m   3767\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3768\u001b[0m         \u001b[0;31m# insert to the axis; this could possibly raise a TypeError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3769\u001b[0;31m         \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3770\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3771\u001b[0m         block = make_block(values=value, ndim=self.ndim,\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/indexes/base.py\u001b[0m in \u001b[0;36minsert\u001b[0;34m(self, loc, item)\u001b[0m\n\u001b[1;32m   3238\u001b[0m         \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_coerce_scalar_to_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3239\u001b[0m         \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_self\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_self\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3240\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shallow_copy_with_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3242\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'raise'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/indexes/base.py\u001b[0m in \u001b[0;36m_shallow_copy_with_infer\u001b[0;34m(self, values, **kwargs)\u001b[0m\n\u001b[1;32m    400\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mattributes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_deepcopy_if_needed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/indexes/base.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, data, dtype, copy, name, fastpath, tupleize_cols, **kwargs)\u001b[0m\n\u001b[1;32m    245\u001b[0m                 \u001b[0msubarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'object'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m                 \u001b[0msubarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_asarray_tuplesafe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m             \u001b[0;31m# _asarray_tuplesafe does not always copy underlying data,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/common.py\u001b[0m in \u001b[0;36m_asarray_tuplesafe\u001b[0;34m(values, dtype)\u001b[0m\n\u001b[1;32m    371\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 373\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobject_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    374\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_to_object_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import kagglegym\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "import xgboost as xgb\n",
    "import math\n",
    "\n",
    "import time\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "from operator import itemgetter\n",
    "\n",
    "# train/public split, use for \n",
    "config_local = {'localrun': True, 'usepublic': True, 'vmode': False, 'all_features': False}\n",
    "\n",
    "# validation mode (random non-stratified 80/20 split)\n",
    "# in *some* versions vmode will auto-stop, others will need xgbcap\n",
    "config_vmode = {'localrun': True, 'usepublic': False, 'vmode': True, 'all_features': False}\n",
    "\n",
    "# just before submission run\n",
    "config_presubmit = {'localrun': True, 'usepublic': True, 'vmode': False, 'all_features': False}\n",
    "\n",
    "# submission run\n",
    "config_submit = {'localrun': False, 'usepublic': False, 'vmode': False, 'all_features': False}\n",
    "\n",
    "config = config_presubmit\n",
    "xgbcap = 200 # reduce after a t/p run for vmode/LB runs\n",
    "\n",
    "# I used individual variables earlier, fix later? ;)\n",
    "localrun = config['localrun']\n",
    "usepublic = config['usepublic']\n",
    "vmode = config['vmode']\n",
    "all_features = config['all_features'] # use w/vmode for feature selection.  run twice, cutting # of rounds to peak round\n",
    "\n",
    "# This is taken from Frans Slothoubers post on the contest discussion forum.\n",
    "# https://www.kaggle.com/slothouber/two-sigma-financial-modeling/kagglegym-emulation\n",
    "\n",
    "def r_score(y_true, y_pred, sample_weight=None, multioutput=None):\n",
    "    r2 = r2_score(y_true, y_pred, sample_weight=sample_weight,\n",
    "                  multioutput=multioutput)\n",
    "    r = (np.sign(r2)*np.sqrt(np.abs(r2)))\n",
    "    if r <= -1:\n",
    "        return -1\n",
    "    else:\n",
    "        return r\n",
    "\n",
    "# From the xgboost script (along with the param settings)\n",
    "    \n",
    "# Function XGBOOST ########################################################\n",
    "def xgb_obj_custom_r(y_pred, dtrain):\n",
    "    y_true = dtrain.get_label()\n",
    "    y_mean = np.mean(y_true)\n",
    "    y_median = np.median(y_true)\n",
    "    c1 = y_true\n",
    "    #c1 = y_true - y_mean\n",
    "    #c1 = y_true - y_median\n",
    "    grad = 2*(y_pred-y_true)/(c1**2)\n",
    "    hess = 2/(c1**2)\n",
    "    return grad, hess\n",
    "\n",
    "def xgb_eval_custom_r(y_pred, dtrain):\n",
    "    #y_pred = np.clip(y_pred, -0.075, .075)\n",
    "#    y_pred[y_pred > .075] = .075\n",
    "#    y_pred[y_pred < -.075] = -.075\n",
    "    y_true = dtrain.get_label()\n",
    "    ybar = np.sum(y_true)/len(y_true)\n",
    "    ssres = np.sum((y_true - y_pred) ** 2)\n",
    "    sstot = np.sum((y_true - ybar)**2)\n",
    "    r2 = 1 - ssres/sstot\n",
    "    error = np.sign(r2) * np.absolute(r2)**0.5\n",
    "    return 'error', error\n",
    "\n",
    "env = kagglegym.make()\n",
    "o = env.reset()\n",
    "\n",
    "#excl = [env.ID_COL_NAME, env.SAMPLE_COL_NAME, env.TARGET_COL_NAME, env.TIME_COL_NAME]\n",
    "excl = ['id', 'sample', 'y', 'timestamp']\n",
    "basecols = [c for c in o.train.columns if c not in excl]\n",
    "\n",
    "\n",
    "#rcol_orig = ['Dtechnical_20', 'y_prev_pred_avg_diff', 'Dtechnical_21', 'technical_43_prev', 'technical_20', 'y_prev_pred_avgT0', 'y_prev_pred_mavg5', 'y_prev_pred_avgT1', 'fundamental_8_prev', 'Dtechnical_40', 'technical_7_prev', 'technical_7', 'fundamental_5', 'Dtechnical_30', 'technical_32_prev', 'technical_14_prev', 'fundamental_1', 'fundamental_43_prev', 'Dfundamental_22', 'Dtechnical_35', 'Dtechnical_6', 'Dtechnical_17', 'Dtechnical_27', 'Dfundamental_42', 'fundamental_1_prev', 'Dtechnical_0', 'technical_40', 'technical_40_prev', 'fundamental_36', 'Dfundamental_33', 'Dfundamental_48', 'technical_27_prev', 'fundamental_62_prev', 'fundamental_41_prev', 'Dfundamental_50', 'fundamental_48', 'derived_2_prev', 'Dtechnical_18', 'fundamental_35', 'Dfundamental_49', 'fundamental_26_prev', 'technical_28_prev', 'Dfundamental_63', 'fundamental_10_prev', 'fundamental_36_prev', 'fundamental_16', 'Dfundamental_8', 'fundamental_32', 'fundamental_40_prev', 'derived_0', 'Dfundamental_32', 'fundamental_17', 'Dtechnical_7', 'fundamental_25', 'technical_35', 'Dtechnical_19', 'technical_35_prev', 'fundamental_8', 'Dtechnical_32', 'Dfundamental_18', 'Dtechnical_37', 'fundamental_33_prev', 'Dtechnical_28', 'fundamental_46', 'Dfundamental_1', 'Dfundamental_45', 'fundamental_18', 'technical_12', 'technical_44', 'fundamental_22', 'Dtechnical_5', 'technical_17_prev', 'Dfundamental_25']\n",
    "rcol_orig = ['y_prev_pred', 'y_prev_pred_mstd5', 'Dtechnical_20', 'technical_43_prev', 'technical_7', 'y_prev_pred_avg_diff', 'y_prev_pred_avgT0', 'y_prev_pred_mavg5', 'technical_7_prev', 'technical_20', 'technical_40_prev', 'y_prev_pred_avgT1', 'Dtechnical_40', 'Dtechnical_30', 'technical_40', 'fundamental_36_prev', 'fundamental_5', 'fundamental_8_prev', 'technical_35', 'Dtechnical_21', 'fundamental_36', 'fundamental_43_prev', 'fundamental_46', 'fundamental_18', 'Dtechnical_35', 'Dtechnical_0', 'Dfundamental_45', 'fundamental_48', 'fundamental_1_prev', 'Dtechnical_27', 'Dfundamental_50', 'Dfundamental_18', 'fundamental_16', 'Dfundamental_48', 'Dtechnical_6', 'fundamental_40_prev', 'fundamental_26_prev', 'Dfundamental_8', 'Dtechnical_19', 'fundamental_25', 'fundamental_8', 'fundamental_10_prev', 'technical_35_prev', 'technical_14_prev', 'fundamental_1', 'Dtechnical_37', 'Dfundamental_49', 'Dtechnical_18', 'Dfundamental_42', 'fundamental_41_prev', 'fundamental_62_prev', 'technical_12', 'technical_17_prev', 'technical_27_prev', 'Dtechnical_17', 'derived_0', 'fundamental_33_prev', 'fundamental_32', 'fundamental_17', 'Dtechnical_32', 'technical_32_prev', 'Dfundamental_22', 'fundamental_22', 'fundamental_35', 'Dfundamental_32', 'Dtechnical_7', 'Dfundamental_1', 'technical_28_prev', 'Dtechnical_28', 'Dfundamental_25', 'Dfundamental_63', 'Dtechnical_5', 'technical_44', 'Dfundamental_33', 'derived_2_prev']\n",
    "rcol = rcol_orig.copy()\n",
    "\n",
    "if all_features:\n",
    "    rcol = []\n",
    "    for c in basecols:\n",
    "        rcol.append(c)\n",
    "        rcol.append(c + '_prev')\n",
    "        rcol.append('D' + c)\n",
    "        \n",
    "    rcol += ['y_prev_pred_avg_diff', 'y_prev_pred_avgT0', 'y_prev_pred_mavg5', 'y_prev_pred_avgT1']\n",
    "    rcol_orig = rcol.copy()\n",
    "\n",
    "backy_fset = ['technical_13', 'technical_20', 'technical_13_prev', 'technical_20_prev', 'technical_30_prev', 'technical_30']\n",
    "\n",
    "backy_fset = []\n",
    "for c in ['technical_13', 'technical_20', 'technical_30']:\n",
    "    backy_fset.append(c)\n",
    "    backy_fset.append(c + '_prev')\n",
    "    backy_fset.append('D' + c)\n",
    "\n",
    "#backy_fset =  ['technical_20', 'Dtechnical_20', 'technical_20_prev', 'Dtechnical_43', 'Dtechnical_7', 'technical_40', 'Dtechnical_40', 'technical_30', 'Dtechnical_30', 'technical_30_prev', 'Dfundamental_5', 'fundamental_8', 'Dfundamental_8', 'Dtechnical_35', 'technical_21', 'Dtechnical_21', 'technical_21_prev', 'Dfundamental_43', 'technical_0', 'Dtechnical_0', 'Dtechnical_27', 'Dfundamental_16', 'technical_6', 'Dtechnical_6', 'fundamental_40', 'Dfundamental_40', 'fundamental_40_prev', 'Dtechnical_19', 'Dtechnical_14', 'Dtechnical_37', 'technical_37_prev', 'Dfundamental_49', 'Dtechnical_18', 'Dfundamental_62', 'Dtechnical_12', 'technical_17', 'Dtechnical_17', 'technical_32', 'Dtechnical_32', 'technical_32_prev', 'Dfundamental_22', 'Dfundamental_35', 'technical_28', 'Dtechnical_28', 'technical_28_prev', 'fundamental_63', 'Dfundamental_63', 'technical_5', 'Dtechnical_5', 'technical_5_prev', 'technical_44', 'Dtechnical_44', 'technical_44_prev', 'technical_13', 'Dtechnical_13', 'technical_13_prev']\n",
    "for f in backy_fset:\n",
    "    if f not in rcol:\n",
    "        rcol.append(f)\n",
    "\n",
    "def get_basecols(rcol):\n",
    "    duse = {}\n",
    "\n",
    "    for r in rcol:\n",
    "        if 'y' in r:\n",
    "            continue\n",
    "\n",
    "        if 'D' in r:\n",
    "            duse[r[1:]] = True\n",
    "        elif '_prev' in r:\n",
    "            duse[r[:-5]] = True\n",
    "        elif r in basecols:\n",
    "            duse[r] = True\n",
    "\n",
    "    return [k for k in duse.keys()]\n",
    "\n",
    "basecols_touse = get_basecols(rcol)\n",
    "\n",
    "if vmode:\n",
    "    train = pd.read_hdf('../input/train.h5')\n",
    "else:\n",
    "    train = o.train.copy()\n",
    "\n",
    "d_mean = o.train[basecols_touse].median(axis=0)\n",
    "for c in basecols_touse:\n",
    "    d_mean[c + '_prev'] = d_mean[c]\n",
    "    d_mean['D' + c] = 0\n",
    "\n",
    "median = {t[0]:t[1] for t in zip(d_mean.index, d_mean.values)}\n",
    "median['y'] = 0\n",
    "\n",
    "print('processed medians')\n",
    "\n",
    "class DataPrep:\n",
    "    \n",
    "    def __init__(self, yprev_model = None, keepinput = True, cols = rcol, seed = 2017):\n",
    "        self.previnput = None\n",
    "        self.prevavg = 0\n",
    "        self.cols = cols.copy()\n",
    "        \n",
    "        self.basecols = get_basecols(self.cols)\n",
    "        self.keepcols = ['y', 'id', 'timestamp'] + self.basecols\n",
    "        \n",
    "        self.allinput = [] if keepinput else None\n",
    "        \n",
    "        self.dayavg = []\n",
    "        \n",
    "        self.yprev_model = yprev_model\n",
    "        \n",
    "        np.random.seed(seed)\n",
    "        self.random_state = np.random.get_state()\n",
    "        \n",
    "    def procday(self, day_in):\n",
    "        \n",
    "        if 'y' not in day_in and 'y' in self.keepcols:\n",
    "            self.keepcols.remove('y')\n",
    "        \n",
    "        day = day_in[self.keepcols].copy()\n",
    "        \n",
    "        notinnew = []\n",
    "        \n",
    "        if self.previnput is not None:\n",
    "            olen = len(day)\n",
    "            day = pd.merge(day, self.previnput, on='id', how = 'left', suffixes=['', '_prev'])\n",
    "            notinnew = self.previnput[~self.previnput.id.isin(day_in.id)].copy()\n",
    "            #print(day.iloc[0].timestamp, len(notinnew))\n",
    "        else:\n",
    "            for c in self.basecols:\n",
    "                day[c + '_prev'] = np.full_like(day[c], 0, dtype=np.float32)\n",
    "                #day[c + '_prev'] = np.zeros_like(day[c], dtype=np.float32)\n",
    "        \n",
    "        for c in self.cols:\n",
    "            if c == 'y_prev_pred':\n",
    "                continue\n",
    "\n",
    "            if c[0] == 'D':\n",
    "                day[c] = day[c[1:]] - day[c[1:] + '_prev']\n",
    "                \n",
    "        self.previnput = day_in[self.keepcols].copy()\n",
    "        if len(notinnew) > 0:\n",
    "            self.previnput = self.previnput.append(notinnew[self.keepcols])\n",
    "        \n",
    "        if self.yprev_model:\n",
    "            day['y_prev_pred'] = self.yprev_model.predict(day[backy_fset].fillna(d_mean).values.reshape(-1,len(backy_fset)))\n",
    "\n",
    "            avg = day.y_prev_pred.mean()\n",
    "\n",
    "            self.dayavg.append(avg)\n",
    "            day['y_prev_pred_mavg5'] = np.ma.average(np.array(self.dayavg[-5:]))#, weights=range(1, len(self.dayavg[-10:]) + 1))\n",
    "            day['y_prev_pred_min5'] = day.y_prev_pred - day.y_prev_pred_mavg5\n",
    "            day['y_prev_pred_mavg5d'] = avg - np.ma.average(np.array(self.dayavg[-5:]))\n",
    "            \n",
    "            day['y_prev_pred_mstd5'] = np.std(np.array(self.dayavg[-5:]))\n",
    "            \n",
    "            day['y_prev_pred_mavg9'] = np.ma.average(np.array(self.dayavg[-9:]))#, weights=range(1, len(self.dayavg[-10:]) + 1))\n",
    "            day['y_prev_pred_mavg20'] = np.ma.average(np.array(self.dayavg[-20:]))\n",
    "            day['y_prev_pred_mavg40'] = np.ma.average(np.array(self.dayavg[-40:]))\n",
    "            \n",
    "            day['y_prev_pred_avgT1'] = self.prevavg\n",
    "            day['y_prev_pred_avgT0'] = avg\n",
    "            day['y_prev_pred_avg_diff'] = avg - self.prevavg\n",
    "\n",
    "            self.prevavg = avg\n",
    "            \n",
    "        np.random.set_state(self.random_state)\n",
    "        day['random'] = np.random.random(len(day))\n",
    "        self.random_state = np.random.get_state()\n",
    "            \n",
    "        if self.allinput is not None:\n",
    "            self.allinput.append(day.copy())\n",
    "\n",
    "        return day\n",
    "    \n",
    "    def run(self, df):\n",
    "        assert self.allinput is not None\n",
    "        \n",
    "        for g in df.groupby('timestamp'):\n",
    "            self.procday(g[1])\n",
    "            \n",
    "        return pd.concat(self.allinput)\n",
    "\n",
    "yptrain = DataPrep(keepinput=True, cols=backy_fset).run(train)\n",
    "\n",
    "#yptrain_prep = tmp.run(yptrain)\n",
    "\n",
    "yptrain.sort_values(['id', 'timestamp'], inplace=True)\n",
    "\n",
    "ypmodel = LinearRegression(n_jobs=-1)\n",
    "low_y_cut = -0.0725\n",
    "high_y_cut = 0.075\n",
    "\n",
    "mask = np.logical_and(yptrain.y > low_y_cut, yptrain.y < high_y_cut)\n",
    "#for f in backy_fset:\n",
    "#    mask = np.logical_and(mask, ~yptrain[f].isnull())\n",
    "    \n",
    "yptraina = yptrain[mask]\n",
    "ypmodel.fit(yptraina[backy_fset].fillna(d_mean).values.reshape(-1,len(backy_fset)), yptraina.y_prev.fillna(0))\n",
    "\n",
    "print(len(yptraina), ypmodel.coef_, ypmodel.intercept_)\n",
    "\n",
    "preds = ypmodel.predict(yptrain[backy_fset].fillna(d_mean).values.reshape(-1,len(backy_fset)))\n",
    "print(r_score(yptrain.y_prev.fillna(0), preds))\n",
    "\n",
    "d_mean['y'] = 0\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "print('beginning train processing')\n",
    "train = DataPrep(keepinput = True, yprev_model = ypmodel).run(train)\n",
    "\n",
    "endt = time.time()\n",
    "print(endt - start)\n",
    "\n",
    "dcol = [c for c in train.columns if c not in excl]\n",
    "\n",
    "if usepublic:\n",
    "    data_all = pd.read_hdf('../input/train.h5')\n",
    "\n",
    "    #public = data_all[data_all.timestamp > 905]\n",
    "    allpublic = DataPrep(yprev_model = ypmodel, keepinput=True).run(data_all)\n",
    "    public = DataPrep(yprev_model = ypmodel, keepinput=True).run(data_all[data_all.timestamp > 905])\n",
    "\n",
    "print(r_score(train.y_prev.fillna(0), train.y_prev_pred))\n",
    "\n",
    "if usepublic:\n",
    "    print(r_score(public.y_prev.fillna(0), public.y_prev_pred))\n",
    "\n",
    "train.sort_values(['id', 'timestamp'], inplace=True)\n",
    "\n",
    "print('prepping xgb now')\n",
    "#xtrain, xvalid = train_test_split(train, test_size = 0.2, random_state = 2017)\n",
    "\n",
    "if not vmode: # submission-style, use all data\n",
    "    rthreshold = 1.0\n",
    "    xtmask = train.random <= rthreshold\n",
    "    xtmask = np.logical_and(xtmask, train['y'] > -.0189765)\n",
    "    xtmask = np.logical_and(xtmask, train['y'] < .0189765)\n",
    "\n",
    "    xtrain = train[xtmask]\n",
    "    xvalid = train[~xtmask]\n",
    "else: # use older split to compare with say the .0202/.0203 subs\n",
    "    xtrain, xvalid = train_test_split(train, test_size = 0.2, random_state = 2017)\n",
    "\n",
    "    xtrain = xtrain[np.abs(xtrain['y']) < 0.018976588919758796]\n",
    "    \n",
    "\n",
    "cols_to_use = [c for c in rcol if c in xtrain.columns and c in rcol_orig] \n",
    "\n",
    "                                                      \n",
    "# Convert to XGB format\n",
    "to_drop = ['timestamp', 'y']\n",
    "\n",
    "train_xgb = xgb.DMatrix(data=xtrain[cols_to_use], label=xtrain['y'])\n",
    "valid_xgb = xgb.DMatrix(data=xvalid[cols_to_use], label=xvalid['y'])\n",
    "\n",
    "evallist = [(valid_xgb, 'valid'), (train_xgb, 'train')]\n",
    "\n",
    "if usepublic:\n",
    "    public_xgb = xgb.DMatrix(data=public[cols_to_use], label=public['y'])\n",
    "\n",
    "    evallist = [(train_xgb, 'train'), (valid_xgb, 'xvalid'), (public_xgb, 'public')]\n",
    "\n",
    "print('xtrain+valid')\n",
    "\n",
    "params = {\n",
    "    'objective': 'reg:linear'\n",
    "    ,'eta': 0.04\n",
    "    ,'max_depth': 3\n",
    "    , 'subsample': 0.9\n",
    "    #, 'colsample_bytree': 1\n",
    "    ,'min_child_weight': 3072 # 2 **11\n",
    "    #,'gamma': 100\n",
    "    , 'seed': 10\n",
    "    #, 'base_score': xtrain.y.mean()\n",
    "}\n",
    "\n",
    "model = []\n",
    "for seed in [10000]:\n",
    "    params['seed'] = seed\n",
    "    model.append(xgb.train(params.items()\n",
    "                  , dtrain=train_xgb\n",
    "                  , num_boost_round=xgbcap # 240 was best_ntree_limit from a train/public split run\n",
    "                  , evals=evallist\n",
    "                  , early_stopping_rounds=50\n",
    "                  , maximize=True\n",
    "                  , verbose_eval=10\n",
    "                  , feval=xgb_eval_custom_r\n",
    "                  ))\n",
    "\n",
    "if not localrun:\n",
    "    del train_xgb\n",
    "    del valid_xgb\n",
    "    if usepublic:\n",
    "        del public_xgb\n",
    "\n",
    "print('xgb done, linear now')\n",
    "\n",
    "lin_features = ['Dtechnical_20', 'technical_20', 'Dtechnical_21']\n",
    "\n",
    "def prep_linear(df, c = lin_features):\n",
    "    df_tmp = df.fillna(d_mean)\n",
    "    m2mat = np.zeros((len(df), len(c)))\n",
    "    for i in range(len(c)):\n",
    "        m2mat[:,i] = df_tmp[c[i]].values\n",
    "    \n",
    "    return m2mat\n",
    "\n",
    "# Observed with histograns:\n",
    "#https://www.kaggle.com/bguberfain/two-sigma-financial-modeling/univariate-model-with-clip/run/482189\n",
    "low_y_cut = -0.075\n",
    "high_y_cut = 0.075\n",
    "traincut = train[np.logical_and(train.y > low_y_cut, train.y < high_y_cut)][['y'] + lin_features].copy().fillna(d_mean)\n",
    "\n",
    "model2 = LinearRegression(n_jobs=-1)\n",
    "model2.fit(prep_linear(traincut), traincut.y)\n",
    "\n",
    "print('linear done')\n",
    "\n",
    "def update_model(m, params_in, cols_to_use):\n",
    "\n",
    "    params = params_in.copy()\n",
    "    \n",
    "    params.update({'process_type': 'update',\n",
    "                       'updater'     : 'refresh',\n",
    "                       'refresh_leaf': False})\n",
    "\n",
    "    m_train = xgb.train(params, train_xgb, m.best_ntree_limit, xgb_model=m)\n",
    "    m_test = xgb.train(params, public_xgb, m.best_ntree_limit, xgb_model=m)\n",
    "\n",
    "    imp = pd.DataFrame(index=cols_to_use)\n",
    "    imp['train'] = pd.Series(m_train.get_score(importance_type='gain'), index=cols_to_use)\n",
    "#    imp['valid'] = pd.Series(m_valid.get_score(importance_type='gain'), index=cols_to_use)\n",
    "    imp['test'] = pd.Series(m_test.get_score(importance_type='gain'), index=cols_to_use)\n",
    "\n",
    "    imp = imp.fillna(0)\n",
    "    \n",
    "    return m_train, m_test, imp\n",
    "\n",
    "if vmode:\n",
    "    preds_xgb = model[0].predict(valid_xgb, ntree_limit=model[0].best_ntree_limit)\n",
    "    preds_linear = model2.predict(prep_linear(xvalid))\n",
    "    \n",
    "    preds = (preds_xgb * 0.7) + (preds_linear * 0.3)\n",
    "    #preds = preds_xgb\n",
    "    \n",
    "    rs = kagglegym.r_score(xvalid.y, preds)\n",
    "    \n",
    "    ID = 'expv-{0}.pkl'.format(int(rs * 10000000))\n",
    "    print(rs, ID)\n",
    "    \n",
    "    #ID = 'subv-203172.pkl' # if actual submission\n",
    "    \n",
    "    output = xvalid[['id', 'timestamp', 'y']].copy()\n",
    "    output['y_hat'] = preds\n",
    "    output['y_hat_xgb'] = preds_xgb\n",
    "    output['y_hat_linear'] = preds_linear\n",
    "    \n",
    "    output.to_pickle(ID)\n",
    "\n",
    "if all_features:\n",
    "    m = model[0]\n",
    "\n",
    "    fs = m.get_fscore()\n",
    "    fsl = [(f,fs[f]) for f in fs.keys()]\n",
    "    fsl = sorted(fsl, key=itemgetter(1), reverse=True)\n",
    "\n",
    "    print(len(fsl))\n",
    "\n",
    "    #print('rcol =', [f[0] for f in fsl])\n",
    "    \n",
    "    m_train, m_test, imp = update_model(model[0], params, cols_to_use)\n",
    "\n",
    "    imp['train_test'] = imp.train * imp.test\n",
    "\n",
    "    imp = imp.sort_values('train_test', ascending=False)\n",
    "    imp.train = imp.train / imp.train.max()\n",
    "    imp.test = imp.test / imp.test.max()\n",
    "    \n",
    "    impr = imp[imp.train_test > 0]\n",
    "    \n",
    "    print('rcol_orig =', list(impr.index))\n",
    "\n",
    "\n",
    "#len(impr), len(imp)\n",
    "\n",
    "start = time.time()        \n",
    "\n",
    "dprep = DataPrep(yprev_model = ypmodel, keepinput=localrun)\n",
    "        \n",
    "\n",
    "if localrun:\n",
    "    env = kagglegym.make()\n",
    "    o = env.reset()\n",
    "\n",
    "while True:\n",
    "    test_preproc = o.features.copy()\n",
    "    \n",
    "    #if c in basecols:\n",
    "        #test_preproc.fillna(d_mean, inplace=True)\n",
    "    \n",
    "    test = dprep.procday(test_preproc)\n",
    "    \n",
    "    #test.fillna(0, inplace=True)\n",
    "    \n",
    "    test_xgb = xgb.DMatrix(data=test.drop(['id', 'timestamp'], axis=1)[cols_to_use])\n",
    "\n",
    "    xgbpreds = np.zeros(len(test), dtype=np.float64)\n",
    "    \n",
    "    for m in model:\n",
    "        xgbpreds += m.predict(test_xgb, ntree_limit=m.best_ntree_limit)\n",
    "\n",
    "    xgbpreds /= len(model)\n",
    "    \n",
    "    test_y = (xgbpreds * .7) + (model2.predict(prep_linear(test)).clip(low_y_cut, high_y_cut) * 0.3)\n",
    "    \n",
    "    o.target['y'] = test_y\n",
    "    target = o.target\n",
    "    \n",
    "    timestamp = o.features[\"timestamp\"][0]\n",
    "    if timestamp % 100 == 0:\n",
    "        print(\"Timestamp #{0} {1}\".format(timestamp, time.time() - start))\n",
    "        start = time.time()\n",
    "\n",
    "    # We perform a \"step\" by making our prediction and getting back an updated \"observation\":\n",
    "    o, reward, done, info = env.step(target)\n",
    "    if done:\n",
    "        print(\"Public score: {}\".format(info[\"public_score\"]))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
