{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import operator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "import xgboost as xgb\n",
    "import random\n",
    "from sklearn import model_selection, preprocessing, ensemble\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "import pickle\n",
    "\n",
    "import sklearn.cluster\n",
    "\n",
    "import Levenshtein\n",
    "\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_pickle('fin-dprep-train.pkl')\n",
    "test_df = pd.read_pickle('fin-dprep-test.pkl')\n",
    "\n",
    "features_to_use = pickle.load(open('fin-dprep-flist.pkl', 'rb'))\n",
    "\n",
    "medium_price = pd.read_pickle('fin-medium-price.pkl')\n",
    "\n",
    "train_df = pd.merge(train_df, medium_price, left_on='listing_id', right_index=True)\n",
    "test_df = pd.merge(test_df, medium_price, left_on='listing_id', right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df[\"predicted_price_diff\"] = np.log(train_df[\"price\"]) - np.log(train_df[\"predicted_price\"])\n",
    "test_df[\"predicted_price_diff\"] = np.log(test_df[\"price\"]) - np.log(test_df[\"predicted_price\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MeansProcessor:\n",
    "    def __init__(self, key, outkey = None, tgt = 'interest_cat'):\n",
    "        self.key = key\n",
    "        self.outkey = key if outkey is None else outkey\n",
    "        \n",
    "        self.count = {}\n",
    "        self.means = {}\n",
    "        self.std = {}\n",
    "        self.global_means = 0\n",
    "        \n",
    "        self.tgt = tgt\n",
    "        \n",
    "        self.outkeys = [self.outkey + '_level', self.outkey + '_level_std']\n",
    "        \n",
    "    def fit(self, df):\n",
    "        self.global_means = df[self.tgt].mean()\n",
    "            \n",
    "        for k in df.groupby(self.key, sort=False):\n",
    "            \n",
    "            self.count[k[0]] = len(k[1])\n",
    "\n",
    "            if len(k[1]) < 0:\n",
    "                self.means[k[0]] = np.nan\n",
    "                self.std[k[0]] = np.nan\n",
    "            else:\n",
    "                self.means[k[0]] = np.mean(k[1][self.tgt])\n",
    "                self.std[k[0]] = np.std(k[1][self.tgt])\n",
    "            \n",
    "    def predict(self, df):\n",
    "        for l in self.outkeys:\n",
    "            df[l] = np.nan # self.global_means[l]\n",
    "            \n",
    "        df[self.outkey + '_count'] = 0\n",
    "            \n",
    "        for k in df.groupby(self.key, sort=False):\n",
    "            if k[0] == 0:\n",
    "                continue\n",
    "            \n",
    "            if k[0] in self.means:\n",
    "                df.loc[k[1].index, self.outkey + '_count'] = self.count[k[0]]\n",
    "                df.loc[k[1].index, self.outkey + '_level'] = self.means[k[0]]\n",
    "                df.loc[k[1].index, self.outkey + '_level_std'] = self.std[k[0]]\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def get_features(self):\n",
    "        return self.outkeys.copy() + [self.outkey + '_count']\n",
    "\n",
    "# i kept the same index randomization (with fixed seed) so I could validate this code against\n",
    "# the original...\n",
    "\n",
    "target_num_map = {'low':0, 'medium':1, 'high':2}\n",
    "train_y = np.array(train_df['interest_level'].apply(lambda x: target_num_map[x]))\n",
    "\n",
    "def proc_fold(fold):\n",
    "    train_index = fold[0]\n",
    "    test_index = fold[1]\n",
    "    \n",
    "    cv_train = train_df.iloc[train_index]\n",
    "    cv_valid = train_df.iloc[test_index][['interest_level', 'manager_id', 'building_id']]\n",
    "    cv_test = test_df.copy()\n",
    "    \n",
    "    m_build = MeansProcessor('building_id', 'building_sort')\n",
    "    m_build.fit(cv_train)\n",
    "    cv_valid = m_build.predict(cv_valid)\n",
    "    cv_test = m_build.predict(cv_test)\n",
    "\n",
    "    m_mgr = MeansProcessor('manager_id', 'manager_sort')\n",
    "    m_mgr.fit(cv_train)\n",
    "    cv_valid = m_mgr.predict(cv_valid)\n",
    "    cv_test = m_mgr.predict(cv_test)\n",
    "\n",
    "    m_comb = MeansProcessor(['building_id', 'manager_id'], 'mb_comb')\n",
    "    m_comb.fit(cv_train)\n",
    "    cv_valid = m_comb.predict(cv_valid)\n",
    "    cv_test = m_comb.predict(cv_test)\n",
    "\n",
    "    return cv_train, cv_valid, cv_test\n",
    "\n",
    "kf = model_selection.StratifiedKFold(n_splits=5, shuffle=True, random_state=2016)\n",
    "folds = [(k[0], k[1]) for k in kf.split(list(range(train_df.shape[0])), train_y)]\n",
    "\n",
    "#with Pool(5) as pool:\n",
    "#    rv = pool.map(proc_fold, folds)\n",
    "\n",
    "import pickle\n",
    "\n",
    "try:\n",
    "    rv = pickle.load(open('0420-model-groupfeatures.pkl', 'rb'))\n",
    "except:\n",
    "    with Pool(5) as pool:\n",
    "        rv = pool.map(proc_fold, folds)\n",
    "\n",
    "        pickle.dump(rv, open('0420-model-groupfeatures.pkl', 'wb'))\n",
    "\n",
    "# dummies to get feature id's\n",
    "m_build = MeansProcessor('building_id', 'building_sort')\n",
    "m_mgr = MeansProcessor('manager_id', 'manager_sort')\n",
    "m_comb = MeansProcessor(['building_id', 'manager_id'], 'mb_comb')\n",
    "\n",
    "group_features = m_build.get_features() + m_mgr.get_features() + m_comb.get_features()\n",
    "\n",
    "cv_test = []\n",
    "for r in rv:\n",
    "    cv_test.append(test_df.merge(r[2][group_features], left_index=True, right_index=True))\n",
    "\n",
    "cv_allvalid = pd.concat([r[1] for r in rv])\n",
    "\n",
    "train_df = train_df.merge(cv_allvalid[group_features], left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_ids = []\n",
    "val_ids = []\n",
    "\n",
    "for dev_index, val_index in kf.split(range(train_df.shape[0]), train_df.interest_cat):\n",
    "    train_ids.append(train_df.iloc[dev_index].listing_id.values)\n",
    "    val_ids.append(train_df.iloc[val_index].listing_id.values)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#fl = features_to_use + m_build.get_features() + m_mgr.get_features() + m_comb.get_features() + tfidf_fn\n",
    "\n",
    "fl = features_to_use.copy() + group_features \n",
    "\n",
    "#fl.remove('price')\n",
    "#fl.remove('price_t')\n",
    "#fl.remove('price_per_room')\n",
    "fl.append('predicted_price')\n",
    "fl.append('predicted_price_diff')\n",
    "\n",
    "fl.append('manager_lazy_rate')\n",
    "\n",
    "fl.append('density_exp01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run3_to_stackdf(run):\n",
    "    \n",
    "    df_testpreds3 = pd.DataFrame(run[2].mean(axis=0))\n",
    "    df_testpreds3.columns = ['low', 'medium', 'high']\n",
    "    df_testpreds3['listing_id'] = test_df.listing_id\n",
    "\n",
    "    df_allpreds3 = pd.concat([run[1][['low', 'medium', 'high', 'listing_id']], df_testpreds3])\n",
    "\n",
    "    df_allpreds3.sort_values('listing_id', inplace=True)\n",
    "    df_allpreds3.set_index('listing_id', inplace=True)\n",
    "    \n",
    "    df_fold = []\n",
    "    for f in range(run[2].shape[0]):\n",
    "        df_fold.append(pd.DataFrame(run[2][f]))\n",
    "        df_fold[-1]['listing_id'] = test_df.listing_id\n",
    "        df_fold[-1].sort_values('listing_id', inplace=True)\n",
    "        df_fold[-1].set_index('listing_id', inplace=True)\n",
    "\n",
    "    return (df_allpreds3, df_fold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "15a46712-582b-28f7-1626-917cdab4f7e5",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def runXGB(train_X, train_y, test_X, test_y=None, feature_names=None, seed_val=0, num_rounds=4000):\n",
    "    param = {}\n",
    "    param['objective'] = 'multi:softprob'\n",
    "    #param['tree_method'] = 'hist'\n",
    "    param['eta'] = 0.02\n",
    "    param['max_depth'] = 6\n",
    "    param['silent'] = 1\n",
    "    param['num_class'] = 3\n",
    "    param['eval_metric'] = \"mlogloss\"\n",
    "    param['min_child_weight'] = 1\n",
    "    param['subsample'] = 0.7\n",
    "    param['colsample_bytree'] = 0.7\n",
    "    param['seed'] = seed_val\n",
    "    #param['base_score'] = [np.mean(train_y == i) for i in [0, 1, 2]]\n",
    "    num_rounds = num_rounds\n",
    "\n",
    "    plst = list(param.items())\n",
    "    xgtrain = xgb.DMatrix(train_X, label=train_y)\n",
    "\n",
    "    if test_y is not None:\n",
    "        xgtest = xgb.DMatrix(test_X, label=test_y)\n",
    "        watchlist = [ (xgtrain,'train'), (xgtest, 'test') ]\n",
    "        model = xgb.train(plst, xgtrain, num_rounds, watchlist, early_stopping_rounds=50, verbose_eval=10)\n",
    "    else:\n",
    "        xgtest = xgb.DMatrix(test_X)\n",
    "        model = xgb.train(plst, xgtrain, num_rounds)\n",
    "\n",
    "    pred_test_y = model.predict(xgtest, ntree_limit=model.best_ntree_limit)\n",
    "    return pred_test_y, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_cv(train_df, cv_test, kf, features_to_use):\n",
    "    train_X = train_df[features_to_use]\n",
    "    train_y = np.array(train_df['interest_level'].apply(lambda x: target_num_map[x]))\n",
    "\n",
    "    cv_preds = []\n",
    "    cv_scores = []\n",
    "    models = []\n",
    "    test_preds = []\n",
    "    \n",
    "    fold = 0\n",
    "\n",
    "    for dev_index, val_index in kf.split(range(train_X.shape[0]), train_y):\n",
    "\n",
    "        dev_X, val_X = train_X.iloc[dev_index], train_X.iloc[val_index]\n",
    "        dev_y, val_y = train_y[dev_index], train_y[val_index]\n",
    "        preds, model = runXGB(dev_X, dev_y, val_X, val_y)\n",
    "        models.append(model)\n",
    "\n",
    "        cv_scores.append(log_loss(val_y, preds))\n",
    "        print(cv_scores)\n",
    "\n",
    "        cut_df = train_df.iloc[val_index]\n",
    "        out_df = pd.DataFrame(preds)\n",
    "        out_df.columns = [\"low\", \"medium\", \"high\"]\n",
    "        out_df[\"listing_id\"] = cut_df.listing_id.values\n",
    "        interest = cut_df.interest_level.apply(lambda x: target_num_map[x])\n",
    "        out_df['interest_tgt'] = interest.values\n",
    "\n",
    "        cv_preds.append(out_df)\n",
    "\n",
    "        xgtest = xgb.DMatrix(cv_test[fold][features_to_use])\n",
    "        test_preds.append(model.predict(xgtest, ntree_limit=model.best_ntree_limit))\n",
    "\n",
    "    df_cv = pd.concat(cv_preds)\n",
    "    print(log_loss(df_cv.interest_tgt, df_cv[['low', 'medium', 'high']]))\n",
    "\n",
    "    apreds = np.array(test_preds)\n",
    "    \n",
    "    return models, df_cv, apreds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:1.08457\ttest-mlogloss:1.08474\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "[10]\ttrain-mlogloss:0.96348\ttest-mlogloss:0.965683\n",
      "[20]\ttrain-mlogloss:0.872029\ttest-mlogloss:0.876469\n",
      "[30]\ttrain-mlogloss:0.801367\ttest-mlogloss:0.807939\n",
      "[40]\ttrain-mlogloss:0.745739\ttest-mlogloss:0.754607\n",
      "[50]\ttrain-mlogloss:0.701679\ttest-mlogloss:0.712797\n",
      "[60]\ttrain-mlogloss:0.666485\ttest-mlogloss:0.679807\n",
      "[70]\ttrain-mlogloss:0.637654\ttest-mlogloss:0.653089\n",
      "[80]\ttrain-mlogloss:0.614372\ttest-mlogloss:0.631793\n",
      "[90]\ttrain-mlogloss:0.595055\ttest-mlogloss:0.614436\n",
      "[100]\ttrain-mlogloss:0.579094\ttest-mlogloss:0.60046\n",
      "[110]\ttrain-mlogloss:0.565481\ttest-mlogloss:0.588773\n",
      "[120]\ttrain-mlogloss:0.553736\ttest-mlogloss:0.5789\n",
      "[130]\ttrain-mlogloss:0.543894\ttest-mlogloss:0.570894\n",
      "[140]\ttrain-mlogloss:0.535246\ttest-mlogloss:0.564114\n",
      "[150]\ttrain-mlogloss:0.527701\ttest-mlogloss:0.558442\n",
      "[160]\ttrain-mlogloss:0.521015\ttest-mlogloss:0.553475\n",
      "[170]\ttrain-mlogloss:0.515087\ttest-mlogloss:0.549249\n",
      "[180]\ttrain-mlogloss:0.509658\ttest-mlogloss:0.545518\n",
      "[190]\ttrain-mlogloss:0.504808\ttest-mlogloss:0.542311\n",
      "[200]\ttrain-mlogloss:0.500315\ttest-mlogloss:0.53951\n",
      "[210]\ttrain-mlogloss:0.496037\ttest-mlogloss:0.537072\n",
      "[220]\ttrain-mlogloss:0.492217\ttest-mlogloss:0.534919\n",
      "[230]\ttrain-mlogloss:0.488477\ttest-mlogloss:0.532879\n",
      "[240]\ttrain-mlogloss:0.485089\ttest-mlogloss:0.531083\n",
      "[250]\ttrain-mlogloss:0.481918\ttest-mlogloss:0.529455\n",
      "[260]\ttrain-mlogloss:0.479012\ttest-mlogloss:0.528067\n",
      "[270]\ttrain-mlogloss:0.476019\ttest-mlogloss:0.52667\n",
      "[280]\ttrain-mlogloss:0.473255\ttest-mlogloss:0.525446\n",
      "[290]\ttrain-mlogloss:0.470753\ttest-mlogloss:0.52427\n",
      "[300]\ttrain-mlogloss:0.468024\ttest-mlogloss:0.523174\n",
      "[310]\ttrain-mlogloss:0.465594\ttest-mlogloss:0.522203\n",
      "[320]\ttrain-mlogloss:0.463247\ttest-mlogloss:0.521422\n",
      "[330]\ttrain-mlogloss:0.461059\ttest-mlogloss:0.520575\n",
      "[340]\ttrain-mlogloss:0.458819\ttest-mlogloss:0.519766\n",
      "[350]\ttrain-mlogloss:0.456705\ttest-mlogloss:0.519057\n",
      "[360]\ttrain-mlogloss:0.454647\ttest-mlogloss:0.518484\n",
      "[370]\ttrain-mlogloss:0.452473\ttest-mlogloss:0.517882\n",
      "[380]\ttrain-mlogloss:0.450452\ttest-mlogloss:0.517276\n",
      "[390]\ttrain-mlogloss:0.448549\ttest-mlogloss:0.516619\n",
      "[400]\ttrain-mlogloss:0.446706\ttest-mlogloss:0.516004\n",
      "[410]\ttrain-mlogloss:0.444759\ttest-mlogloss:0.515526\n",
      "[420]\ttrain-mlogloss:0.442839\ttest-mlogloss:0.5151\n",
      "[430]\ttrain-mlogloss:0.441014\ttest-mlogloss:0.514779\n",
      "[440]\ttrain-mlogloss:0.439166\ttest-mlogloss:0.514378\n",
      "[450]\ttrain-mlogloss:0.437239\ttest-mlogloss:0.513916\n",
      "[460]\ttrain-mlogloss:0.43534\ttest-mlogloss:0.513468\n",
      "[470]\ttrain-mlogloss:0.433629\ttest-mlogloss:0.513086\n",
      "[480]\ttrain-mlogloss:0.431744\ttest-mlogloss:0.512774\n",
      "[490]\ttrain-mlogloss:0.430184\ttest-mlogloss:0.512465\n",
      "[500]\ttrain-mlogloss:0.428682\ttest-mlogloss:0.512167\n",
      "[510]\ttrain-mlogloss:0.427056\ttest-mlogloss:0.511812\n",
      "[520]\ttrain-mlogloss:0.42544\ttest-mlogloss:0.511541\n",
      "[530]\ttrain-mlogloss:0.423883\ttest-mlogloss:0.511311\n",
      "[540]\ttrain-mlogloss:0.422333\ttest-mlogloss:0.511023\n",
      "[550]\ttrain-mlogloss:0.420689\ttest-mlogloss:0.5108\n",
      "[560]\ttrain-mlogloss:0.419159\ttest-mlogloss:0.510596\n",
      "[570]\ttrain-mlogloss:0.41781\ttest-mlogloss:0.510369\n",
      "[580]\ttrain-mlogloss:0.416276\ttest-mlogloss:0.51014\n",
      "[590]\ttrain-mlogloss:0.414686\ttest-mlogloss:0.510003\n",
      "[600]\ttrain-mlogloss:0.413281\ttest-mlogloss:0.509872\n",
      "[610]\ttrain-mlogloss:0.411911\ttest-mlogloss:0.509679\n",
      "[620]\ttrain-mlogloss:0.410288\ttest-mlogloss:0.509531\n",
      "[630]\ttrain-mlogloss:0.408764\ttest-mlogloss:0.509315\n",
      "[640]\ttrain-mlogloss:0.407232\ttest-mlogloss:0.509203\n",
      "[650]\ttrain-mlogloss:0.405755\ttest-mlogloss:0.509051\n",
      "[660]\ttrain-mlogloss:0.404273\ttest-mlogloss:0.508909\n",
      "[670]\ttrain-mlogloss:0.402781\ttest-mlogloss:0.508724\n",
      "[680]\ttrain-mlogloss:0.401333\ttest-mlogloss:0.50858\n",
      "[690]\ttrain-mlogloss:0.399852\ttest-mlogloss:0.508485\n",
      "[700]\ttrain-mlogloss:0.398293\ttest-mlogloss:0.508391\n",
      "[710]\ttrain-mlogloss:0.396752\ttest-mlogloss:0.508235\n",
      "[720]\ttrain-mlogloss:0.395181\ttest-mlogloss:0.508152\n",
      "[730]\ttrain-mlogloss:0.39363\ttest-mlogloss:0.507957\n",
      "[740]\ttrain-mlogloss:0.392286\ttest-mlogloss:0.507847\n",
      "[750]\ttrain-mlogloss:0.39087\ttest-mlogloss:0.507639\n",
      "[760]\ttrain-mlogloss:0.389552\ttest-mlogloss:0.507487\n",
      "[770]\ttrain-mlogloss:0.388145\ttest-mlogloss:0.507513\n",
      "[780]\ttrain-mlogloss:0.386686\ttest-mlogloss:0.507354\n",
      "[790]\ttrain-mlogloss:0.385257\ttest-mlogloss:0.507271\n",
      "[800]\ttrain-mlogloss:0.383852\ttest-mlogloss:0.507223\n",
      "[810]\ttrain-mlogloss:0.382626\ttest-mlogloss:0.507124\n",
      "[820]\ttrain-mlogloss:0.381251\ttest-mlogloss:0.507035\n",
      "[830]\ttrain-mlogloss:0.379903\ttest-mlogloss:0.50701\n",
      "[840]\ttrain-mlogloss:0.378773\ttest-mlogloss:0.506868\n",
      "[850]\ttrain-mlogloss:0.377311\ttest-mlogloss:0.50674\n",
      "[860]\ttrain-mlogloss:0.375907\ttest-mlogloss:0.506648\n",
      "[870]\ttrain-mlogloss:0.374456\ttest-mlogloss:0.506565\n",
      "[880]\ttrain-mlogloss:0.373204\ttest-mlogloss:0.506465\n",
      "[890]\ttrain-mlogloss:0.371972\ttest-mlogloss:0.506396\n",
      "[900]\ttrain-mlogloss:0.370537\ttest-mlogloss:0.506338\n",
      "[910]\ttrain-mlogloss:0.369345\ttest-mlogloss:0.506243\n",
      "[920]\ttrain-mlogloss:0.368102\ttest-mlogloss:0.506188\n",
      "[930]\ttrain-mlogloss:0.366794\ttest-mlogloss:0.506226\n",
      "[940]\ttrain-mlogloss:0.365392\ttest-mlogloss:0.506145\n",
      "[950]\ttrain-mlogloss:0.363955\ttest-mlogloss:0.506165\n",
      "[960]\ttrain-mlogloss:0.362698\ttest-mlogloss:0.506048\n",
      "[970]\ttrain-mlogloss:0.361551\ttest-mlogloss:0.506006\n",
      "[980]\ttrain-mlogloss:0.360458\ttest-mlogloss:0.505943\n",
      "[990]\ttrain-mlogloss:0.359043\ttest-mlogloss:0.50604\n",
      "[1000]\ttrain-mlogloss:0.357772\ttest-mlogloss:0.506029\n",
      "[1010]\ttrain-mlogloss:0.356413\ttest-mlogloss:0.506072\n",
      "[1020]\ttrain-mlogloss:0.355174\ttest-mlogloss:0.506186\n",
      "Stopping. Best iteration:\n",
      "[978]\ttrain-mlogloss:0.360616\ttest-mlogloss:0.505937\n",
      "\n",
      "[0.50593702950354136]\n",
      "[0]\ttrain-mlogloss:1.08465\ttest-mlogloss:1.08469\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "[10]\ttrain-mlogloss:0.963941\ttest-mlogloss:0.965377\n",
      "[20]\ttrain-mlogloss:0.872884\ttest-mlogloss:0.875824\n",
      "[30]\ttrain-mlogloss:0.802516\ttest-mlogloss:0.807074\n",
      "[40]\ttrain-mlogloss:0.747009\ttest-mlogloss:0.753138\n",
      "[50]\ttrain-mlogloss:0.703105\ttest-mlogloss:0.710825\n",
      "[60]\ttrain-mlogloss:0.668051\ttest-mlogloss:0.677339\n",
      "[70]\ttrain-mlogloss:0.639167\ttest-mlogloss:0.650131\n",
      "[80]\ttrain-mlogloss:0.615889\ttest-mlogloss:0.628493\n",
      "[90]\ttrain-mlogloss:0.596526\ttest-mlogloss:0.610784\n",
      "[100]\ttrain-mlogloss:0.580618\ttest-mlogloss:0.596611\n",
      "[110]\ttrain-mlogloss:0.567006\ttest-mlogloss:0.584608\n",
      "[120]\ttrain-mlogloss:0.555304\ttest-mlogloss:0.574531\n",
      "[130]\ttrain-mlogloss:0.545487\ttest-mlogloss:0.566372\n",
      "[140]\ttrain-mlogloss:0.536853\ttest-mlogloss:0.559444\n",
      "[150]\ttrain-mlogloss:0.529277\ttest-mlogloss:0.553654\n",
      "[160]\ttrain-mlogloss:0.522551\ttest-mlogloss:0.548557\n",
      "[170]\ttrain-mlogloss:0.516529\ttest-mlogloss:0.544076\n",
      "[180]\ttrain-mlogloss:0.511107\ttest-mlogloss:0.540329\n",
      "[190]\ttrain-mlogloss:0.506237\ttest-mlogloss:0.537125\n",
      "[200]\ttrain-mlogloss:0.501638\ttest-mlogloss:0.534176\n",
      "[210]\ttrain-mlogloss:0.497498\ttest-mlogloss:0.531654\n",
      "[220]\ttrain-mlogloss:0.49361\ttest-mlogloss:0.529387\n",
      "[230]\ttrain-mlogloss:0.490053\ttest-mlogloss:0.527486\n",
      "[240]\ttrain-mlogloss:0.48668\ttest-mlogloss:0.525641\n",
      "[250]\ttrain-mlogloss:0.483373\ttest-mlogloss:0.524038\n",
      "[260]\ttrain-mlogloss:0.480316\ttest-mlogloss:0.522616\n",
      "[270]\ttrain-mlogloss:0.477294\ttest-mlogloss:0.521411\n",
      "[280]\ttrain-mlogloss:0.474683\ttest-mlogloss:0.520333\n",
      "[290]\ttrain-mlogloss:0.472036\ttest-mlogloss:0.519288\n",
      "[300]\ttrain-mlogloss:0.469485\ttest-mlogloss:0.518285\n",
      "[310]\ttrain-mlogloss:0.467279\ttest-mlogloss:0.517407\n",
      "[320]\ttrain-mlogloss:0.464915\ttest-mlogloss:0.516607\n",
      "[330]\ttrain-mlogloss:0.462639\ttest-mlogloss:0.515831\n",
      "[340]\ttrain-mlogloss:0.460544\ttest-mlogloss:0.51514\n",
      "[350]\ttrain-mlogloss:0.458509\ttest-mlogloss:0.514536\n",
      "[360]\ttrain-mlogloss:0.456545\ttest-mlogloss:0.513944\n",
      "[370]\ttrain-mlogloss:0.454397\ttest-mlogloss:0.513326\n",
      "[380]\ttrain-mlogloss:0.452365\ttest-mlogloss:0.512784\n",
      "[390]\ttrain-mlogloss:0.450522\ttest-mlogloss:0.512343\n",
      "[400]\ttrain-mlogloss:0.448609\ttest-mlogloss:0.511897\n",
      "[410]\ttrain-mlogloss:0.446703\ttest-mlogloss:0.511406\n",
      "[420]\ttrain-mlogloss:0.444894\ttest-mlogloss:0.510944\n",
      "[430]\ttrain-mlogloss:0.443086\ttest-mlogloss:0.510522\n",
      "[440]\ttrain-mlogloss:0.441377\ttest-mlogloss:0.51015\n",
      "[450]\ttrain-mlogloss:0.439603\ttest-mlogloss:0.509825\n",
      "[460]\ttrain-mlogloss:0.4379\ttest-mlogloss:0.509541\n",
      "[470]\ttrain-mlogloss:0.436303\ttest-mlogloss:0.509197\n",
      "[480]\ttrain-mlogloss:0.434644\ttest-mlogloss:0.508899\n",
      "[490]\ttrain-mlogloss:0.433004\ttest-mlogloss:0.508607\n",
      "[500]\ttrain-mlogloss:0.431324\ttest-mlogloss:0.508303\n",
      "[510]\ttrain-mlogloss:0.429729\ttest-mlogloss:0.508034\n",
      "[520]\ttrain-mlogloss:0.428004\ttest-mlogloss:0.50771\n",
      "[530]\ttrain-mlogloss:0.426386\ttest-mlogloss:0.507444\n",
      "[540]\ttrain-mlogloss:0.4249\ttest-mlogloss:0.507201\n",
      "[550]\ttrain-mlogloss:0.42345\ttest-mlogloss:0.506983\n",
      "[560]\ttrain-mlogloss:0.421807\ttest-mlogloss:0.506693\n",
      "[570]\ttrain-mlogloss:0.42017\ttest-mlogloss:0.506469\n",
      "[580]\ttrain-mlogloss:0.418476\ttest-mlogloss:0.506256\n",
      "[590]\ttrain-mlogloss:0.416969\ttest-mlogloss:0.506052\n",
      "[600]\ttrain-mlogloss:0.415227\ttest-mlogloss:0.505825\n",
      "[610]\ttrain-mlogloss:0.413783\ttest-mlogloss:0.505637\n",
      "[620]\ttrain-mlogloss:0.412143\ttest-mlogloss:0.505484\n",
      "[630]\ttrain-mlogloss:0.410738\ttest-mlogloss:0.505305\n",
      "[640]\ttrain-mlogloss:0.409167\ttest-mlogloss:0.505089\n",
      "[650]\ttrain-mlogloss:0.407679\ttest-mlogloss:0.504951\n",
      "[660]\ttrain-mlogloss:0.40628\ttest-mlogloss:0.504828\n",
      "[670]\ttrain-mlogloss:0.404878\ttest-mlogloss:0.504752\n",
      "[680]\ttrain-mlogloss:0.403509\ttest-mlogloss:0.504632\n",
      "[690]\ttrain-mlogloss:0.402086\ttest-mlogloss:0.504476\n",
      "[700]\ttrain-mlogloss:0.400403\ttest-mlogloss:0.504288\n",
      "[710]\ttrain-mlogloss:0.399067\ttest-mlogloss:0.504159\n",
      "[720]\ttrain-mlogloss:0.397732\ttest-mlogloss:0.504061\n",
      "[730]\ttrain-mlogloss:0.396314\ttest-mlogloss:0.503895\n",
      "[740]\ttrain-mlogloss:0.394916\ttest-mlogloss:0.503794\n",
      "[750]\ttrain-mlogloss:0.393338\ttest-mlogloss:0.503783\n",
      "[760]\ttrain-mlogloss:0.391913\ttest-mlogloss:0.50361\n",
      "[770]\ttrain-mlogloss:0.39051\ttest-mlogloss:0.503497\n",
      "[780]\ttrain-mlogloss:0.389071\ttest-mlogloss:0.503325\n",
      "[790]\ttrain-mlogloss:0.387626\ttest-mlogloss:0.503229\n",
      "[800]\ttrain-mlogloss:0.386148\ttest-mlogloss:0.50313\n",
      "[810]\ttrain-mlogloss:0.384836\ttest-mlogloss:0.503032\n",
      "[820]\ttrain-mlogloss:0.383432\ttest-mlogloss:0.502824\n",
      "[830]\ttrain-mlogloss:0.382271\ttest-mlogloss:0.502731\n",
      "[840]\ttrain-mlogloss:0.380872\ttest-mlogloss:0.502597\n",
      "[850]\ttrain-mlogloss:0.379553\ttest-mlogloss:0.502508\n",
      "[860]\ttrain-mlogloss:0.378371\ttest-mlogloss:0.502451\n",
      "[870]\ttrain-mlogloss:0.377141\ttest-mlogloss:0.502422\n",
      "[880]\ttrain-mlogloss:0.375911\ttest-mlogloss:0.502369\n",
      "[890]\ttrain-mlogloss:0.374638\ttest-mlogloss:0.502291\n",
      "[900]\ttrain-mlogloss:0.373167\ttest-mlogloss:0.502257\n",
      "[910]\ttrain-mlogloss:0.371807\ttest-mlogloss:0.502202\n",
      "[920]\ttrain-mlogloss:0.37037\ttest-mlogloss:0.502091\n",
      "[930]\ttrain-mlogloss:0.368988\ttest-mlogloss:0.502085\n",
      "[940]\ttrain-mlogloss:0.367668\ttest-mlogloss:0.50207\n",
      "[950]\ttrain-mlogloss:0.366394\ttest-mlogloss:0.502037\n",
      "[960]\ttrain-mlogloss:0.365111\ttest-mlogloss:0.50196\n",
      "[970]\ttrain-mlogloss:0.363908\ttest-mlogloss:0.501993\n",
      "[980]\ttrain-mlogloss:0.362627\ttest-mlogloss:0.501904\n",
      "[990]\ttrain-mlogloss:0.361387\ttest-mlogloss:0.501837\n",
      "[1000]\ttrain-mlogloss:0.360052\ttest-mlogloss:0.501789\n",
      "[1010]\ttrain-mlogloss:0.358685\ttest-mlogloss:0.501799\n",
      "[1020]\ttrain-mlogloss:0.357445\ttest-mlogloss:0.50179\n",
      "[1030]\ttrain-mlogloss:0.356138\ttest-mlogloss:0.501749\n",
      "[1040]\ttrain-mlogloss:0.354901\ttest-mlogloss:0.501769\n",
      "[1050]\ttrain-mlogloss:0.353704\ttest-mlogloss:0.501707\n",
      "[1060]\ttrain-mlogloss:0.352372\ttest-mlogloss:0.501639\n",
      "[1070]\ttrain-mlogloss:0.351089\ttest-mlogloss:0.50154\n",
      "[1080]\ttrain-mlogloss:0.34995\ttest-mlogloss:0.501438\n",
      "[1090]\ttrain-mlogloss:0.348707\ttest-mlogloss:0.501354\n",
      "[1100]\ttrain-mlogloss:0.3475\ttest-mlogloss:0.501286\n",
      "[1110]\ttrain-mlogloss:0.346212\ttest-mlogloss:0.50122\n",
      "[1120]\ttrain-mlogloss:0.344985\ttest-mlogloss:0.501237\n",
      "[1130]\ttrain-mlogloss:0.34382\ttest-mlogloss:0.501222\n",
      "[1140]\ttrain-mlogloss:0.342606\ttest-mlogloss:0.501121\n",
      "[1150]\ttrain-mlogloss:0.341407\ttest-mlogloss:0.501047\n",
      "[1160]\ttrain-mlogloss:0.340203\ttest-mlogloss:0.500928\n",
      "[1170]\ttrain-mlogloss:0.339119\ttest-mlogloss:0.500996\n",
      "[1180]\ttrain-mlogloss:0.337938\ttest-mlogloss:0.500952\n",
      "[1190]\ttrain-mlogloss:0.336759\ttest-mlogloss:0.500963\n",
      "[1200]\ttrain-mlogloss:0.335569\ttest-mlogloss:0.501018\n",
      "[1210]\ttrain-mlogloss:0.33444\ttest-mlogloss:0.500997\n",
      "Stopping. Best iteration:\n",
      "[1161]\ttrain-mlogloss:0.340089\ttest-mlogloss:0.500923\n",
      "\n",
      "[0.50593702950354136, 0.50092266559477416]\n",
      "[0]\ttrain-mlogloss:1.08448\ttest-mlogloss:1.08495\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "[10]\ttrain-mlogloss:0.962992\ttest-mlogloss:0.967513\n",
      "[20]\ttrain-mlogloss:0.871387\ttest-mlogloss:0.879663\n",
      "[30]\ttrain-mlogloss:0.800331\ttest-mlogloss:0.811987\n",
      "[40]\ttrain-mlogloss:0.744479\ttest-mlogloss:0.759205\n",
      "[50]\ttrain-mlogloss:0.700321\ttest-mlogloss:0.717827\n",
      "[60]\ttrain-mlogloss:0.664943\ttest-mlogloss:0.685229\n",
      "[70]\ttrain-mlogloss:0.63587\ttest-mlogloss:0.658718\n",
      "[80]\ttrain-mlogloss:0.612489\ttest-mlogloss:0.63765\n",
      "[90]\ttrain-mlogloss:0.593076\ttest-mlogloss:0.620559\n",
      "[100]\ttrain-mlogloss:0.577102\ttest-mlogloss:0.606687\n",
      "[110]\ttrain-mlogloss:0.563492\ttest-mlogloss:0.595101\n",
      "[120]\ttrain-mlogloss:0.551667\ttest-mlogloss:0.585425\n",
      "[130]\ttrain-mlogloss:0.541728\ttest-mlogloss:0.577582\n",
      "[140]\ttrain-mlogloss:0.533017\ttest-mlogloss:0.570908\n",
      "[150]\ttrain-mlogloss:0.525484\ttest-mlogloss:0.565362\n",
      "[160]\ttrain-mlogloss:0.518796\ttest-mlogloss:0.560553\n",
      "[170]\ttrain-mlogloss:0.512791\ttest-mlogloss:0.556424\n",
      "[180]\ttrain-mlogloss:0.507402\ttest-mlogloss:0.552787\n",
      "[190]\ttrain-mlogloss:0.502443\ttest-mlogloss:0.549634\n",
      "[200]\ttrain-mlogloss:0.497977\ttest-mlogloss:0.546937\n",
      "[210]\ttrain-mlogloss:0.493831\ttest-mlogloss:0.544581\n",
      "[220]\ttrain-mlogloss:0.489909\ttest-mlogloss:0.542378\n",
      "[230]\ttrain-mlogloss:0.486345\ttest-mlogloss:0.54051\n",
      "[240]\ttrain-mlogloss:0.482975\ttest-mlogloss:0.538836\n",
      "[250]\ttrain-mlogloss:0.479899\ttest-mlogloss:0.53742\n",
      "[260]\ttrain-mlogloss:0.476858\ttest-mlogloss:0.536085\n",
      "[270]\ttrain-mlogloss:0.473934\ttest-mlogloss:0.534844\n",
      "[280]\ttrain-mlogloss:0.471232\ttest-mlogloss:0.533697\n",
      "[290]\ttrain-mlogloss:0.468451\ttest-mlogloss:0.532529\n",
      "[300]\ttrain-mlogloss:0.466032\ttest-mlogloss:0.531734\n",
      "[310]\ttrain-mlogloss:0.46357\ttest-mlogloss:0.530874\n",
      "[320]\ttrain-mlogloss:0.461214\ttest-mlogloss:0.530003\n",
      "[330]\ttrain-mlogloss:0.458952\ttest-mlogloss:0.529224\n",
      "[340]\ttrain-mlogloss:0.456858\ttest-mlogloss:0.528584\n",
      "[350]\ttrain-mlogloss:0.454687\ttest-mlogloss:0.527964\n",
      "[360]\ttrain-mlogloss:0.452574\ttest-mlogloss:0.527348\n",
      "[370]\ttrain-mlogloss:0.450331\ttest-mlogloss:0.526721\n",
      "[380]\ttrain-mlogloss:0.448268\ttest-mlogloss:0.5262\n",
      "[390]\ttrain-mlogloss:0.446238\ttest-mlogloss:0.52568\n",
      "[400]\ttrain-mlogloss:0.444063\ttest-mlogloss:0.525134\n",
      "[410]\ttrain-mlogloss:0.442434\ttest-mlogloss:0.524733\n",
      "[420]\ttrain-mlogloss:0.440619\ttest-mlogloss:0.524316\n",
      "[430]\ttrain-mlogloss:0.438639\ttest-mlogloss:0.523913\n",
      "[440]\ttrain-mlogloss:0.43682\ttest-mlogloss:0.52349\n",
      "[450]\ttrain-mlogloss:0.434939\ttest-mlogloss:0.523073\n",
      "[460]\ttrain-mlogloss:0.433449\ttest-mlogloss:0.522746\n",
      "[470]\ttrain-mlogloss:0.431705\ttest-mlogloss:0.522426\n",
      "[480]\ttrain-mlogloss:0.430039\ttest-mlogloss:0.522045\n",
      "[490]\ttrain-mlogloss:0.428146\ttest-mlogloss:0.521781\n",
      "[500]\ttrain-mlogloss:0.42652\ttest-mlogloss:0.521472\n",
      "[510]\ttrain-mlogloss:0.424719\ttest-mlogloss:0.521102\n",
      "[520]\ttrain-mlogloss:0.422946\ttest-mlogloss:0.52082\n",
      "[530]\ttrain-mlogloss:0.421542\ttest-mlogloss:0.520601\n",
      "[540]\ttrain-mlogloss:0.419967\ttest-mlogloss:0.520308\n",
      "[550]\ttrain-mlogloss:0.418461\ttest-mlogloss:0.52006\n",
      "[560]\ttrain-mlogloss:0.416766\ttest-mlogloss:0.519882\n",
      "[570]\ttrain-mlogloss:0.415187\ttest-mlogloss:0.519651\n",
      "[580]\ttrain-mlogloss:0.413686\ttest-mlogloss:0.519503\n",
      "[590]\ttrain-mlogloss:0.412156\ttest-mlogloss:0.519169\n",
      "[600]\ttrain-mlogloss:0.410559\ttest-mlogloss:0.518938\n",
      "[610]\ttrain-mlogloss:0.409067\ttest-mlogloss:0.518637\n",
      "[620]\ttrain-mlogloss:0.407593\ttest-mlogloss:0.518468\n",
      "[630]\ttrain-mlogloss:0.406231\ttest-mlogloss:0.518315\n",
      "[640]\ttrain-mlogloss:0.404836\ttest-mlogloss:0.518138\n",
      "[650]\ttrain-mlogloss:0.403466\ttest-mlogloss:0.517991\n",
      "[660]\ttrain-mlogloss:0.401837\ttest-mlogloss:0.517897\n",
      "[670]\ttrain-mlogloss:0.400135\ttest-mlogloss:0.517863\n",
      "[680]\ttrain-mlogloss:0.398719\ttest-mlogloss:0.517655\n",
      "[690]\ttrain-mlogloss:0.397267\ttest-mlogloss:0.517461\n",
      "[700]\ttrain-mlogloss:0.395902\ttest-mlogloss:0.517382\n",
      "[710]\ttrain-mlogloss:0.39439\ttest-mlogloss:0.517265\n",
      "[720]\ttrain-mlogloss:0.392892\ttest-mlogloss:0.517121\n",
      "[730]\ttrain-mlogloss:0.39139\ttest-mlogloss:0.516973\n",
      "[740]\ttrain-mlogloss:0.389994\ttest-mlogloss:0.516863\n",
      "[750]\ttrain-mlogloss:0.388442\ttest-mlogloss:0.516847\n",
      "[760]\ttrain-mlogloss:0.387271\ttest-mlogloss:0.516768\n",
      "[770]\ttrain-mlogloss:0.385891\ttest-mlogloss:0.516702\n",
      "[780]\ttrain-mlogloss:0.384594\ttest-mlogloss:0.516582\n",
      "[790]\ttrain-mlogloss:0.383122\ttest-mlogloss:0.516435\n",
      "[800]\ttrain-mlogloss:0.381774\ttest-mlogloss:0.516267\n",
      "[810]\ttrain-mlogloss:0.380436\ttest-mlogloss:0.516221\n",
      "[820]\ttrain-mlogloss:0.379153\ttest-mlogloss:0.516108\n",
      "[830]\ttrain-mlogloss:0.3778\ttest-mlogloss:0.516002\n",
      "[840]\ttrain-mlogloss:0.376467\ttest-mlogloss:0.515907\n",
      "[850]\ttrain-mlogloss:0.375012\ttest-mlogloss:0.515857\n",
      "[860]\ttrain-mlogloss:0.373545\ttest-mlogloss:0.515738\n",
      "[870]\ttrain-mlogloss:0.372192\ttest-mlogloss:0.515677\n",
      "[880]\ttrain-mlogloss:0.370975\ttest-mlogloss:0.515608\n",
      "[890]\ttrain-mlogloss:0.369831\ttest-mlogloss:0.51551\n",
      "[900]\ttrain-mlogloss:0.368541\ttest-mlogloss:0.515394\n",
      "[910]\ttrain-mlogloss:0.367195\ttest-mlogloss:0.515328\n",
      "[920]\ttrain-mlogloss:0.365893\ttest-mlogloss:0.515281\n",
      "[930]\ttrain-mlogloss:0.364575\ttest-mlogloss:0.515194\n",
      "[940]\ttrain-mlogloss:0.363339\ttest-mlogloss:0.515177\n",
      "[950]\ttrain-mlogloss:0.362095\ttest-mlogloss:0.515247\n",
      "[960]\ttrain-mlogloss:0.360748\ttest-mlogloss:0.515157\n",
      "[970]\ttrain-mlogloss:0.359497\ttest-mlogloss:0.515171\n",
      "[980]\ttrain-mlogloss:0.358197\ttest-mlogloss:0.515152\n",
      "[990]\ttrain-mlogloss:0.356917\ttest-mlogloss:0.515155\n",
      "[1000]\ttrain-mlogloss:0.355645\ttest-mlogloss:0.51515\n",
      "[1010]\ttrain-mlogloss:0.354457\ttest-mlogloss:0.515066\n",
      "[1020]\ttrain-mlogloss:0.353347\ttest-mlogloss:0.514978\n",
      "[1030]\ttrain-mlogloss:0.352152\ttest-mlogloss:0.514936\n",
      "[1040]\ttrain-mlogloss:0.351011\ttest-mlogloss:0.514856\n",
      "[1050]\ttrain-mlogloss:0.34973\ttest-mlogloss:0.514795\n",
      "[1060]\ttrain-mlogloss:0.348622\ttest-mlogloss:0.514759\n",
      "[1070]\ttrain-mlogloss:0.347416\ttest-mlogloss:0.514751\n",
      "[1080]\ttrain-mlogloss:0.34623\ttest-mlogloss:0.514676\n",
      "[1090]\ttrain-mlogloss:0.34504\ttest-mlogloss:0.514641\n",
      "[1100]\ttrain-mlogloss:0.343701\ttest-mlogloss:0.514627\n",
      "[1110]\ttrain-mlogloss:0.342402\ttest-mlogloss:0.514578\n",
      "[1120]\ttrain-mlogloss:0.341268\ttest-mlogloss:0.514619\n",
      "[1130]\ttrain-mlogloss:0.340115\ttest-mlogloss:0.5146\n",
      "[1140]\ttrain-mlogloss:0.338997\ttest-mlogloss:0.514522\n",
      "[1150]\ttrain-mlogloss:0.337885\ttest-mlogloss:0.51445\n",
      "[1160]\ttrain-mlogloss:0.336836\ttest-mlogloss:0.514434\n",
      "[1170]\ttrain-mlogloss:0.33569\ttest-mlogloss:0.514425\n",
      "[1180]\ttrain-mlogloss:0.334599\ttest-mlogloss:0.514457\n",
      "[1190]\ttrain-mlogloss:0.333493\ttest-mlogloss:0.514396\n",
      "[1200]\ttrain-mlogloss:0.332379\ttest-mlogloss:0.514348\n",
      "[1210]\ttrain-mlogloss:0.331162\ttest-mlogloss:0.514339\n",
      "[1220]\ttrain-mlogloss:0.330025\ttest-mlogloss:0.51435\n",
      "[1230]\ttrain-mlogloss:0.328848\ttest-mlogloss:0.514384\n",
      "[1240]\ttrain-mlogloss:0.327812\ttest-mlogloss:0.514358\n",
      "[1250]\ttrain-mlogloss:0.326785\ttest-mlogloss:0.51435\n",
      "Stopping. Best iteration:\n",
      "[1207]\ttrain-mlogloss:0.331518\ttest-mlogloss:0.514305\n",
      "\n",
      "[0.50593702950354136, 0.50092266559477416, 0.51430512114807325]\n",
      "[0]\ttrain-mlogloss:1.08454\ttest-mlogloss:1.08487\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "[10]\ttrain-mlogloss:0.963362\ttest-mlogloss:0.966917\n",
      "[20]\ttrain-mlogloss:0.871817\ttest-mlogloss:0.878514\n",
      "[30]\ttrain-mlogloss:0.800996\ttest-mlogloss:0.810687\n",
      "[40]\ttrain-mlogloss:0.745173\ttest-mlogloss:0.757635\n",
      "[50]\ttrain-mlogloss:0.700972\ttest-mlogloss:0.716051\n",
      "[60]\ttrain-mlogloss:0.665718\ttest-mlogloss:0.683207\n",
      "[70]\ttrain-mlogloss:0.636716\ttest-mlogloss:0.656573\n",
      "[80]\ttrain-mlogloss:0.613329\ttest-mlogloss:0.635439\n",
      "[90]\ttrain-mlogloss:0.5939\ttest-mlogloss:0.618173\n",
      "[100]\ttrain-mlogloss:0.577877\ttest-mlogloss:0.604058\n",
      "[110]\ttrain-mlogloss:0.564213\ttest-mlogloss:0.592412\n",
      "[120]\ttrain-mlogloss:0.552298\ttest-mlogloss:0.582626\n",
      "[130]\ttrain-mlogloss:0.54239\ttest-mlogloss:0.574552\n",
      "[140]\ttrain-mlogloss:0.533724\ttest-mlogloss:0.567784\n",
      "[150]\ttrain-mlogloss:0.526156\ttest-mlogloss:0.561937\n",
      "[160]\ttrain-mlogloss:0.519492\ttest-mlogloss:0.557001\n",
      "[170]\ttrain-mlogloss:0.513598\ttest-mlogloss:0.552741\n",
      "[180]\ttrain-mlogloss:0.508226\ttest-mlogloss:0.549135\n",
      "[190]\ttrain-mlogloss:0.503253\ttest-mlogloss:0.545784\n",
      "[200]\ttrain-mlogloss:0.498734\ttest-mlogloss:0.542902\n",
      "[210]\ttrain-mlogloss:0.494516\ttest-mlogloss:0.540387\n",
      "[220]\ttrain-mlogloss:0.490799\ttest-mlogloss:0.538191\n",
      "[230]\ttrain-mlogloss:0.487142\ttest-mlogloss:0.536157\n",
      "[240]\ttrain-mlogloss:0.483787\ttest-mlogloss:0.534411\n",
      "[250]\ttrain-mlogloss:0.4804\ttest-mlogloss:0.532628\n",
      "[260]\ttrain-mlogloss:0.477357\ttest-mlogloss:0.531129\n",
      "[270]\ttrain-mlogloss:0.47436\ttest-mlogloss:0.529846\n",
      "[280]\ttrain-mlogloss:0.47166\ttest-mlogloss:0.52858\n",
      "[290]\ttrain-mlogloss:0.468954\ttest-mlogloss:0.52744\n",
      "[300]\ttrain-mlogloss:0.466275\ttest-mlogloss:0.526446\n",
      "[310]\ttrain-mlogloss:0.463791\ttest-mlogloss:0.525551\n",
      "[320]\ttrain-mlogloss:0.461622\ttest-mlogloss:0.524678\n",
      "[330]\ttrain-mlogloss:0.459383\ttest-mlogloss:0.523966\n",
      "[340]\ttrain-mlogloss:0.457243\ttest-mlogloss:0.523327\n",
      "[350]\ttrain-mlogloss:0.454874\ttest-mlogloss:0.522563\n",
      "[360]\ttrain-mlogloss:0.452676\ttest-mlogloss:0.521838\n",
      "[370]\ttrain-mlogloss:0.450454\ttest-mlogloss:0.521186\n",
      "[380]\ttrain-mlogloss:0.448574\ttest-mlogloss:0.520612\n",
      "[390]\ttrain-mlogloss:0.446525\ttest-mlogloss:0.520098\n",
      "[400]\ttrain-mlogloss:0.444502\ttest-mlogloss:0.519571\n",
      "[410]\ttrain-mlogloss:0.442545\ttest-mlogloss:0.519118\n",
      "[420]\ttrain-mlogloss:0.440751\ttest-mlogloss:0.518763\n",
      "[430]\ttrain-mlogloss:0.439002\ttest-mlogloss:0.518345\n",
      "[440]\ttrain-mlogloss:0.437284\ttest-mlogloss:0.518005\n",
      "[450]\ttrain-mlogloss:0.435531\ttest-mlogloss:0.517629\n",
      "[460]\ttrain-mlogloss:0.433831\ttest-mlogloss:0.517209\n",
      "[470]\ttrain-mlogloss:0.432256\ttest-mlogloss:0.516877\n",
      "[480]\ttrain-mlogloss:0.430702\ttest-mlogloss:0.516607\n",
      "[490]\ttrain-mlogloss:0.429177\ttest-mlogloss:0.516334\n",
      "[500]\ttrain-mlogloss:0.427422\ttest-mlogloss:0.516085\n",
      "[510]\ttrain-mlogloss:0.425667\ttest-mlogloss:0.51587\n",
      "[520]\ttrain-mlogloss:0.424137\ttest-mlogloss:0.515622\n",
      "[530]\ttrain-mlogloss:0.42257\ttest-mlogloss:0.515442\n",
      "[540]\ttrain-mlogloss:0.421006\ttest-mlogloss:0.51519\n",
      "[550]\ttrain-mlogloss:0.419482\ttest-mlogloss:0.514936\n",
      "[560]\ttrain-mlogloss:0.417851\ttest-mlogloss:0.514725\n",
      "[570]\ttrain-mlogloss:0.416251\ttest-mlogloss:0.514521\n",
      "[580]\ttrain-mlogloss:0.414791\ttest-mlogloss:0.514327\n",
      "[590]\ttrain-mlogloss:0.413362\ttest-mlogloss:0.514121\n",
      "[600]\ttrain-mlogloss:0.411683\ttest-mlogloss:0.513959\n",
      "[610]\ttrain-mlogloss:0.410178\ttest-mlogloss:0.513726\n",
      "[620]\ttrain-mlogloss:0.408777\ttest-mlogloss:0.513524\n",
      "[630]\ttrain-mlogloss:0.407295\ttest-mlogloss:0.51335\n",
      "[640]\ttrain-mlogloss:0.405811\ttest-mlogloss:0.513233\n",
      "[650]\ttrain-mlogloss:0.404269\ttest-mlogloss:0.513088\n",
      "[660]\ttrain-mlogloss:0.402777\ttest-mlogloss:0.512917\n",
      "[670]\ttrain-mlogloss:0.401301\ttest-mlogloss:0.512829\n",
      "[680]\ttrain-mlogloss:0.399838\ttest-mlogloss:0.512664\n",
      "[690]\ttrain-mlogloss:0.398579\ttest-mlogloss:0.512562\n",
      "[700]\ttrain-mlogloss:0.397361\ttest-mlogloss:0.512454\n",
      "[710]\ttrain-mlogloss:0.395878\ttest-mlogloss:0.512356\n",
      "[720]\ttrain-mlogloss:0.394436\ttest-mlogloss:0.512242\n",
      "[730]\ttrain-mlogloss:0.39297\ttest-mlogloss:0.512118\n",
      "[740]\ttrain-mlogloss:0.391621\ttest-mlogloss:0.511922\n",
      "[750]\ttrain-mlogloss:0.390257\ttest-mlogloss:0.511863\n",
      "[760]\ttrain-mlogloss:0.388889\ttest-mlogloss:0.511735\n",
      "[770]\ttrain-mlogloss:0.387483\ttest-mlogloss:0.511724\n",
      "[780]\ttrain-mlogloss:0.38618\ttest-mlogloss:0.511589\n",
      "[790]\ttrain-mlogloss:0.384818\ttest-mlogloss:0.511538\n",
      "[800]\ttrain-mlogloss:0.383441\ttest-mlogloss:0.511432\n",
      "[810]\ttrain-mlogloss:0.382183\ttest-mlogloss:0.511376\n",
      "[820]\ttrain-mlogloss:0.380818\ttest-mlogloss:0.511218\n",
      "[830]\ttrain-mlogloss:0.379419\ttest-mlogloss:0.511042\n",
      "[840]\ttrain-mlogloss:0.378202\ttest-mlogloss:0.511054\n",
      "[850]\ttrain-mlogloss:0.376865\ttest-mlogloss:0.510952\n",
      "[860]\ttrain-mlogloss:0.375577\ttest-mlogloss:0.510829\n",
      "[870]\ttrain-mlogloss:0.374348\ttest-mlogloss:0.510773\n",
      "[880]\ttrain-mlogloss:0.373018\ttest-mlogloss:0.510752\n",
      "[890]\ttrain-mlogloss:0.371695\ttest-mlogloss:0.510701\n",
      "[900]\ttrain-mlogloss:0.370489\ttest-mlogloss:0.51069\n",
      "[910]\ttrain-mlogloss:0.36922\ttest-mlogloss:0.510573\n",
      "[920]\ttrain-mlogloss:0.367806\ttest-mlogloss:0.510503\n",
      "[930]\ttrain-mlogloss:0.366697\ttest-mlogloss:0.510338\n",
      "[940]\ttrain-mlogloss:0.365362\ttest-mlogloss:0.510252\n",
      "[950]\ttrain-mlogloss:0.364021\ttest-mlogloss:0.510108\n",
      "[960]\ttrain-mlogloss:0.362816\ttest-mlogloss:0.510064\n",
      "[970]\ttrain-mlogloss:0.361495\ttest-mlogloss:0.51013\n",
      "[980]\ttrain-mlogloss:0.360267\ttest-mlogloss:0.51002\n",
      "[990]\ttrain-mlogloss:0.359232\ttest-mlogloss:0.510018\n",
      "[1000]\ttrain-mlogloss:0.358071\ttest-mlogloss:0.510004\n",
      "[1010]\ttrain-mlogloss:0.35679\ttest-mlogloss:0.509964\n",
      "[1020]\ttrain-mlogloss:0.355487\ttest-mlogloss:0.509963\n",
      "[1030]\ttrain-mlogloss:0.354268\ttest-mlogloss:0.509913\n",
      "[1040]\ttrain-mlogloss:0.353007\ttest-mlogloss:0.509873\n",
      "[1050]\ttrain-mlogloss:0.351679\ttest-mlogloss:0.509732\n",
      "[1060]\ttrain-mlogloss:0.350332\ttest-mlogloss:0.509697\n",
      "[1070]\ttrain-mlogloss:0.349067\ttest-mlogloss:0.509641\n",
      "[1080]\ttrain-mlogloss:0.347816\ttest-mlogloss:0.509628\n",
      "[1090]\ttrain-mlogloss:0.346688\ttest-mlogloss:0.50958\n",
      "[1100]\ttrain-mlogloss:0.345392\ttest-mlogloss:0.509475\n",
      "[1110]\ttrain-mlogloss:0.34414\ttest-mlogloss:0.509456\n",
      "[1120]\ttrain-mlogloss:0.342959\ttest-mlogloss:0.509421\n",
      "[1130]\ttrain-mlogloss:0.341838\ttest-mlogloss:0.509375\n",
      "[1140]\ttrain-mlogloss:0.340646\ttest-mlogloss:0.509398\n",
      "[1150]\ttrain-mlogloss:0.339491\ttest-mlogloss:0.509446\n",
      "[1160]\ttrain-mlogloss:0.338368\ttest-mlogloss:0.509361\n",
      "[1170]\ttrain-mlogloss:0.337234\ttest-mlogloss:0.509361\n",
      "[1180]\ttrain-mlogloss:0.336155\ttest-mlogloss:0.5093\n",
      "[1190]\ttrain-mlogloss:0.335098\ttest-mlogloss:0.509334\n",
      "[1200]\ttrain-mlogloss:0.333829\ttest-mlogloss:0.509274\n",
      "[1210]\ttrain-mlogloss:0.332686\ttest-mlogloss:0.50925\n",
      "[1220]\ttrain-mlogloss:0.331619\ttest-mlogloss:0.509188\n",
      "[1230]\ttrain-mlogloss:0.330469\ttest-mlogloss:0.509095\n",
      "[1240]\ttrain-mlogloss:0.329323\ttest-mlogloss:0.509113\n",
      "[1250]\ttrain-mlogloss:0.328212\ttest-mlogloss:0.509109\n",
      "[1260]\ttrain-mlogloss:0.327062\ttest-mlogloss:0.50907\n",
      "[1270]\ttrain-mlogloss:0.325915\ttest-mlogloss:0.50911\n",
      "[1280]\ttrain-mlogloss:0.324731\ttest-mlogloss:0.509145\n",
      "[1290]\ttrain-mlogloss:0.323593\ttest-mlogloss:0.50913\n",
      "[1300]\ttrain-mlogloss:0.322538\ttest-mlogloss:0.509103\n",
      "[1310]\ttrain-mlogloss:0.321477\ttest-mlogloss:0.509039\n",
      "[1320]\ttrain-mlogloss:0.32044\ttest-mlogloss:0.509092\n",
      "[1330]\ttrain-mlogloss:0.319377\ttest-mlogloss:0.509056\n",
      "[1340]\ttrain-mlogloss:0.318224\ttest-mlogloss:0.509061\n",
      "[1350]\ttrain-mlogloss:0.317133\ttest-mlogloss:0.509046\n",
      "[1360]\ttrain-mlogloss:0.316067\ttest-mlogloss:0.509089\n",
      "Stopping. Best iteration:\n",
      "[1311]\ttrain-mlogloss:0.321386\ttest-mlogloss:0.509025\n",
      "\n",
      "[0.50593702950354136, 0.50092266559477416, 0.51430512114807325, 0.50902529081389458]\n",
      "[0]\ttrain-mlogloss:1.08405\ttest-mlogloss:1.08432\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "[10]\ttrain-mlogloss:0.961148\ttest-mlogloss:0.964277\n",
      "[20]\ttrain-mlogloss:0.870388\ttest-mlogloss:0.876137\n",
      "[30]\ttrain-mlogloss:0.799929\ttest-mlogloss:0.808079\n",
      "[40]\ttrain-mlogloss:0.745274\ttest-mlogloss:0.755759\n",
      "[50]\ttrain-mlogloss:0.701664\ttest-mlogloss:0.714193\n",
      "[60]\ttrain-mlogloss:0.666117\ttest-mlogloss:0.680796\n",
      "[70]\ttrain-mlogloss:0.637518\ttest-mlogloss:0.654233\n",
      "[80]\ttrain-mlogloss:0.613946\ttest-mlogloss:0.632519\n",
      "[90]\ttrain-mlogloss:0.594514\ttest-mlogloss:0.615022\n",
      "[100]\ttrain-mlogloss:0.578386\ttest-mlogloss:0.600683\n",
      "[110]\ttrain-mlogloss:0.564983\ttest-mlogloss:0.588987\n",
      "[120]\ttrain-mlogloss:0.553199\ttest-mlogloss:0.57908\n",
      "[130]\ttrain-mlogloss:0.543236\ttest-mlogloss:0.570872\n",
      "[140]\ttrain-mlogloss:0.534648\ttest-mlogloss:0.563973\n",
      "[150]\ttrain-mlogloss:0.527059\ttest-mlogloss:0.558108\n",
      "[160]\ttrain-mlogloss:0.520401\ttest-mlogloss:0.553104\n",
      "[170]\ttrain-mlogloss:0.51441\ttest-mlogloss:0.548745\n",
      "[180]\ttrain-mlogloss:0.508854\ttest-mlogloss:0.54499\n",
      "[190]\ttrain-mlogloss:0.503967\ttest-mlogloss:0.541846\n",
      "[200]\ttrain-mlogloss:0.499391\ttest-mlogloss:0.538993\n",
      "[210]\ttrain-mlogloss:0.495349\ttest-mlogloss:0.536484\n",
      "[220]\ttrain-mlogloss:0.491474\ttest-mlogloss:0.534225\n",
      "[230]\ttrain-mlogloss:0.487973\ttest-mlogloss:0.532259\n",
      "[240]\ttrain-mlogloss:0.484443\ttest-mlogloss:0.530472\n",
      "[250]\ttrain-mlogloss:0.481059\ttest-mlogloss:0.528791\n",
      "[260]\ttrain-mlogloss:0.478067\ttest-mlogloss:0.527331\n",
      "[270]\ttrain-mlogloss:0.47528\ttest-mlogloss:0.525971\n",
      "[280]\ttrain-mlogloss:0.472403\ttest-mlogloss:0.524694\n",
      "[290]\ttrain-mlogloss:0.469659\ttest-mlogloss:0.52362\n",
      "[300]\ttrain-mlogloss:0.467\ttest-mlogloss:0.522562\n",
      "[310]\ttrain-mlogloss:0.464453\ttest-mlogloss:0.521599\n",
      "[320]\ttrain-mlogloss:0.461996\ttest-mlogloss:0.520706\n",
      "[330]\ttrain-mlogloss:0.459635\ttest-mlogloss:0.519778\n",
      "[340]\ttrain-mlogloss:0.457318\ttest-mlogloss:0.518949\n",
      "[350]\ttrain-mlogloss:0.455159\ttest-mlogloss:0.518217\n",
      "[360]\ttrain-mlogloss:0.452899\ttest-mlogloss:0.517581\n",
      "[370]\ttrain-mlogloss:0.450727\ttest-mlogloss:0.516949\n",
      "[380]\ttrain-mlogloss:0.4485\ttest-mlogloss:0.51638\n",
      "[390]\ttrain-mlogloss:0.446427\ttest-mlogloss:0.515797\n",
      "[400]\ttrain-mlogloss:0.4444\ttest-mlogloss:0.515357\n",
      "[410]\ttrain-mlogloss:0.442599\ttest-mlogloss:0.514848\n",
      "[420]\ttrain-mlogloss:0.440708\ttest-mlogloss:0.514396\n",
      "[430]\ttrain-mlogloss:0.438908\ttest-mlogloss:0.513933\n",
      "[440]\ttrain-mlogloss:0.437118\ttest-mlogloss:0.513568\n",
      "[450]\ttrain-mlogloss:0.435411\ttest-mlogloss:0.513185\n",
      "[460]\ttrain-mlogloss:0.433461\ttest-mlogloss:0.512785\n",
      "[470]\ttrain-mlogloss:0.431748\ttest-mlogloss:0.512469\n",
      "[480]\ttrain-mlogloss:0.430045\ttest-mlogloss:0.512195\n",
      "[490]\ttrain-mlogloss:0.428418\ttest-mlogloss:0.511887\n",
      "[500]\ttrain-mlogloss:0.426728\ttest-mlogloss:0.511558\n",
      "[510]\ttrain-mlogloss:0.425126\ttest-mlogloss:0.51113\n",
      "[520]\ttrain-mlogloss:0.423411\ttest-mlogloss:0.510837\n",
      "[530]\ttrain-mlogloss:0.42174\ttest-mlogloss:0.510637\n",
      "[540]\ttrain-mlogloss:0.420415\ttest-mlogloss:0.510376\n",
      "[550]\ttrain-mlogloss:0.418793\ttest-mlogloss:0.510196\n",
      "[560]\ttrain-mlogloss:0.417318\ttest-mlogloss:0.510013\n",
      "[570]\ttrain-mlogloss:0.415622\ttest-mlogloss:0.509769\n",
      "[580]\ttrain-mlogloss:0.414179\ttest-mlogloss:0.509632\n",
      "[590]\ttrain-mlogloss:0.412664\ttest-mlogloss:0.509426\n",
      "[600]\ttrain-mlogloss:0.411249\ttest-mlogloss:0.509284\n",
      "[610]\ttrain-mlogloss:0.409839\ttest-mlogloss:0.509089\n",
      "[620]\ttrain-mlogloss:0.408413\ttest-mlogloss:0.508921\n",
      "[630]\ttrain-mlogloss:0.406751\ttest-mlogloss:0.508711\n",
      "[640]\ttrain-mlogloss:0.405029\ttest-mlogloss:0.508519\n",
      "[650]\ttrain-mlogloss:0.403562\ttest-mlogloss:0.508368\n",
      "[660]\ttrain-mlogloss:0.402038\ttest-mlogloss:0.508143\n",
      "[670]\ttrain-mlogloss:0.400452\ttest-mlogloss:0.508012\n",
      "[680]\ttrain-mlogloss:0.398977\ttest-mlogloss:0.507924\n",
      "[690]\ttrain-mlogloss:0.397624\ttest-mlogloss:0.507816\n",
      "[700]\ttrain-mlogloss:0.396184\ttest-mlogloss:0.50768\n",
      "[710]\ttrain-mlogloss:0.394663\ttest-mlogloss:0.507574\n",
      "[720]\ttrain-mlogloss:0.393239\ttest-mlogloss:0.507513\n",
      "[730]\ttrain-mlogloss:0.39196\ttest-mlogloss:0.50738\n",
      "[740]\ttrain-mlogloss:0.390526\ttest-mlogloss:0.507355\n",
      "[750]\ttrain-mlogloss:0.389126\ttest-mlogloss:0.507252\n",
      "[760]\ttrain-mlogloss:0.387768\ttest-mlogloss:0.507015\n",
      "[770]\ttrain-mlogloss:0.386351\ttest-mlogloss:0.506904\n",
      "[780]\ttrain-mlogloss:0.384966\ttest-mlogloss:0.506823\n",
      "[790]\ttrain-mlogloss:0.383476\ttest-mlogloss:0.506765\n",
      "[800]\ttrain-mlogloss:0.382162\ttest-mlogloss:0.506666\n",
      "[810]\ttrain-mlogloss:0.380807\ttest-mlogloss:0.506575\n",
      "[820]\ttrain-mlogloss:0.379504\ttest-mlogloss:0.506471\n",
      "[830]\ttrain-mlogloss:0.378234\ttest-mlogloss:0.506423\n",
      "[840]\ttrain-mlogloss:0.376869\ttest-mlogloss:0.506346\n",
      "[850]\ttrain-mlogloss:0.375649\ttest-mlogloss:0.506169\n",
      "[860]\ttrain-mlogloss:0.374279\ttest-mlogloss:0.506064\n",
      "[870]\ttrain-mlogloss:0.373012\ttest-mlogloss:0.505987\n",
      "[880]\ttrain-mlogloss:0.371773\ttest-mlogloss:0.505902\n",
      "[890]\ttrain-mlogloss:0.37053\ttest-mlogloss:0.505824\n",
      "[900]\ttrain-mlogloss:0.369293\ttest-mlogloss:0.505776\n",
      "[910]\ttrain-mlogloss:0.36807\ttest-mlogloss:0.505698\n",
      "[920]\ttrain-mlogloss:0.366628\ttest-mlogloss:0.505693\n",
      "[930]\ttrain-mlogloss:0.365295\ttest-mlogloss:0.505618\n",
      "[940]\ttrain-mlogloss:0.364057\ttest-mlogloss:0.505495\n",
      "[950]\ttrain-mlogloss:0.362753\ttest-mlogloss:0.50545\n",
      "[960]\ttrain-mlogloss:0.361483\ttest-mlogloss:0.505398\n",
      "[970]\ttrain-mlogloss:0.36021\ttest-mlogloss:0.505307\n",
      "[980]\ttrain-mlogloss:0.358903\ttest-mlogloss:0.505296\n",
      "[990]\ttrain-mlogloss:0.357645\ttest-mlogloss:0.50522\n",
      "[1000]\ttrain-mlogloss:0.356376\ttest-mlogloss:0.505091\n",
      "[1010]\ttrain-mlogloss:0.355204\ttest-mlogloss:0.505102\n",
      "[1020]\ttrain-mlogloss:0.354033\ttest-mlogloss:0.505038\n",
      "[1030]\ttrain-mlogloss:0.352771\ttest-mlogloss:0.505047\n",
      "[1040]\ttrain-mlogloss:0.351625\ttest-mlogloss:0.504996\n",
      "[1050]\ttrain-mlogloss:0.35047\ttest-mlogloss:0.504953\n",
      "[1060]\ttrain-mlogloss:0.349202\ttest-mlogloss:0.504896\n",
      "[1070]\ttrain-mlogloss:0.347961\ttest-mlogloss:0.504809\n",
      "[1080]\ttrain-mlogloss:0.34674\ttest-mlogloss:0.504774\n",
      "[1090]\ttrain-mlogloss:0.345405\ttest-mlogloss:0.504734\n",
      "[1100]\ttrain-mlogloss:0.344086\ttest-mlogloss:0.504713\n",
      "[1110]\ttrain-mlogloss:0.343056\ttest-mlogloss:0.504675\n",
      "[1120]\ttrain-mlogloss:0.341795\ttest-mlogloss:0.504682\n",
      "[1130]\ttrain-mlogloss:0.340678\ttest-mlogloss:0.504642\n",
      "[1140]\ttrain-mlogloss:0.33961\ttest-mlogloss:0.504606\n",
      "[1150]\ttrain-mlogloss:0.33834\ttest-mlogloss:0.504601\n",
      "[1160]\ttrain-mlogloss:0.337054\ttest-mlogloss:0.504505\n",
      "[1170]\ttrain-mlogloss:0.335963\ttest-mlogloss:0.504455\n",
      "[1180]\ttrain-mlogloss:0.334808\ttest-mlogloss:0.504395\n",
      "[1190]\ttrain-mlogloss:0.333714\ttest-mlogloss:0.504358\n",
      "[1200]\ttrain-mlogloss:0.332564\ttest-mlogloss:0.504277\n",
      "[1210]\ttrain-mlogloss:0.331427\ttest-mlogloss:0.504271\n",
      "[1220]\ttrain-mlogloss:0.330265\ttest-mlogloss:0.504225\n",
      "[1230]\ttrain-mlogloss:0.329095\ttest-mlogloss:0.504201\n",
      "[1240]\ttrain-mlogloss:0.328079\ttest-mlogloss:0.504183\n",
      "[1250]\ttrain-mlogloss:0.326966\ttest-mlogloss:0.504196\n",
      "[1260]\ttrain-mlogloss:0.325917\ttest-mlogloss:0.504156\n",
      "[1270]\ttrain-mlogloss:0.324883\ttest-mlogloss:0.504157\n",
      "[1280]\ttrain-mlogloss:0.323703\ttest-mlogloss:0.50413\n",
      "[1290]\ttrain-mlogloss:0.322628\ttest-mlogloss:0.504104\n",
      "[1300]\ttrain-mlogloss:0.32155\ttest-mlogloss:0.504137\n",
      "[1310]\ttrain-mlogloss:0.320482\ttest-mlogloss:0.504109\n",
      "[1320]\ttrain-mlogloss:0.319325\ttest-mlogloss:0.504116\n",
      "[1330]\ttrain-mlogloss:0.318167\ttest-mlogloss:0.50412\n",
      "[1340]\ttrain-mlogloss:0.317055\ttest-mlogloss:0.50409\n",
      "[1350]\ttrain-mlogloss:0.315926\ttest-mlogloss:0.50407\n",
      "[1360]\ttrain-mlogloss:0.314961\ttest-mlogloss:0.504101\n",
      "[1370]\ttrain-mlogloss:0.313805\ttest-mlogloss:0.504064\n",
      "[1380]\ttrain-mlogloss:0.312716\ttest-mlogloss:0.504014\n",
      "[1390]\ttrain-mlogloss:0.311662\ttest-mlogloss:0.504086\n",
      "[1400]\ttrain-mlogloss:0.310658\ttest-mlogloss:0.504106\n",
      "[1410]\ttrain-mlogloss:0.309635\ttest-mlogloss:0.504036\n",
      "[1420]\ttrain-mlogloss:0.308494\ttest-mlogloss:0.504061\n",
      "Stopping. Best iteration:\n",
      "[1379]\ttrain-mlogloss:0.312806\ttest-mlogloss:0.504009\n",
      "\n",
      "[0.50593702950354136, 0.50092266559477416, 0.51430512114807325, 0.50902529081389458, 0.50400881779857165]\n",
      "0.50683995706\n"
     ]
    }
   ],
   "source": [
    "rv3 = run_cv(train_df, cv_test, kf, fl) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfs3 = run3_to_stackdf(rv3)\n",
    "pickle.dump(dfs3, open('modeloutput-xgb-clf.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_to_stackdf(run):\n",
    "    df_testpreds = pd.DataFrame(run[2].mean(axis=0))\n",
    "    df_testpreds.columns = ['level']\n",
    "    df_testpreds['listing_id'] = cv_test[0].listing_id\n",
    "    df_allpreds = pd.concat([run[1][['level', 'listing_id']], df_testpreds])\n",
    "\n",
    "    df_allpreds.sort_values('listing_id', inplace=True)\n",
    "    df_allpreds.set_index('listing_id', inplace=True)\n",
    "\n",
    "    df_fold = []\n",
    "    for f in range(run[2].shape[0]):\n",
    "        df_fold.append(pd.DataFrame(run[2][f]))\n",
    "        df_fold[-1]['listing_id'] = test_df.listing_id\n",
    "        df_fold[-1].sort_values('listing_id', inplace=True)\n",
    "        df_fold[-1].set_index('listing_id', inplace=True)\n",
    "\n",
    "    return (df_allpreds, df_fold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def runXGB1(train_X, train_y, test_X, test_y=None, feature_names=None, seed_val=0, num_rounds=4000):\n",
    "    param = {}\n",
    "    param['objective'] = 'reg:logistic'\n",
    "    #param['tree_method'] = 'hist'\n",
    "    param['eta'] = 0.02\n",
    "    param['max_depth'] = 6\n",
    "    param['silent'] = 1\n",
    "    param['num_class'] = 1\n",
    "    param['eval_metric'] = \"rmse\"\n",
    "    param['min_child_weight'] = 1\n",
    "    param['subsample'] = 0.7\n",
    "    param['colsample_bytree'] = 0.7\n",
    "    param['seed'] = seed_val\n",
    "    param['base_score'] = train_y.mean()\n",
    "    num_rounds = num_rounds\n",
    "\n",
    "    plst = list(param.items())\n",
    "    xgtrain = xgb.DMatrix(train_X, label=train_y)\n",
    "\n",
    "    if test_y is not None:\n",
    "        xgtest = xgb.DMatrix(test_X, label=test_y)\n",
    "        watchlist = [ (xgtrain,'train'), (xgtest, 'test') ]\n",
    "        model = xgb.train(plst, xgtrain, num_rounds, watchlist, early_stopping_rounds=50, verbose_eval=10)\n",
    "    else:\n",
    "        xgtest = xgb.DMatrix(test_X)\n",
    "        model = xgb.train(plst, xgtrain, num_rounds)\n",
    "\n",
    "    pred_test_y = model.predict(xgtest, ntree_limit=model.best_ntree_limit)\n",
    "    return pred_test_y, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "medium_regression_tgt = (.5 + (9/13)) / 2\n",
    "\n",
    "def run_cv1(train_df, cv_test, kf, features_to_use):\n",
    "    \n",
    "    train_X = train_df[features_to_use] #sparse.hstack([train_df[features_to_use], tr_sparse]).tocsr()\n",
    "    train_y3 = np.array(train_df['interest_level'].apply(lambda x: target_num_map[x]))\n",
    "    \n",
    "    train_y = np.zeros_like(train_y3, dtype=np.float32)\n",
    "    train_y[train_y3 == 1] = medium_regression_tgt\n",
    "    train_y[train_y3 == 2] = 1\n",
    "\n",
    "    cv_preds = []\n",
    "    cv_scores = []\n",
    "    models = []\n",
    "    test_preds = []\n",
    "    \n",
    "    fold = 0\n",
    "\n",
    "    for dev_index, val_index in kf.split(range(train_X.shape[0]), train_y):\n",
    "\n",
    "        dev_X, val_X = train_X.iloc[dev_index], train_X.iloc[val_index]\n",
    "        dev_y, val_y = train_y[dev_index], train_y[val_index]\n",
    "        preds, model = runXGB1(dev_X, dev_y, val_X, val_y)\n",
    "        models.append(model)\n",
    "\n",
    "        cv_scores.append(model.best_score)\n",
    "        print(cv_scores)\n",
    "\n",
    "        cut_df = train_df.iloc[val_index]\n",
    "        \n",
    "        out_df = pd.DataFrame(preds)\n",
    "        out_df.columns = [\"level\"]\n",
    "        out_df[\"listing_id\"] = cut_df.listing_id.values\n",
    "        out_df['interest_tgt'] = val_y # cut_df.interest.values\n",
    "\n",
    "        cv_preds.append(out_df)\n",
    "\n",
    "        xgtest = xgb.DMatrix(cv_test[fold][features_to_use])\n",
    "        test_preds.append(model.predict(xgtest, ntree_limit=model.best_ntree_limit))\n",
    "\n",
    "    df_cv = pd.concat(cv_preds)\n",
    "    print(np.sqrt(sklearn.metrics.mean_squared_error(df_cv.interest_tgt, df_cv.level)))\n",
    "    \n",
    "    apreds = np.array(test_preds)\n",
    "    \n",
    "    return models, df_cv, apreds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:0.334483\ttest-rmse:0.334523\n",
      "Multiple eval metrics have been passed: 'test-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until test-rmse hasn't improved in 50 rounds.\n",
      "[10]\ttrain-rmse:0.313981\ttest-rmse:0.314755\n",
      "[20]\ttrain-rmse:0.298413\ttest-rmse:0.299804\n",
      "[30]\ttrain-rmse:0.286126\ttest-rmse:0.288265\n",
      "[40]\ttrain-rmse:0.27618\ttest-rmse:0.278983\n",
      "[50]\ttrain-rmse:0.268765\ttest-rmse:0.272163\n",
      "[60]\ttrain-rmse:0.263497\ttest-rmse:0.267494\n",
      "[70]\ttrain-rmse:0.258939\ttest-rmse:0.263398\n",
      "[80]\ttrain-rmse:0.255294\ttest-rmse:0.260178\n",
      "[90]\ttrain-rmse:0.252345\ttest-rmse:0.257657\n",
      "[100]\ttrain-rmse:0.249963\ttest-rmse:0.255729\n",
      "[110]\ttrain-rmse:0.247915\ttest-rmse:0.254029\n",
      "[120]\ttrain-rmse:0.246146\ttest-rmse:0.252676\n",
      "[130]\ttrain-rmse:0.244603\ttest-rmse:0.251512\n",
      "[140]\ttrain-rmse:0.243268\ttest-rmse:0.250504\n",
      "[150]\ttrain-rmse:0.24198\ttest-rmse:0.249626\n",
      "[160]\ttrain-rmse:0.240862\ttest-rmse:0.248845\n",
      "[170]\ttrain-rmse:0.239945\ttest-rmse:0.24829\n",
      "[180]\ttrain-rmse:0.239108\ttest-rmse:0.247768\n",
      "[190]\ttrain-rmse:0.238226\ttest-rmse:0.247241\n",
      "[200]\ttrain-rmse:0.237444\ttest-rmse:0.246773\n",
      "[210]\ttrain-rmse:0.236599\ttest-rmse:0.246365\n",
      "[220]\ttrain-rmse:0.235836\ttest-rmse:0.245984\n",
      "[230]\ttrain-rmse:0.235163\ttest-rmse:0.245642\n",
      "[240]\ttrain-rmse:0.234549\ttest-rmse:0.245253\n",
      "[250]\ttrain-rmse:0.234051\ttest-rmse:0.244997\n",
      "[260]\ttrain-rmse:0.233433\ttest-rmse:0.244676\n",
      "[270]\ttrain-rmse:0.232805\ttest-rmse:0.244348\n",
      "[280]\ttrain-rmse:0.23223\ttest-rmse:0.244067\n",
      "[290]\ttrain-rmse:0.231591\ttest-rmse:0.243783\n",
      "[300]\ttrain-rmse:0.231055\ttest-rmse:0.243615\n",
      "[310]\ttrain-rmse:0.230575\ttest-rmse:0.243391\n",
      "[320]\ttrain-rmse:0.230193\ttest-rmse:0.24325\n",
      "[330]\ttrain-rmse:0.229752\ttest-rmse:0.243115\n",
      "[340]\ttrain-rmse:0.229248\ttest-rmse:0.242932\n",
      "[350]\ttrain-rmse:0.22862\ttest-rmse:0.242735\n",
      "[360]\ttrain-rmse:0.228082\ttest-rmse:0.242579\n",
      "[370]\ttrain-rmse:0.227556\ttest-rmse:0.242427\n",
      "[380]\ttrain-rmse:0.227041\ttest-rmse:0.242281\n",
      "[390]\ttrain-rmse:0.226469\ttest-rmse:0.242152\n",
      "[400]\ttrain-rmse:0.226004\ttest-rmse:0.242029\n",
      "[410]\ttrain-rmse:0.225458\ttest-rmse:0.241906\n",
      "[420]\ttrain-rmse:0.225053\ttest-rmse:0.24179\n",
      "[430]\ttrain-rmse:0.2247\ttest-rmse:0.241691\n",
      "[440]\ttrain-rmse:0.224174\ttest-rmse:0.241576\n",
      "[450]\ttrain-rmse:0.223844\ttest-rmse:0.241462\n",
      "[460]\ttrain-rmse:0.223416\ttest-rmse:0.241332\n",
      "[470]\ttrain-rmse:0.222986\ttest-rmse:0.241247\n",
      "[480]\ttrain-rmse:0.22256\ttest-rmse:0.241138\n",
      "[490]\ttrain-rmse:0.222141\ttest-rmse:0.241033\n",
      "[500]\ttrain-rmse:0.221695\ttest-rmse:0.240937\n",
      "[510]\ttrain-rmse:0.221309\ttest-rmse:0.240904\n",
      "[520]\ttrain-rmse:0.220911\ttest-rmse:0.240853\n",
      "[530]\ttrain-rmse:0.220537\ttest-rmse:0.240776\n",
      "[540]\ttrain-rmse:0.220113\ttest-rmse:0.240683\n",
      "[550]\ttrain-rmse:0.219797\ttest-rmse:0.240613\n",
      "[560]\ttrain-rmse:0.219423\ttest-rmse:0.240556\n",
      "[570]\ttrain-rmse:0.219002\ttest-rmse:0.240497\n",
      "[580]\ttrain-rmse:0.218586\ttest-rmse:0.240518\n",
      "[590]\ttrain-rmse:0.218216\ttest-rmse:0.240468\n",
      "[600]\ttrain-rmse:0.217754\ttest-rmse:0.24044\n",
      "[610]\ttrain-rmse:0.2174\ttest-rmse:0.240383\n",
      "[620]\ttrain-rmse:0.217061\ttest-rmse:0.240368\n",
      "[630]\ttrain-rmse:0.216666\ttest-rmse:0.240329\n",
      "[640]\ttrain-rmse:0.21609\ttest-rmse:0.240249\n",
      "[650]\ttrain-rmse:0.215752\ttest-rmse:0.240199\n",
      "[660]\ttrain-rmse:0.215344\ttest-rmse:0.240116\n",
      "[670]\ttrain-rmse:0.214947\ttest-rmse:0.240081\n",
      "[680]\ttrain-rmse:0.214533\ttest-rmse:0.240076\n",
      "[690]\ttrain-rmse:0.214053\ttest-rmse:0.240014\n",
      "[700]\ttrain-rmse:0.213651\ttest-rmse:0.239954\n",
      "[710]\ttrain-rmse:0.213213\ttest-rmse:0.239939\n",
      "[720]\ttrain-rmse:0.212875\ttest-rmse:0.239904\n",
      "[730]\ttrain-rmse:0.212428\ttest-rmse:0.239866\n",
      "[740]\ttrain-rmse:0.212036\ttest-rmse:0.239798\n",
      "[750]\ttrain-rmse:0.21167\ttest-rmse:0.239784\n",
      "[760]\ttrain-rmse:0.211328\ttest-rmse:0.239752\n",
      "[770]\ttrain-rmse:0.210822\ttest-rmse:0.239657\n",
      "[780]\ttrain-rmse:0.210405\ttest-rmse:0.239635\n",
      "[790]\ttrain-rmse:0.210003\ttest-rmse:0.23961\n",
      "[800]\ttrain-rmse:0.209626\ttest-rmse:0.239582\n",
      "[810]\ttrain-rmse:0.209218\ttest-rmse:0.239522\n",
      "[820]\ttrain-rmse:0.208853\ttest-rmse:0.239451\n",
      "[830]\ttrain-rmse:0.208481\ttest-rmse:0.239438\n",
      "[840]\ttrain-rmse:0.208112\ttest-rmse:0.239438\n",
      "[850]\ttrain-rmse:0.20768\ttest-rmse:0.239424\n",
      "[860]\ttrain-rmse:0.20721\ttest-rmse:0.239371\n",
      "[870]\ttrain-rmse:0.206819\ttest-rmse:0.239336\n",
      "[880]\ttrain-rmse:0.206463\ttest-rmse:0.239331\n",
      "[890]\ttrain-rmse:0.206086\ttest-rmse:0.239296\n",
      "[900]\ttrain-rmse:0.20567\ttest-rmse:0.239274\n",
      "[910]\ttrain-rmse:0.205222\ttest-rmse:0.239273\n",
      "[920]\ttrain-rmse:0.204798\ttest-rmse:0.239228\n",
      "[930]\ttrain-rmse:0.204459\ttest-rmse:0.239177\n",
      "[940]\ttrain-rmse:0.204056\ttest-rmse:0.239163\n",
      "[950]\ttrain-rmse:0.203791\ttest-rmse:0.239151\n",
      "[960]\ttrain-rmse:0.20341\ttest-rmse:0.239139\n",
      "[970]\ttrain-rmse:0.203068\ttest-rmse:0.23913\n",
      "[980]\ttrain-rmse:0.202755\ttest-rmse:0.239128\n",
      "[990]\ttrain-rmse:0.202401\ttest-rmse:0.239134\n",
      "[1000]\ttrain-rmse:0.202022\ttest-rmse:0.239099\n",
      "[1010]\ttrain-rmse:0.201671\ttest-rmse:0.239077\n",
      "[1020]\ttrain-rmse:0.201297\ttest-rmse:0.239042\n",
      "[1030]\ttrain-rmse:0.200882\ttest-rmse:0.239009\n",
      "[1040]\ttrain-rmse:0.200538\ttest-rmse:0.238979\n",
      "[1050]\ttrain-rmse:0.20023\ttest-rmse:0.238976\n",
      "[1060]\ttrain-rmse:0.199887\ttest-rmse:0.238969\n",
      "[1070]\ttrain-rmse:0.199542\ttest-rmse:0.238966\n",
      "[1080]\ttrain-rmse:0.199245\ttest-rmse:0.238951\n",
      "[1090]\ttrain-rmse:0.198883\ttest-rmse:0.238949\n",
      "[1100]\ttrain-rmse:0.198543\ttest-rmse:0.238929\n",
      "[1110]\ttrain-rmse:0.198145\ttest-rmse:0.238901\n",
      "[1120]\ttrain-rmse:0.197799\ttest-rmse:0.23889\n",
      "[1130]\ttrain-rmse:0.197478\ttest-rmse:0.238891\n",
      "[1140]\ttrain-rmse:0.197172\ttest-rmse:0.238882\n",
      "[1150]\ttrain-rmse:0.196827\ttest-rmse:0.238867\n",
      "[1160]\ttrain-rmse:0.196511\ttest-rmse:0.238845\n",
      "[1170]\ttrain-rmse:0.196203\ttest-rmse:0.238844\n",
      "[1180]\ttrain-rmse:0.195804\ttest-rmse:0.238806\n",
      "[1190]\ttrain-rmse:0.195452\ttest-rmse:0.238804\n",
      "[1200]\ttrain-rmse:0.195128\ttest-rmse:0.238787\n",
      "[1210]\ttrain-rmse:0.194898\ttest-rmse:0.23877\n",
      "[1220]\ttrain-rmse:0.19462\ttest-rmse:0.23877\n",
      "[1230]\ttrain-rmse:0.19425\ttest-rmse:0.23876\n",
      "[1240]\ttrain-rmse:0.193837\ttest-rmse:0.238764\n",
      "[1250]\ttrain-rmse:0.193554\ttest-rmse:0.23875\n",
      "[1260]\ttrain-rmse:0.193216\ttest-rmse:0.238734\n",
      "[1270]\ttrain-rmse:0.192863\ttest-rmse:0.238713\n",
      "[1280]\ttrain-rmse:0.192541\ttest-rmse:0.238686\n",
      "[1290]\ttrain-rmse:0.19224\ttest-rmse:0.238706\n",
      "[1300]\ttrain-rmse:0.191902\ttest-rmse:0.238699\n",
      "[1310]\ttrain-rmse:0.191547\ttest-rmse:0.238687\n",
      "[1320]\ttrain-rmse:0.191207\ttest-rmse:0.238699\n",
      "[1330]\ttrain-rmse:0.190867\ttest-rmse:0.238674\n",
      "[1340]\ttrain-rmse:0.190543\ttest-rmse:0.238697\n",
      "[1350]\ttrain-rmse:0.19021\ttest-rmse:0.238722\n",
      "Stopping. Best iteration:\n",
      "[1306]\ttrain-rmse:0.191675\ttest-rmse:0.23867\n",
      "\n",
      "[0.23867]\n",
      "[0]\ttrain-rmse:0.334444\ttest-rmse:0.334482\n",
      "Multiple eval metrics have been passed: 'test-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until test-rmse hasn't improved in 50 rounds.\n",
      "[10]\ttrain-rmse:0.314009\ttest-rmse:0.314302\n",
      "[20]\ttrain-rmse:0.29865\ttest-rmse:0.299383\n",
      "[30]\ttrain-rmse:0.286515\ttest-rmse:0.287706\n",
      "[40]\ttrain-rmse:0.276692\ttest-rmse:0.278343\n",
      "[50]\ttrain-rmse:0.269259\ttest-rmse:0.271424\n",
      "[60]\ttrain-rmse:0.263948\ttest-rmse:0.266573\n",
      "[70]\ttrain-rmse:0.259423\ttest-rmse:0.262534\n",
      "[80]\ttrain-rmse:0.255648\ttest-rmse:0.259232\n",
      "[90]\ttrain-rmse:0.252714\ttest-rmse:0.256699\n",
      "[100]\ttrain-rmse:0.250313\ttest-rmse:0.254746\n",
      "[110]\ttrain-rmse:0.248252\ttest-rmse:0.253013\n",
      "[120]\ttrain-rmse:0.246426\ttest-rmse:0.2516\n",
      "[130]\ttrain-rmse:0.244977\ttest-rmse:0.250547\n",
      "[140]\ttrain-rmse:0.243685\ttest-rmse:0.249656\n",
      "[150]\ttrain-rmse:0.242434\ttest-rmse:0.248801\n",
      "[160]\ttrain-rmse:0.24138\ttest-rmse:0.248135\n",
      "[170]\ttrain-rmse:0.240373\ttest-rmse:0.247471\n",
      "[180]\ttrain-rmse:0.239466\ttest-rmse:0.246904\n",
      "[190]\ttrain-rmse:0.238567\ttest-rmse:0.246384\n",
      "[200]\ttrain-rmse:0.237834\ttest-rmse:0.245912\n",
      "[210]\ttrain-rmse:0.237071\ttest-rmse:0.245512\n",
      "[220]\ttrain-rmse:0.23633\ttest-rmse:0.245181\n",
      "[230]\ttrain-rmse:0.235568\ttest-rmse:0.244802\n",
      "[240]\ttrain-rmse:0.234966\ttest-rmse:0.244548\n",
      "[250]\ttrain-rmse:0.234411\ttest-rmse:0.244266\n",
      "[260]\ttrain-rmse:0.23384\ttest-rmse:0.244025\n",
      "[270]\ttrain-rmse:0.23315\ttest-rmse:0.243746\n",
      "[280]\ttrain-rmse:0.232607\ttest-rmse:0.243591\n",
      "[290]\ttrain-rmse:0.23215\ttest-rmse:0.243435\n",
      "[300]\ttrain-rmse:0.231709\ttest-rmse:0.24328\n",
      "[310]\ttrain-rmse:0.231247\ttest-rmse:0.243121\n",
      "[320]\ttrain-rmse:0.230556\ttest-rmse:0.24292\n",
      "[330]\ttrain-rmse:0.230005\ttest-rmse:0.242696\n",
      "[340]\ttrain-rmse:0.229587\ttest-rmse:0.24257\n",
      "[350]\ttrain-rmse:0.229054\ttest-rmse:0.242365\n",
      "[360]\ttrain-rmse:0.228613\ttest-rmse:0.242236\n",
      "[370]\ttrain-rmse:0.228095\ttest-rmse:0.242124\n",
      "[380]\ttrain-rmse:0.227577\ttest-rmse:0.242012\n",
      "[390]\ttrain-rmse:0.227129\ttest-rmse:0.24193\n",
      "[400]\ttrain-rmse:0.226683\ttest-rmse:0.241793\n",
      "[410]\ttrain-rmse:0.226268\ttest-rmse:0.24166\n",
      "[420]\ttrain-rmse:0.225689\ttest-rmse:0.241536\n",
      "[430]\ttrain-rmse:0.225299\ttest-rmse:0.241478\n",
      "[440]\ttrain-rmse:0.224903\ttest-rmse:0.241388\n",
      "[450]\ttrain-rmse:0.22453\ttest-rmse:0.241337\n",
      "[460]\ttrain-rmse:0.22412\ttest-rmse:0.241271\n",
      "[470]\ttrain-rmse:0.223724\ttest-rmse:0.241238\n",
      "[480]\ttrain-rmse:0.223292\ttest-rmse:0.241159\n",
      "[490]\ttrain-rmse:0.222847\ttest-rmse:0.241088\n",
      "[500]\ttrain-rmse:0.222408\ttest-rmse:0.241004\n",
      "[510]\ttrain-rmse:0.221997\ttest-rmse:0.240956\n",
      "[520]\ttrain-rmse:0.221471\ttest-rmse:0.24088\n",
      "[530]\ttrain-rmse:0.221058\ttest-rmse:0.240827\n",
      "[540]\ttrain-rmse:0.220684\ttest-rmse:0.240778\n",
      "[550]\ttrain-rmse:0.220265\ttest-rmse:0.240726\n",
      "[560]\ttrain-rmse:0.21985\ttest-rmse:0.240677\n",
      "[570]\ttrain-rmse:0.219473\ttest-rmse:0.240635\n",
      "[580]\ttrain-rmse:0.219011\ttest-rmse:0.24056\n",
      "[590]\ttrain-rmse:0.218551\ttest-rmse:0.240522\n",
      "[600]\ttrain-rmse:0.218209\ttest-rmse:0.240479\n",
      "[610]\ttrain-rmse:0.217864\ttest-rmse:0.240449\n",
      "[620]\ttrain-rmse:0.217445\ttest-rmse:0.240364\n",
      "[630]\ttrain-rmse:0.217025\ttest-rmse:0.240317\n",
      "[640]\ttrain-rmse:0.216707\ttest-rmse:0.240261\n",
      "[650]\ttrain-rmse:0.216305\ttest-rmse:0.240232\n",
      "[660]\ttrain-rmse:0.215833\ttest-rmse:0.240199\n",
      "[670]\ttrain-rmse:0.21535\ttest-rmse:0.24016\n",
      "[680]\ttrain-rmse:0.214941\ttest-rmse:0.240112\n",
      "[690]\ttrain-rmse:0.214476\ttest-rmse:0.240027\n",
      "[700]\ttrain-rmse:0.214152\ttest-rmse:0.240012\n",
      "[710]\ttrain-rmse:0.213775\ttest-rmse:0.239964\n",
      "[720]\ttrain-rmse:0.213309\ttest-rmse:0.239887\n",
      "[730]\ttrain-rmse:0.212949\ttest-rmse:0.239825\n",
      "[740]\ttrain-rmse:0.212543\ttest-rmse:0.239813\n",
      "[750]\ttrain-rmse:0.212021\ttest-rmse:0.239767\n",
      "[760]\ttrain-rmse:0.211638\ttest-rmse:0.23974\n",
      "[770]\ttrain-rmse:0.211327\ttest-rmse:0.239707\n",
      "[780]\ttrain-rmse:0.210901\ttest-rmse:0.239672\n",
      "[790]\ttrain-rmse:0.210468\ttest-rmse:0.239638\n",
      "[800]\ttrain-rmse:0.210018\ttest-rmse:0.239612\n",
      "[810]\ttrain-rmse:0.20972\ttest-rmse:0.239614\n",
      "[820]\ttrain-rmse:0.209364\ttest-rmse:0.239586\n",
      "[830]\ttrain-rmse:0.209002\ttest-rmse:0.239582\n",
      "[840]\ttrain-rmse:0.20859\ttest-rmse:0.239524\n",
      "[850]\ttrain-rmse:0.208195\ttest-rmse:0.239506\n",
      "[860]\ttrain-rmse:0.207729\ttest-rmse:0.239453\n",
      "[870]\ttrain-rmse:0.207425\ttest-rmse:0.239453\n",
      "[880]\ttrain-rmse:0.207028\ttest-rmse:0.239411\n",
      "[890]\ttrain-rmse:0.206586\ttest-rmse:0.239398\n",
      "[900]\ttrain-rmse:0.206177\ttest-rmse:0.239371\n",
      "[910]\ttrain-rmse:0.205838\ttest-rmse:0.239337\n",
      "[920]\ttrain-rmse:0.205439\ttest-rmse:0.239287\n",
      "[930]\ttrain-rmse:0.205135\ttest-rmse:0.239275\n",
      "[940]\ttrain-rmse:0.204841\ttest-rmse:0.239265\n",
      "[950]\ttrain-rmse:0.204532\ttest-rmse:0.239238\n",
      "[960]\ttrain-rmse:0.204161\ttest-rmse:0.239202\n",
      "[970]\ttrain-rmse:0.203753\ttest-rmse:0.239179\n",
      "[980]\ttrain-rmse:0.203341\ttest-rmse:0.239165\n",
      "[990]\ttrain-rmse:0.202985\ttest-rmse:0.239134\n",
      "[1000]\ttrain-rmse:0.202564\ttest-rmse:0.239097\n",
      "[1010]\ttrain-rmse:0.202203\ttest-rmse:0.239079\n",
      "[1020]\ttrain-rmse:0.201787\ttest-rmse:0.23902\n",
      "[1030]\ttrain-rmse:0.201375\ttest-rmse:0.238989\n",
      "[1040]\ttrain-rmse:0.201004\ttest-rmse:0.23897\n",
      "[1050]\ttrain-rmse:0.200536\ttest-rmse:0.238907\n",
      "[1060]\ttrain-rmse:0.200218\ttest-rmse:0.238891\n",
      "[1070]\ttrain-rmse:0.199877\ttest-rmse:0.238858\n",
      "[1080]\ttrain-rmse:0.199547\ttest-rmse:0.238856\n",
      "[1090]\ttrain-rmse:0.199239\ttest-rmse:0.238836\n",
      "[1100]\ttrain-rmse:0.198892\ttest-rmse:0.238819\n",
      "[1110]\ttrain-rmse:0.198542\ttest-rmse:0.238781\n",
      "[1120]\ttrain-rmse:0.198167\ttest-rmse:0.238755\n",
      "[1130]\ttrain-rmse:0.197792\ttest-rmse:0.238745\n",
      "[1140]\ttrain-rmse:0.197487\ttest-rmse:0.238734\n",
      "[1150]\ttrain-rmse:0.197169\ttest-rmse:0.238716\n",
      "[1160]\ttrain-rmse:0.1968\ttest-rmse:0.238742\n",
      "[1170]\ttrain-rmse:0.196465\ttest-rmse:0.238753\n",
      "[1180]\ttrain-rmse:0.196098\ttest-rmse:0.23874\n",
      "[1190]\ttrain-rmse:0.195799\ttest-rmse:0.23872\n",
      "[1200]\ttrain-rmse:0.195396\ttest-rmse:0.238659\n",
      "[1210]\ttrain-rmse:0.194992\ttest-rmse:0.238683\n",
      "[1220]\ttrain-rmse:0.194694\ttest-rmse:0.238642\n",
      "[1230]\ttrain-rmse:0.194385\ttest-rmse:0.238571\n",
      "[1240]\ttrain-rmse:0.193979\ttest-rmse:0.23854\n",
      "[1250]\ttrain-rmse:0.193663\ttest-rmse:0.238571\n",
      "[1260]\ttrain-rmse:0.193329\ttest-rmse:0.238569\n",
      "[1270]\ttrain-rmse:0.192998\ttest-rmse:0.238547\n",
      "[1280]\ttrain-rmse:0.192619\ttest-rmse:0.238563\n",
      "Stopping. Best iteration:\n",
      "[1236]\ttrain-rmse:0.194106\ttest-rmse:0.238535\n",
      "\n",
      "[0.23867, 0.238535]\n",
      "[0]\ttrain-rmse:0.334355\ttest-rmse:0.334517\n",
      "Multiple eval metrics have been passed: 'test-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until test-rmse hasn't improved in 50 rounds.\n",
      "[10]\ttrain-rmse:0.313581\ttest-rmse:0.315226\n",
      "[20]\ttrain-rmse:0.297931\ttest-rmse:0.300946\n",
      "[30]\ttrain-rmse:0.285549\ttest-rmse:0.28983\n",
      "[40]\ttrain-rmse:0.27555\ttest-rmse:0.281061\n",
      "[50]\ttrain-rmse:0.268036\ttest-rmse:0.274553\n",
      "[60]\ttrain-rmse:0.262654\ttest-rmse:0.270064\n",
      "[70]\ttrain-rmse:0.258044\ttest-rmse:0.266257\n",
      "[80]\ttrain-rmse:0.254322\ttest-rmse:0.263194\n",
      "[90]\ttrain-rmse:0.251342\ttest-rmse:0.260813\n",
      "[100]\ttrain-rmse:0.248932\ttest-rmse:0.25896\n",
      "[110]\ttrain-rmse:0.246899\ttest-rmse:0.257375\n",
      "[120]\ttrain-rmse:0.245153\ttest-rmse:0.256146\n",
      "[130]\ttrain-rmse:0.243755\ttest-rmse:0.255189\n",
      "[140]\ttrain-rmse:0.242443\ttest-rmse:0.254311\n",
      "[150]\ttrain-rmse:0.241359\ttest-rmse:0.25358\n",
      "[160]\ttrain-rmse:0.240135\ttest-rmse:0.252845\n",
      "[170]\ttrain-rmse:0.239209\ttest-rmse:0.252306\n",
      "[180]\ttrain-rmse:0.238309\ttest-rmse:0.25176\n",
      "[190]\ttrain-rmse:0.237472\ttest-rmse:0.251311\n",
      "[200]\ttrain-rmse:0.236738\ttest-rmse:0.250877\n",
      "[210]\ttrain-rmse:0.236011\ttest-rmse:0.250471\n",
      "[220]\ttrain-rmse:0.235337\ttest-rmse:0.250091\n",
      "[230]\ttrain-rmse:0.234523\ttest-rmse:0.249709\n",
      "[240]\ttrain-rmse:0.233764\ttest-rmse:0.249345\n",
      "[250]\ttrain-rmse:0.233216\ttest-rmse:0.249088\n",
      "[260]\ttrain-rmse:0.232734\ttest-rmse:0.248857\n",
      "[270]\ttrain-rmse:0.232187\ttest-rmse:0.248614\n",
      "[280]\ttrain-rmse:0.231739\ttest-rmse:0.248407\n",
      "[290]\ttrain-rmse:0.231221\ttest-rmse:0.248212\n",
      "[300]\ttrain-rmse:0.230633\ttest-rmse:0.248022\n",
      "[310]\ttrain-rmse:0.23012\ttest-rmse:0.247845\n",
      "[320]\ttrain-rmse:0.229665\ttest-rmse:0.247673\n",
      "[330]\ttrain-rmse:0.229275\ttest-rmse:0.247509\n",
      "[340]\ttrain-rmse:0.228803\ttest-rmse:0.247329\n",
      "[350]\ttrain-rmse:0.228296\ttest-rmse:0.247207\n",
      "[360]\ttrain-rmse:0.22785\ttest-rmse:0.247046\n",
      "[370]\ttrain-rmse:0.227422\ttest-rmse:0.24691\n",
      "[380]\ttrain-rmse:0.226846\ttest-rmse:0.246779\n",
      "[390]\ttrain-rmse:0.226414\ttest-rmse:0.246665\n",
      "[400]\ttrain-rmse:0.225914\ttest-rmse:0.246563\n",
      "[410]\ttrain-rmse:0.225467\ttest-rmse:0.246443\n",
      "[420]\ttrain-rmse:0.225064\ttest-rmse:0.246352\n",
      "[430]\ttrain-rmse:0.224484\ttest-rmse:0.246271\n",
      "[440]\ttrain-rmse:0.22402\ttest-rmse:0.246163\n",
      "[450]\ttrain-rmse:0.22357\ttest-rmse:0.246078\n",
      "[460]\ttrain-rmse:0.22319\ttest-rmse:0.246019\n",
      "[470]\ttrain-rmse:0.222886\ttest-rmse:0.245944\n",
      "[480]\ttrain-rmse:0.222472\ttest-rmse:0.245844\n",
      "[490]\ttrain-rmse:0.221993\ttest-rmse:0.245709\n",
      "[500]\ttrain-rmse:0.221558\ttest-rmse:0.245584\n",
      "[510]\ttrain-rmse:0.221146\ttest-rmse:0.245537\n",
      "[520]\ttrain-rmse:0.220813\ttest-rmse:0.245513\n",
      "[530]\ttrain-rmse:0.220426\ttest-rmse:0.245436\n",
      "[540]\ttrain-rmse:0.219943\ttest-rmse:0.245306\n",
      "[550]\ttrain-rmse:0.219413\ttest-rmse:0.245201\n",
      "[560]\ttrain-rmse:0.218905\ttest-rmse:0.245116\n",
      "[570]\ttrain-rmse:0.218457\ttest-rmse:0.245059\n",
      "[580]\ttrain-rmse:0.218082\ttest-rmse:0.244991\n",
      "[590]\ttrain-rmse:0.217682\ttest-rmse:0.244913\n",
      "[600]\ttrain-rmse:0.217291\ttest-rmse:0.244819\n",
      "[610]\ttrain-rmse:0.216879\ttest-rmse:0.244741\n",
      "[620]\ttrain-rmse:0.216541\ttest-rmse:0.244694\n",
      "[630]\ttrain-rmse:0.216074\ttest-rmse:0.244605\n",
      "[640]\ttrain-rmse:0.215724\ttest-rmse:0.244582\n",
      "[650]\ttrain-rmse:0.215159\ttest-rmse:0.244541\n",
      "[660]\ttrain-rmse:0.214836\ttest-rmse:0.244497\n",
      "[670]\ttrain-rmse:0.214357\ttest-rmse:0.244423\n",
      "[680]\ttrain-rmse:0.213935\ttest-rmse:0.244348\n",
      "[690]\ttrain-rmse:0.213573\ttest-rmse:0.244309\n",
      "[700]\ttrain-rmse:0.213132\ttest-rmse:0.244275\n",
      "[710]\ttrain-rmse:0.212816\ttest-rmse:0.244216\n",
      "[720]\ttrain-rmse:0.212419\ttest-rmse:0.244199\n",
      "[730]\ttrain-rmse:0.212007\ttest-rmse:0.244164\n",
      "[740]\ttrain-rmse:0.211602\ttest-rmse:0.244105\n",
      "[750]\ttrain-rmse:0.21124\ttest-rmse:0.244059\n",
      "[760]\ttrain-rmse:0.210831\ttest-rmse:0.244035\n",
      "[770]\ttrain-rmse:0.210403\ttest-rmse:0.24399\n",
      "[780]\ttrain-rmse:0.210058\ttest-rmse:0.243971\n",
      "[790]\ttrain-rmse:0.209694\ttest-rmse:0.243925\n",
      "[800]\ttrain-rmse:0.209366\ttest-rmse:0.243879\n",
      "[810]\ttrain-rmse:0.20903\ttest-rmse:0.243852\n",
      "[820]\ttrain-rmse:0.208761\ttest-rmse:0.243836\n",
      "[830]\ttrain-rmse:0.208366\ttest-rmse:0.243806\n",
      "[840]\ttrain-rmse:0.207894\ttest-rmse:0.243793\n",
      "[850]\ttrain-rmse:0.207527\ttest-rmse:0.243764\n",
      "[860]\ttrain-rmse:0.207192\ttest-rmse:0.243766\n",
      "[870]\ttrain-rmse:0.206848\ttest-rmse:0.243749\n",
      "[880]\ttrain-rmse:0.206492\ttest-rmse:0.243691\n",
      "[890]\ttrain-rmse:0.206111\ttest-rmse:0.243676\n",
      "[900]\ttrain-rmse:0.205776\ttest-rmse:0.243654\n",
      "[910]\ttrain-rmse:0.205321\ttest-rmse:0.243615\n",
      "[920]\ttrain-rmse:0.20496\ttest-rmse:0.243607\n",
      "[930]\ttrain-rmse:0.204518\ttest-rmse:0.243542\n",
      "[940]\ttrain-rmse:0.204219\ttest-rmse:0.243533\n",
      "[950]\ttrain-rmse:0.203872\ttest-rmse:0.243513\n",
      "[960]\ttrain-rmse:0.203496\ttest-rmse:0.243471\n",
      "[970]\ttrain-rmse:0.203182\ttest-rmse:0.243461\n",
      "[980]\ttrain-rmse:0.202839\ttest-rmse:0.243443\n",
      "[990]\ttrain-rmse:0.202437\ttest-rmse:0.243428\n",
      "[1000]\ttrain-rmse:0.202052\ttest-rmse:0.243415\n",
      "[1010]\ttrain-rmse:0.201645\ttest-rmse:0.24335\n",
      "[1020]\ttrain-rmse:0.201275\ttest-rmse:0.243324\n",
      "[1030]\ttrain-rmse:0.200907\ttest-rmse:0.243337\n",
      "[1040]\ttrain-rmse:0.200557\ttest-rmse:0.243305\n",
      "[1050]\ttrain-rmse:0.200209\ttest-rmse:0.243263\n",
      "[1060]\ttrain-rmse:0.199884\ttest-rmse:0.243218\n",
      "[1070]\ttrain-rmse:0.199571\ttest-rmse:0.243186\n",
      "[1080]\ttrain-rmse:0.19922\ttest-rmse:0.243187\n",
      "[1090]\ttrain-rmse:0.198829\ttest-rmse:0.243171\n",
      "[1100]\ttrain-rmse:0.19846\ttest-rmse:0.243131\n",
      "[1110]\ttrain-rmse:0.198125\ttest-rmse:0.243098\n",
      "[1120]\ttrain-rmse:0.19772\ttest-rmse:0.24305\n",
      "[1130]\ttrain-rmse:0.197411\ttest-rmse:0.24305\n",
      "[1140]\ttrain-rmse:0.197058\ttest-rmse:0.243038\n",
      "[1150]\ttrain-rmse:0.196677\ttest-rmse:0.242983\n",
      "[1160]\ttrain-rmse:0.196303\ttest-rmse:0.242963\n",
      "[1170]\ttrain-rmse:0.195949\ttest-rmse:0.242972\n",
      "[1180]\ttrain-rmse:0.195638\ttest-rmse:0.242968\n",
      "[1190]\ttrain-rmse:0.195233\ttest-rmse:0.242945\n",
      "[1200]\ttrain-rmse:0.194914\ttest-rmse:0.242942\n",
      "[1210]\ttrain-rmse:0.194584\ttest-rmse:0.242948\n",
      "[1220]\ttrain-rmse:0.19432\ttest-rmse:0.242886\n",
      "[1230]\ttrain-rmse:0.194014\ttest-rmse:0.242937\n",
      "[1240]\ttrain-rmse:0.193599\ttest-rmse:0.242907\n",
      "[1250]\ttrain-rmse:0.19321\ttest-rmse:0.242956\n",
      "[1260]\ttrain-rmse:0.192901\ttest-rmse:0.242952\n",
      "[1270]\ttrain-rmse:0.192551\ttest-rmse:0.242917\n",
      "Stopping. Best iteration:\n",
      "[1220]\ttrain-rmse:0.19432\ttest-rmse:0.242886\n",
      "\n",
      "[0.23867, 0.238535, 0.242886]\n",
      "[0]\ttrain-rmse:0.334393\ttest-rmse:0.334486\n",
      "Multiple eval metrics have been passed: 'test-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until test-rmse hasn't improved in 50 rounds.\n",
      "[10]\ttrain-rmse:0.313851\ttest-rmse:0.314847\n",
      "[20]\ttrain-rmse:0.29814\ttest-rmse:0.300012\n",
      "[30]\ttrain-rmse:0.285874\ttest-rmse:0.28859\n",
      "[40]\ttrain-rmse:0.275913\ttest-rmse:0.279404\n",
      "[50]\ttrain-rmse:0.268549\ttest-rmse:0.272886\n",
      "[60]\ttrain-rmse:0.263192\ttest-rmse:0.268111\n",
      "[70]\ttrain-rmse:0.258552\ttest-rmse:0.264107\n",
      "[80]\ttrain-rmse:0.254887\ttest-rmse:0.261068\n",
      "[90]\ttrain-rmse:0.251843\ttest-rmse:0.2586\n",
      "[100]\ttrain-rmse:0.249513\ttest-rmse:0.256832\n",
      "[110]\ttrain-rmse:0.247415\ttest-rmse:0.255267\n",
      "[120]\ttrain-rmse:0.245641\ttest-rmse:0.253958\n",
      "[130]\ttrain-rmse:0.244156\ttest-rmse:0.252879\n",
      "[140]\ttrain-rmse:0.24277\ttest-rmse:0.25187\n",
      "[150]\ttrain-rmse:0.241578\ttest-rmse:0.251124\n",
      "[160]\ttrain-rmse:0.240431\ttest-rmse:0.250437\n",
      "[170]\ttrain-rmse:0.239512\ttest-rmse:0.249842\n",
      "[180]\ttrain-rmse:0.238672\ttest-rmse:0.249306\n",
      "[190]\ttrain-rmse:0.237816\ttest-rmse:0.248844\n",
      "[200]\ttrain-rmse:0.237011\ttest-rmse:0.248346\n",
      "[210]\ttrain-rmse:0.236307\ttest-rmse:0.24794\n",
      "[220]\ttrain-rmse:0.235674\ttest-rmse:0.247569\n",
      "[230]\ttrain-rmse:0.234936\ttest-rmse:0.247227\n",
      "[240]\ttrain-rmse:0.234303\ttest-rmse:0.246887\n",
      "[250]\ttrain-rmse:0.233742\ttest-rmse:0.246595\n",
      "[260]\ttrain-rmse:0.233263\ttest-rmse:0.246299\n",
      "[270]\ttrain-rmse:0.232718\ttest-rmse:0.246052\n",
      "[280]\ttrain-rmse:0.231995\ttest-rmse:0.245763\n",
      "[290]\ttrain-rmse:0.231427\ttest-rmse:0.245498\n",
      "[300]\ttrain-rmse:0.231001\ttest-rmse:0.245303\n",
      "[310]\ttrain-rmse:0.230494\ttest-rmse:0.245107\n",
      "[320]\ttrain-rmse:0.229973\ttest-rmse:0.2449\n",
      "[330]\ttrain-rmse:0.229496\ttest-rmse:0.244714\n",
      "[340]\ttrain-rmse:0.22901\ttest-rmse:0.244524\n",
      "[350]\ttrain-rmse:0.228551\ttest-rmse:0.244405\n",
      "[360]\ttrain-rmse:0.228079\ttest-rmse:0.244299\n",
      "[370]\ttrain-rmse:0.227565\ttest-rmse:0.244137\n",
      "[380]\ttrain-rmse:0.227047\ttest-rmse:0.243954\n",
      "[390]\ttrain-rmse:0.226562\ttest-rmse:0.243814\n",
      "[400]\ttrain-rmse:0.226063\ttest-rmse:0.243683\n",
      "[410]\ttrain-rmse:0.225511\ttest-rmse:0.243636\n",
      "[420]\ttrain-rmse:0.225084\ttest-rmse:0.243483\n",
      "[430]\ttrain-rmse:0.224689\ttest-rmse:0.243417\n",
      "[440]\ttrain-rmse:0.224412\ttest-rmse:0.243357\n",
      "[450]\ttrain-rmse:0.223968\ttest-rmse:0.243266\n",
      "[460]\ttrain-rmse:0.22364\ttest-rmse:0.243187\n",
      "[470]\ttrain-rmse:0.223211\ttest-rmse:0.243094\n",
      "[480]\ttrain-rmse:0.222887\ttest-rmse:0.243022\n",
      "[490]\ttrain-rmse:0.222512\ttest-rmse:0.24295\n",
      "[500]\ttrain-rmse:0.221957\ttest-rmse:0.242865\n",
      "[510]\ttrain-rmse:0.22144\ttest-rmse:0.242732\n",
      "[520]\ttrain-rmse:0.220969\ttest-rmse:0.242675\n",
      "[530]\ttrain-rmse:0.22056\ttest-rmse:0.242614\n",
      "[540]\ttrain-rmse:0.220238\ttest-rmse:0.242565\n",
      "[550]\ttrain-rmse:0.219814\ttest-rmse:0.242477\n",
      "[560]\ttrain-rmse:0.219402\ttest-rmse:0.242387\n",
      "[570]\ttrain-rmse:0.218977\ttest-rmse:0.242336\n",
      "[580]\ttrain-rmse:0.218508\ttest-rmse:0.242277\n",
      "[590]\ttrain-rmse:0.218064\ttest-rmse:0.242233\n",
      "[600]\ttrain-rmse:0.217666\ttest-rmse:0.242163\n",
      "[610]\ttrain-rmse:0.217245\ttest-rmse:0.242088\n",
      "[620]\ttrain-rmse:0.216914\ttest-rmse:0.242058\n",
      "[630]\ttrain-rmse:0.216545\ttest-rmse:0.242019\n",
      "[640]\ttrain-rmse:0.216144\ttest-rmse:0.241985\n",
      "[650]\ttrain-rmse:0.215685\ttest-rmse:0.241958\n",
      "[660]\ttrain-rmse:0.215262\ttest-rmse:0.241865\n",
      "[670]\ttrain-rmse:0.21493\ttest-rmse:0.241794\n",
      "[680]\ttrain-rmse:0.214539\ttest-rmse:0.241746\n",
      "[690]\ttrain-rmse:0.214096\ttest-rmse:0.241717\n",
      "[700]\ttrain-rmse:0.213709\ttest-rmse:0.241668\n",
      "[710]\ttrain-rmse:0.213342\ttest-rmse:0.24159\n",
      "[720]\ttrain-rmse:0.212997\ttest-rmse:0.241571\n",
      "[730]\ttrain-rmse:0.212586\ttest-rmse:0.241524\n",
      "[740]\ttrain-rmse:0.212228\ttest-rmse:0.241489\n",
      "[750]\ttrain-rmse:0.211862\ttest-rmse:0.241438\n",
      "[760]\ttrain-rmse:0.211473\ttest-rmse:0.241393\n",
      "[770]\ttrain-rmse:0.211005\ttest-rmse:0.241352\n",
      "[780]\ttrain-rmse:0.210726\ttest-rmse:0.241316\n",
      "[790]\ttrain-rmse:0.210261\ttest-rmse:0.241278\n",
      "[800]\ttrain-rmse:0.209954\ttest-rmse:0.241235\n",
      "[810]\ttrain-rmse:0.209601\ttest-rmse:0.241219\n",
      "[820]\ttrain-rmse:0.209273\ttest-rmse:0.241174\n",
      "[830]\ttrain-rmse:0.20894\ttest-rmse:0.241116\n",
      "[840]\ttrain-rmse:0.208549\ttest-rmse:0.241084\n",
      "[850]\ttrain-rmse:0.208165\ttest-rmse:0.241058\n",
      "[860]\ttrain-rmse:0.207829\ttest-rmse:0.241039\n",
      "[870]\ttrain-rmse:0.207569\ttest-rmse:0.241027\n",
      "[880]\ttrain-rmse:0.207214\ttest-rmse:0.24101\n",
      "[890]\ttrain-rmse:0.20687\ttest-rmse:0.240963\n",
      "[900]\ttrain-rmse:0.206535\ttest-rmse:0.240947\n",
      "[910]\ttrain-rmse:0.206099\ttest-rmse:0.240916\n",
      "[920]\ttrain-rmse:0.205783\ttest-rmse:0.240892\n",
      "[930]\ttrain-rmse:0.205445\ttest-rmse:0.240834\n",
      "[940]\ttrain-rmse:0.205022\ttest-rmse:0.240768\n",
      "[950]\ttrain-rmse:0.204663\ttest-rmse:0.240722\n",
      "[960]\ttrain-rmse:0.204289\ttest-rmse:0.240706\n",
      "[970]\ttrain-rmse:0.203911\ttest-rmse:0.240693\n",
      "[980]\ttrain-rmse:0.203496\ttest-rmse:0.240663\n",
      "[990]\ttrain-rmse:0.203214\ttest-rmse:0.240665\n",
      "[1000]\ttrain-rmse:0.202917\ttest-rmse:0.240626\n",
      "[1010]\ttrain-rmse:0.202523\ttest-rmse:0.240591\n",
      "[1020]\ttrain-rmse:0.202124\ttest-rmse:0.240579\n",
      "[1030]\ttrain-rmse:0.201661\ttest-rmse:0.240543\n",
      "[1040]\ttrain-rmse:0.201334\ttest-rmse:0.240501\n",
      "[1050]\ttrain-rmse:0.200931\ttest-rmse:0.240497\n",
      "[1060]\ttrain-rmse:0.200537\ttest-rmse:0.240513\n",
      "[1070]\ttrain-rmse:0.200164\ttest-rmse:0.240522\n",
      "[1080]\ttrain-rmse:0.19975\ttest-rmse:0.240511\n",
      "[1090]\ttrain-rmse:0.199314\ttest-rmse:0.240478\n",
      "[1100]\ttrain-rmse:0.199004\ttest-rmse:0.24049\n",
      "[1110]\ttrain-rmse:0.198659\ttest-rmse:0.24046\n",
      "[1120]\ttrain-rmse:0.1983\ttest-rmse:0.240474\n",
      "[1130]\ttrain-rmse:0.197921\ttest-rmse:0.240473\n",
      "[1140]\ttrain-rmse:0.197658\ttest-rmse:0.240456\n",
      "[1150]\ttrain-rmse:0.197349\ttest-rmse:0.240462\n",
      "[1160]\ttrain-rmse:0.197004\ttest-rmse:0.240456\n",
      "[1170]\ttrain-rmse:0.196703\ttest-rmse:0.240439\n",
      "[1180]\ttrain-rmse:0.196366\ttest-rmse:0.240432\n",
      "[1190]\ttrain-rmse:0.196035\ttest-rmse:0.240415\n",
      "[1200]\ttrain-rmse:0.195645\ttest-rmse:0.240395\n",
      "[1210]\ttrain-rmse:0.195331\ttest-rmse:0.240346\n",
      "[1220]\ttrain-rmse:0.194958\ttest-rmse:0.240331\n",
      "[1230]\ttrain-rmse:0.194678\ttest-rmse:0.240329\n",
      "[1240]\ttrain-rmse:0.194351\ttest-rmse:0.240325\n",
      "[1250]\ttrain-rmse:0.193997\ttest-rmse:0.240332\n",
      "[1260]\ttrain-rmse:0.193677\ttest-rmse:0.240326\n",
      "[1270]\ttrain-rmse:0.193371\ttest-rmse:0.24032\n",
      "[1280]\ttrain-rmse:0.193032\ttest-rmse:0.240321\n",
      "[1290]\ttrain-rmse:0.192623\ttest-rmse:0.240288\n",
      "[1300]\ttrain-rmse:0.192408\ttest-rmse:0.240295\n",
      "[1310]\ttrain-rmse:0.192048\ttest-rmse:0.240308\n",
      "[1320]\ttrain-rmse:0.191704\ttest-rmse:0.240268\n",
      "[1330]\ttrain-rmse:0.191354\ttest-rmse:0.24028\n",
      "[1340]\ttrain-rmse:0.191095\ttest-rmse:0.240252\n",
      "[1350]\ttrain-rmse:0.190776\ttest-rmse:0.240268\n",
      "[1360]\ttrain-rmse:0.190453\ttest-rmse:0.240265\n",
      "[1370]\ttrain-rmse:0.190197\ttest-rmse:0.24025\n",
      "[1380]\ttrain-rmse:0.189842\ttest-rmse:0.240244\n",
      "[1390]\ttrain-rmse:0.18945\ttest-rmse:0.240222\n",
      "[1400]\ttrain-rmse:0.189083\ttest-rmse:0.240164\n",
      "[1410]\ttrain-rmse:0.188683\ttest-rmse:0.240161\n",
      "[1420]\ttrain-rmse:0.188304\ttest-rmse:0.240155\n",
      "[1430]\ttrain-rmse:0.187896\ttest-rmse:0.240156\n",
      "[1440]\ttrain-rmse:0.187597\ttest-rmse:0.240156\n",
      "[1450]\ttrain-rmse:0.187271\ttest-rmse:0.240125\n",
      "[1460]\ttrain-rmse:0.186931\ttest-rmse:0.24011\n",
      "[1470]\ttrain-rmse:0.186682\ttest-rmse:0.240111\n",
      "[1480]\ttrain-rmse:0.186453\ttest-rmse:0.240102\n",
      "[1490]\ttrain-rmse:0.186138\ttest-rmse:0.240112\n",
      "[1500]\ttrain-rmse:0.185857\ttest-rmse:0.240091\n",
      "[1510]\ttrain-rmse:0.185507\ttest-rmse:0.240105\n",
      "[1520]\ttrain-rmse:0.185196\ttest-rmse:0.240068\n",
      "[1530]\ttrain-rmse:0.184912\ttest-rmse:0.240088\n",
      "[1540]\ttrain-rmse:0.184567\ttest-rmse:0.240093\n",
      "[1550]\ttrain-rmse:0.184302\ttest-rmse:0.240101\n",
      "[1560]\ttrain-rmse:0.184062\ttest-rmse:0.240093\n",
      "[1570]\ttrain-rmse:0.1838\ttest-rmse:0.240083\n",
      "Stopping. Best iteration:\n",
      "[1520]\ttrain-rmse:0.185196\ttest-rmse:0.240068\n",
      "\n",
      "[0.23867, 0.238535, 0.242886, 0.240068]\n",
      "[0]\ttrain-rmse:0.334012\ttest-rmse:0.334011\n",
      "Multiple eval metrics have been passed: 'test-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until test-rmse hasn't improved in 50 rounds.\n",
      "[10]\ttrain-rmse:0.312643\ttest-rmse:0.313244\n",
      "[20]\ttrain-rmse:0.296718\ttest-rmse:0.297891\n",
      "[30]\ttrain-rmse:0.284602\ttest-rmse:0.286402\n",
      "[40]\ttrain-rmse:0.275684\ttest-rmse:0.278018\n",
      "[50]\ttrain-rmse:0.268425\ttest-rmse:0.271298\n",
      "[60]\ttrain-rmse:0.26303\ttest-rmse:0.266401\n",
      "[70]\ttrain-rmse:0.258664\ttest-rmse:0.262518\n",
      "[80]\ttrain-rmse:0.255124\ttest-rmse:0.259486\n",
      "[90]\ttrain-rmse:0.252251\ttest-rmse:0.257054\n",
      "[100]\ttrain-rmse:0.249845\ttest-rmse:0.25511\n",
      "[110]\ttrain-rmse:0.247879\ttest-rmse:0.253532\n",
      "[120]\ttrain-rmse:0.246198\ttest-rmse:0.252219\n",
      "[130]\ttrain-rmse:0.244809\ttest-rmse:0.251142\n",
      "[140]\ttrain-rmse:0.243533\ttest-rmse:0.250182\n",
      "[150]\ttrain-rmse:0.24242\ttest-rmse:0.249386\n",
      "[160]\ttrain-rmse:0.241294\ttest-rmse:0.248613\n",
      "[170]\ttrain-rmse:0.240291\ttest-rmse:0.247963\n",
      "[180]\ttrain-rmse:0.239185\ttest-rmse:0.24729\n",
      "[190]\ttrain-rmse:0.238349\ttest-rmse:0.24676\n",
      "[200]\ttrain-rmse:0.237562\ttest-rmse:0.246288\n",
      "[210]\ttrain-rmse:0.236748\ttest-rmse:0.245821\n",
      "[220]\ttrain-rmse:0.235907\ttest-rmse:0.245368\n",
      "[230]\ttrain-rmse:0.23516\ttest-rmse:0.244967\n",
      "[240]\ttrain-rmse:0.234596\ttest-rmse:0.244644\n",
      "[250]\ttrain-rmse:0.234027\ttest-rmse:0.244346\n",
      "[260]\ttrain-rmse:0.233457\ttest-rmse:0.244069\n",
      "[270]\ttrain-rmse:0.232895\ttest-rmse:0.243826\n",
      "[280]\ttrain-rmse:0.232246\ttest-rmse:0.243577\n",
      "[290]\ttrain-rmse:0.2317\ttest-rmse:0.243359\n",
      "[300]\ttrain-rmse:0.231227\ttest-rmse:0.243205\n",
      "[310]\ttrain-rmse:0.230587\ttest-rmse:0.242972\n",
      "[320]\ttrain-rmse:0.230094\ttest-rmse:0.242787\n",
      "[330]\ttrain-rmse:0.229676\ttest-rmse:0.242652\n",
      "[340]\ttrain-rmse:0.229301\ttest-rmse:0.242521\n",
      "[350]\ttrain-rmse:0.228822\ttest-rmse:0.24233\n",
      "[360]\ttrain-rmse:0.228145\ttest-rmse:0.242155\n",
      "[370]\ttrain-rmse:0.227728\ttest-rmse:0.242088\n",
      "[380]\ttrain-rmse:0.227254\ttest-rmse:0.241975\n",
      "[390]\ttrain-rmse:0.226841\ttest-rmse:0.241831\n",
      "[400]\ttrain-rmse:0.226335\ttest-rmse:0.241688\n",
      "[410]\ttrain-rmse:0.225815\ttest-rmse:0.241556\n",
      "[420]\ttrain-rmse:0.225372\ttest-rmse:0.241474\n",
      "[430]\ttrain-rmse:0.22489\ttest-rmse:0.241345\n",
      "[440]\ttrain-rmse:0.224408\ttest-rmse:0.241273\n",
      "[450]\ttrain-rmse:0.223914\ttest-rmse:0.24114\n",
      "[460]\ttrain-rmse:0.223524\ttest-rmse:0.241053\n",
      "[470]\ttrain-rmse:0.223008\ttest-rmse:0.240978\n",
      "[480]\ttrain-rmse:0.222649\ttest-rmse:0.240897\n",
      "[490]\ttrain-rmse:0.222225\ttest-rmse:0.240785\n",
      "[500]\ttrain-rmse:0.221816\ttest-rmse:0.240689\n",
      "[510]\ttrain-rmse:0.221391\ttest-rmse:0.240636\n",
      "[520]\ttrain-rmse:0.220963\ttest-rmse:0.240554\n",
      "[530]\ttrain-rmse:0.220544\ttest-rmse:0.240472\n",
      "[540]\ttrain-rmse:0.219895\ttest-rmse:0.240372\n",
      "[550]\ttrain-rmse:0.219452\ttest-rmse:0.240342\n",
      "[560]\ttrain-rmse:0.218971\ttest-rmse:0.2403\n",
      "[570]\ttrain-rmse:0.218544\ttest-rmse:0.240226\n",
      "[580]\ttrain-rmse:0.218025\ttest-rmse:0.240122\n",
      "[590]\ttrain-rmse:0.21766\ttest-rmse:0.240094\n",
      "[600]\ttrain-rmse:0.217289\ttest-rmse:0.24003\n",
      "[610]\ttrain-rmse:0.216899\ttest-rmse:0.239974\n",
      "[620]\ttrain-rmse:0.216568\ttest-rmse:0.239932\n",
      "[630]\ttrain-rmse:0.216164\ttest-rmse:0.239888\n",
      "[640]\ttrain-rmse:0.215685\ttest-rmse:0.239852\n",
      "[650]\ttrain-rmse:0.215387\ttest-rmse:0.239819\n",
      "[660]\ttrain-rmse:0.214943\ttest-rmse:0.239773\n",
      "[670]\ttrain-rmse:0.214496\ttest-rmse:0.239774\n",
      "[680]\ttrain-rmse:0.214141\ttest-rmse:0.239749\n",
      "[690]\ttrain-rmse:0.213744\ttest-rmse:0.23972\n",
      "[700]\ttrain-rmse:0.213339\ttest-rmse:0.239675\n",
      "[710]\ttrain-rmse:0.212912\ttest-rmse:0.239631\n",
      "[720]\ttrain-rmse:0.212587\ttest-rmse:0.239572\n",
      "[730]\ttrain-rmse:0.212268\ttest-rmse:0.239538\n",
      "[740]\ttrain-rmse:0.211847\ttest-rmse:0.239511\n",
      "[750]\ttrain-rmse:0.211474\ttest-rmse:0.239447\n",
      "[760]\ttrain-rmse:0.211124\ttest-rmse:0.239423\n",
      "[770]\ttrain-rmse:0.210711\ttest-rmse:0.239366\n",
      "[780]\ttrain-rmse:0.210306\ttest-rmse:0.239318\n",
      "[790]\ttrain-rmse:0.209908\ttest-rmse:0.239295\n",
      "[800]\ttrain-rmse:0.209606\ttest-rmse:0.23927\n",
      "[810]\ttrain-rmse:0.209174\ttest-rmse:0.239245\n",
      "[820]\ttrain-rmse:0.208823\ttest-rmse:0.239213\n",
      "[830]\ttrain-rmse:0.208438\ttest-rmse:0.23915\n",
      "[840]\ttrain-rmse:0.208079\ttest-rmse:0.23914\n",
      "[850]\ttrain-rmse:0.207745\ttest-rmse:0.239097\n",
      "[860]\ttrain-rmse:0.207419\ttest-rmse:0.239076\n",
      "[870]\ttrain-rmse:0.207104\ttest-rmse:0.239045\n",
      "[880]\ttrain-rmse:0.206799\ttest-rmse:0.239013\n",
      "[890]\ttrain-rmse:0.206335\ttest-rmse:0.238999\n",
      "[900]\ttrain-rmse:0.206004\ttest-rmse:0.238972\n",
      "[910]\ttrain-rmse:0.205737\ttest-rmse:0.238968\n",
      "[920]\ttrain-rmse:0.205385\ttest-rmse:0.238944\n",
      "[930]\ttrain-rmse:0.204918\ttest-rmse:0.23894\n",
      "[940]\ttrain-rmse:0.204545\ttest-rmse:0.238915\n",
      "[950]\ttrain-rmse:0.204191\ttest-rmse:0.238876\n",
      "[960]\ttrain-rmse:0.203753\ttest-rmse:0.238854\n",
      "[970]\ttrain-rmse:0.203484\ttest-rmse:0.238837\n",
      "[980]\ttrain-rmse:0.203081\ttest-rmse:0.238824\n",
      "[990]\ttrain-rmse:0.202626\ttest-rmse:0.238829\n",
      "[1000]\ttrain-rmse:0.202303\ttest-rmse:0.238806\n",
      "[1010]\ttrain-rmse:0.201927\ttest-rmse:0.238781\n",
      "[1020]\ttrain-rmse:0.201545\ttest-rmse:0.238767\n",
      "[1030]\ttrain-rmse:0.20116\ttest-rmse:0.238761\n",
      "[1040]\ttrain-rmse:0.200831\ttest-rmse:0.238745\n",
      "[1050]\ttrain-rmse:0.200488\ttest-rmse:0.238756\n",
      "[1060]\ttrain-rmse:0.20013\ttest-rmse:0.238711\n",
      "[1070]\ttrain-rmse:0.199789\ttest-rmse:0.23869\n",
      "[1080]\ttrain-rmse:0.199418\ttest-rmse:0.238651\n",
      "[1090]\ttrain-rmse:0.199008\ttest-rmse:0.23864\n",
      "[1100]\ttrain-rmse:0.198709\ttest-rmse:0.238607\n",
      "[1110]\ttrain-rmse:0.198325\ttest-rmse:0.238599\n",
      "[1120]\ttrain-rmse:0.197975\ttest-rmse:0.23859\n",
      "[1130]\ttrain-rmse:0.197607\ttest-rmse:0.238559\n",
      "[1140]\ttrain-rmse:0.197142\ttest-rmse:0.238531\n",
      "[1150]\ttrain-rmse:0.196776\ttest-rmse:0.238506\n",
      "[1160]\ttrain-rmse:0.196393\ttest-rmse:0.238562\n",
      "[1170]\ttrain-rmse:0.196051\ttest-rmse:0.238536\n",
      "[1180]\ttrain-rmse:0.195707\ttest-rmse:0.238507\n",
      "[1190]\ttrain-rmse:0.195344\ttest-rmse:0.238503\n",
      "[1200]\ttrain-rmse:0.195022\ttest-rmse:0.238494\n",
      "[1210]\ttrain-rmse:0.19471\ttest-rmse:0.238462\n",
      "[1220]\ttrain-rmse:0.194392\ttest-rmse:0.238451\n",
      "[1230]\ttrain-rmse:0.194038\ttest-rmse:0.238449\n",
      "[1240]\ttrain-rmse:0.193688\ttest-rmse:0.238425\n",
      "[1250]\ttrain-rmse:0.193387\ttest-rmse:0.238405\n",
      "[1260]\ttrain-rmse:0.193087\ttest-rmse:0.238409\n",
      "[1270]\ttrain-rmse:0.192741\ttest-rmse:0.238401\n",
      "[1280]\ttrain-rmse:0.192407\ttest-rmse:0.238391\n",
      "[1290]\ttrain-rmse:0.192062\ttest-rmse:0.238378\n",
      "[1300]\ttrain-rmse:0.191751\ttest-rmse:0.238365\n",
      "[1310]\ttrain-rmse:0.191382\ttest-rmse:0.238349\n",
      "[1320]\ttrain-rmse:0.191169\ttest-rmse:0.238346\n",
      "[1330]\ttrain-rmse:0.190812\ttest-rmse:0.238354\n",
      "[1340]\ttrain-rmse:0.19044\ttest-rmse:0.238337\n",
      "[1350]\ttrain-rmse:0.190126\ttest-rmse:0.238337\n",
      "[1360]\ttrain-rmse:0.18986\ttest-rmse:0.23836\n",
      "[1370]\ttrain-rmse:0.189526\ttest-rmse:0.238339\n",
      "[1380]\ttrain-rmse:0.189064\ttest-rmse:0.238284\n",
      "[1390]\ttrain-rmse:0.188768\ttest-rmse:0.238272\n",
      "[1400]\ttrain-rmse:0.188471\ttest-rmse:0.238237\n",
      "[1410]\ttrain-rmse:0.188196\ttest-rmse:0.238244\n",
      "[1420]\ttrain-rmse:0.187886\ttest-rmse:0.23822\n",
      "[1430]\ttrain-rmse:0.187567\ttest-rmse:0.238199\n",
      "[1440]\ttrain-rmse:0.187225\ttest-rmse:0.238237\n",
      "[1450]\ttrain-rmse:0.186947\ttest-rmse:0.23826\n",
      "[1460]\ttrain-rmse:0.1866\ttest-rmse:0.238256\n",
      "[1470]\ttrain-rmse:0.186307\ttest-rmse:0.238256\n",
      "Stopping. Best iteration:\n",
      "[1425]\ttrain-rmse:0.18776\ttest-rmse:0.238196\n",
      "\n",
      "[0.23867, 0.238535, 0.242886, 0.240068, 0.238196]\n",
      "0.239677\n"
     ]
    }
   ],
   "source": [
    "rv1 = run_cv1(train_df, cv_test, kf, fl) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfs1 = run_to_stackdf(rv1)\n",
    "pickle.dump(dfs1, open('modeloutput-xgb-reg.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "_change_revision": 410,
  "_is_fork": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
