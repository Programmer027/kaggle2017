{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import operator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "import xgboost as xgb\n",
    "import random\n",
    "from sklearn import model_selection, preprocessing, ensemble\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "import pickle\n",
    "\n",
    "import sklearn.cluster\n",
    "\n",
    "import Levenshtein\n",
    "\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_pickle('fin-dprep-train.pkl')\n",
    "test_df = pd.read_pickle('fin-dprep-test.pkl')\n",
    "\n",
    "features_to_use = pickle.load(open('fin-dprep-flist.pkl', 'rb'))\n",
    "\n",
    "medium_price = pd.read_pickle('fin-medium-price.pkl')\n",
    "\n",
    "train_df = pd.merge(train_df, medium_price, left_on='listing_id', right_index=True)\n",
    "test_df = pd.merge(test_df, medium_price, left_on='listing_id', right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adams = pd.read_pickle('features-adams.pkl')\n",
    "\n",
    "train_df = pd.merge(train_df, adams, left_on='listing_id', right_index=True)\n",
    "test_df = pd.merge(test_df, adams, left_on='listing_id', right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df[\"predicted_price_diff\"] = np.log(train_df[\"price\"]) - np.log(train_df[\"predicted_price\"])\n",
    "test_df[\"predicted_price_diff\"] = np.log(test_df[\"price\"]) - np.log(test_df[\"predicted_price\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MeansProcessor:\n",
    "    def __init__(self, key, outkey = None, tgt = 'interest_cat'):\n",
    "        self.key = key\n",
    "        self.outkey = key if outkey is None else outkey\n",
    "        \n",
    "        self.count = {}\n",
    "        self.means = {}\n",
    "        self.std = {}\n",
    "        self.global_means = 0\n",
    "        \n",
    "        self.tgt = tgt\n",
    "        \n",
    "        self.outkeys = [self.outkey + '_level', self.outkey + '_level_std']\n",
    "        \n",
    "    def fit(self, df):\n",
    "        self.global_means = df[self.tgt].mean()\n",
    "            \n",
    "        for k in df.groupby(self.key, sort=False):\n",
    "            \n",
    "            self.count[k[0]] = len(k[1])\n",
    "\n",
    "            if len(k[1]) < 0:\n",
    "                self.means[k[0]] = np.nan\n",
    "                self.std[k[0]] = np.nan\n",
    "            else:\n",
    "                self.means[k[0]] = np.mean(k[1][self.tgt])\n",
    "                self.std[k[0]] = np.std(k[1][self.tgt])\n",
    "            \n",
    "    def predict(self, df):\n",
    "        for l in self.outkeys:\n",
    "            df[l] = np.nan # self.global_means[l]\n",
    "            \n",
    "        df[self.outkey + '_count'] = 0\n",
    "            \n",
    "        for k in df.groupby(self.key, sort=False):\n",
    "            if k[0] == 0:\n",
    "                continue\n",
    "            \n",
    "            if k[0] in self.means:\n",
    "                df.loc[k[1].index, self.outkey + '_count'] = self.count[k[0]]\n",
    "                df.loc[k[1].index, self.outkey + '_level'] = self.means[k[0]]\n",
    "                df.loc[k[1].index, self.outkey + '_level_std'] = self.std[k[0]]\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def get_features(self):\n",
    "        return self.outkeys.copy() + [self.outkey + '_count']\n",
    "\n",
    "# i kept the same index randomization (with fixed seed) so I could validate this code against\n",
    "# the original...\n",
    "\n",
    "target_num_map = {'low':0, 'medium':1, 'high':2}\n",
    "train_y = np.array(train_df['interest_level'].apply(lambda x: target_num_map[x]))\n",
    "\n",
    "def proc_fold(fold):\n",
    "    train_index = fold[0]\n",
    "    test_index = fold[1]\n",
    "    \n",
    "    cv_train = train_df.iloc[train_index]\n",
    "    cv_valid = train_df.iloc[test_index][['interest_level', 'manager_id', 'building_id']]\n",
    "    cv_test = test_df.copy()\n",
    "    \n",
    "    m_build = MeansProcessor('building_id', 'building_sort')\n",
    "    m_build.fit(cv_train)\n",
    "    cv_valid = m_build.predict(cv_valid)\n",
    "    cv_test = m_build.predict(cv_test)\n",
    "\n",
    "    m_mgr = MeansProcessor('manager_id', 'manager_sort')\n",
    "    m_mgr.fit(cv_train)\n",
    "    cv_valid = m_mgr.predict(cv_valid)\n",
    "    cv_test = m_mgr.predict(cv_test)\n",
    "\n",
    "    m_comb = MeansProcessor(['building_id', 'manager_id'], 'mb_comb')\n",
    "    m_comb.fit(cv_train)\n",
    "    cv_valid = m_comb.predict(cv_valid)\n",
    "    cv_test = m_comb.predict(cv_test)\n",
    "\n",
    "    return cv_train, cv_valid, cv_test\n",
    "\n",
    "kf = model_selection.StratifiedKFold(n_splits=5, shuffle=True, random_state=2016)\n",
    "folds = [(k[0], k[1]) for k in kf.split(list(range(train_df.shape[0])), train_y)]\n",
    "\n",
    "#with Pool(5) as pool:\n",
    "#    rv = pool.map(proc_fold, folds)\n",
    "\n",
    "import pickle\n",
    "\n",
    "try:\n",
    "    rv = pickle.load(open('0420-model-groupfeatures.pkl', 'rb'))\n",
    "except:\n",
    "    with Pool(5) as pool:\n",
    "        rv = pool.map(proc_fold, folds)\n",
    "\n",
    "        pickle.dump(rv, open('0420-model-groupfeatures.pkl', 'wb'))\n",
    "\n",
    "# dummies to get feature id's\n",
    "m_build = MeansProcessor('building_id', 'building_sort')\n",
    "m_mgr = MeansProcessor('manager_id', 'manager_sort')\n",
    "m_comb = MeansProcessor(['building_id', 'manager_id'], 'mb_comb')\n",
    "\n",
    "group_features = m_build.get_features() + m_mgr.get_features() + m_comb.get_features()\n",
    "\n",
    "cv_test = []\n",
    "for r in rv:\n",
    "    cv_test.append(test_df.merge(r[2][group_features], left_index=True, right_index=True))\n",
    "\n",
    "cv_allvalid = pd.concat([r[1] for r in rv])\n",
    "\n",
    "train_df = train_df.merge(cv_allvalid[group_features], left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_ids = []\n",
    "val_ids = []\n",
    "\n",
    "for dev_index, val_index in kf.split(range(train_df.shape[0]), train_df.interest_cat):\n",
    "    train_ids.append(train_df.iloc[dev_index].listing_id.values)\n",
    "    val_ids.append(train_df.iloc[val_index].listing_id.values)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adams_features = ['num_rot15_X', 'num_rot15_Y', 'num_rot30_X', 'num_rot30_Y', 'num_rot45_X', 'num_rot45_Y', 'num_rot60_X', 'num_rot60_Y', 'num_rho', 'num_phi', 'num_cap_share', 'num_nr_of_lines', 'num_redacted', 'num_email', 'num_phone_nr']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#fl = features_to_use + m_build.get_features() + m_mgr.get_features() + m_comb.get_features() + tfidf_fn\n",
    "\n",
    "fl = features_to_use.copy() + group_features + adams_features.copy()\n",
    "\n",
    "#fl.remove('price')\n",
    "#fl.remove('price_t')\n",
    "#fl.remove('price_per_room')\n",
    "fl.append('predicted_price')\n",
    "fl.append('predicted_price_diff')\n",
    "\n",
    "fl.append('manager_lazy_rate')\n",
    "\n",
    "fl.append('density_exp01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run3_to_stackdf(run):\n",
    "    \n",
    "    df_testpreds3 = pd.DataFrame(run[2].mean(axis=0))\n",
    "    df_testpreds3.columns = ['low', 'medium', 'high']\n",
    "    df_testpreds3['listing_id'] = test_df.listing_id\n",
    "\n",
    "    df_allpreds3 = pd.concat([run[1][['low', 'medium', 'high', 'listing_id']], df_testpreds3])\n",
    "\n",
    "    df_allpreds3.sort_values('listing_id', inplace=True)\n",
    "    df_allpreds3.set_index('listing_id', inplace=True)\n",
    "    \n",
    "    df_fold = []\n",
    "    for f in range(run[2].shape[0]):\n",
    "        df_fold.append(pd.DataFrame(run[2][f]))\n",
    "        df_fold[-1]['listing_id'] = test_df.listing_id\n",
    "        df_fold[-1].sort_values('listing_id', inplace=True)\n",
    "        df_fold[-1].set_index('listing_id', inplace=True)\n",
    "\n",
    "    return (df_allpreds3, df_fold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "15a46712-582b-28f7-1626-917cdab4f7e5",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def runXGB(train_X, train_y, test_X, test_y=None, feature_names=None, seed_val=0, num_rounds=4000):\n",
    "    param = {}\n",
    "    param['objective'] = 'multi:softprob'\n",
    "    #param['tree_method'] = 'hist'\n",
    "    param['eta'] = 0.02\n",
    "    param['max_depth'] = 6\n",
    "    param['silent'] = 1\n",
    "    param['num_class'] = 3\n",
    "    param['eval_metric'] = \"mlogloss\"\n",
    "    param['min_child_weight'] = 1\n",
    "    param['subsample'] = 0.7\n",
    "    param['colsample_bytree'] = 0.7\n",
    "    param['seed'] = seed_val\n",
    "    #param['base_score'] = [np.mean(train_y == i) for i in [0, 1, 2]]\n",
    "    num_rounds = num_rounds\n",
    "\n",
    "    plst = list(param.items())\n",
    "    xgtrain = xgb.DMatrix(train_X, label=train_y)\n",
    "\n",
    "    if test_y is not None:\n",
    "        xgtest = xgb.DMatrix(test_X, label=test_y)\n",
    "        watchlist = [ (xgtrain,'train'), (xgtest, 'test') ]\n",
    "        model = xgb.train(plst, xgtrain, num_rounds, watchlist, early_stopping_rounds=50, verbose_eval=10)\n",
    "    else:\n",
    "        xgtest = xgb.DMatrix(test_X)\n",
    "        model = xgb.train(plst, xgtrain, num_rounds)\n",
    "\n",
    "    pred_test_y = model.predict(xgtest, ntree_limit=model.best_ntree_limit)\n",
    "    return pred_test_y, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_cv(train_df, cv_test, kf, features_to_use):\n",
    "    train_X = train_df[features_to_use]\n",
    "    train_y = np.array(train_df['interest_level'].apply(lambda x: target_num_map[x]))\n",
    "\n",
    "    cv_preds = []\n",
    "    cv_scores = []\n",
    "    models = []\n",
    "    test_preds = []\n",
    "    \n",
    "    fold = 0\n",
    "\n",
    "    for dev_index, val_index in kf.split(range(train_X.shape[0]), train_y):\n",
    "\n",
    "        dev_X, val_X = train_X.iloc[dev_index], train_X.iloc[val_index]\n",
    "        dev_y, val_y = train_y[dev_index], train_y[val_index]\n",
    "        preds, model = runXGB(dev_X, dev_y, val_X, val_y)\n",
    "        models.append(model)\n",
    "\n",
    "        cv_scores.append(log_loss(val_y, preds))\n",
    "        print(cv_scores)\n",
    "\n",
    "        cut_df = train_df.iloc[val_index]\n",
    "        out_df = pd.DataFrame(preds)\n",
    "        out_df.columns = [\"low\", \"medium\", \"high\"]\n",
    "        out_df[\"listing_id\"] = cut_df.listing_id.values\n",
    "        interest = cut_df.interest_level.apply(lambda x: target_num_map[x])\n",
    "        out_df['interest_tgt'] = interest.values\n",
    "\n",
    "        cv_preds.append(out_df)\n",
    "\n",
    "        xgtest = xgb.DMatrix(cv_test[fold][features_to_use])\n",
    "        test_preds.append(model.predict(xgtest, ntree_limit=model.best_ntree_limit))\n",
    "\n",
    "    df_cv = pd.concat(cv_preds)\n",
    "    print(log_loss(df_cv.interest_tgt, df_cv[['low', 'medium', 'high']]))\n",
    "\n",
    "    apreds = np.array(test_preds)\n",
    "    \n",
    "    return models, df_cv, apreds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:1.08432\ttest-mlogloss:1.08449\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "[10]\ttrain-mlogloss:0.962911\ttest-mlogloss:0.965201\n",
      "[20]\ttrain-mlogloss:0.871901\ttest-mlogloss:0.876265\n",
      "[30]\ttrain-mlogloss:0.801269\ttest-mlogloss:0.808002\n",
      "[40]\ttrain-mlogloss:0.746058\ttest-mlogloss:0.755017\n",
      "[50]\ttrain-mlogloss:0.701655\ttest-mlogloss:0.712867\n",
      "[60]\ttrain-mlogloss:0.666381\ttest-mlogloss:0.679916\n",
      "[70]\ttrain-mlogloss:0.637632\ttest-mlogloss:0.653404\n",
      "[80]\ttrain-mlogloss:0.614002\ttest-mlogloss:0.63193\n",
      "[90]\ttrain-mlogloss:0.594618\ttest-mlogloss:0.614589\n",
      "[100]\ttrain-mlogloss:0.578171\ttest-mlogloss:0.600221\n",
      "[110]\ttrain-mlogloss:0.564296\ttest-mlogloss:0.588338\n",
      "[120]\ttrain-mlogloss:0.552398\ttest-mlogloss:0.578562\n",
      "[130]\ttrain-mlogloss:0.542329\ttest-mlogloss:0.570419\n",
      "[140]\ttrain-mlogloss:0.533656\ttest-mlogloss:0.563634\n",
      "[150]\ttrain-mlogloss:0.525917\ttest-mlogloss:0.557837\n",
      "[160]\ttrain-mlogloss:0.519254\ttest-mlogloss:0.553052\n",
      "[170]\ttrain-mlogloss:0.513068\ttest-mlogloss:0.548835\n",
      "[180]\ttrain-mlogloss:0.5074\ttest-mlogloss:0.54515\n",
      "[190]\ttrain-mlogloss:0.502382\ttest-mlogloss:0.541992\n",
      "[200]\ttrain-mlogloss:0.497765\ttest-mlogloss:0.539186\n",
      "[210]\ttrain-mlogloss:0.493544\ttest-mlogloss:0.536689\n",
      "[220]\ttrain-mlogloss:0.489681\ttest-mlogloss:0.534644\n",
      "[230]\ttrain-mlogloss:0.485965\ttest-mlogloss:0.532692\n",
      "[240]\ttrain-mlogloss:0.48223\ttest-mlogloss:0.530797\n",
      "[250]\ttrain-mlogloss:0.478801\ttest-mlogloss:0.529234\n",
      "[260]\ttrain-mlogloss:0.475695\ttest-mlogloss:0.52765\n",
      "[270]\ttrain-mlogloss:0.472806\ttest-mlogloss:0.526353\n",
      "[280]\ttrain-mlogloss:0.469957\ttest-mlogloss:0.525113\n",
      "[290]\ttrain-mlogloss:0.467192\ttest-mlogloss:0.523861\n",
      "[300]\ttrain-mlogloss:0.464531\ttest-mlogloss:0.522819\n",
      "[310]\ttrain-mlogloss:0.461778\ttest-mlogloss:0.521725\n",
      "[320]\ttrain-mlogloss:0.459104\ttest-mlogloss:0.520878\n",
      "[330]\ttrain-mlogloss:0.456656\ttest-mlogloss:0.52005\n",
      "[340]\ttrain-mlogloss:0.454204\ttest-mlogloss:0.51914\n",
      "[350]\ttrain-mlogloss:0.452022\ttest-mlogloss:0.518418\n",
      "[360]\ttrain-mlogloss:0.449853\ttest-mlogloss:0.517831\n",
      "[370]\ttrain-mlogloss:0.447809\ttest-mlogloss:0.517095\n",
      "[380]\ttrain-mlogloss:0.445656\ttest-mlogloss:0.516553\n",
      "[390]\ttrain-mlogloss:0.443569\ttest-mlogloss:0.515948\n",
      "[400]\ttrain-mlogloss:0.441326\ttest-mlogloss:0.515298\n",
      "[410]\ttrain-mlogloss:0.439254\ttest-mlogloss:0.514825\n",
      "[420]\ttrain-mlogloss:0.437488\ttest-mlogloss:0.514265\n",
      "[430]\ttrain-mlogloss:0.435727\ttest-mlogloss:0.513739\n",
      "[440]\ttrain-mlogloss:0.43385\ttest-mlogloss:0.513236\n",
      "[450]\ttrain-mlogloss:0.432221\ttest-mlogloss:0.512899\n",
      "[460]\ttrain-mlogloss:0.430429\ttest-mlogloss:0.512526\n",
      "[470]\ttrain-mlogloss:0.428606\ttest-mlogloss:0.512198\n",
      "[480]\ttrain-mlogloss:0.426832\ttest-mlogloss:0.511727\n",
      "[490]\ttrain-mlogloss:0.425156\ttest-mlogloss:0.511378\n",
      "[500]\ttrain-mlogloss:0.423472\ttest-mlogloss:0.511027\n",
      "[510]\ttrain-mlogloss:0.421743\ttest-mlogloss:0.510755\n",
      "[520]\ttrain-mlogloss:0.420175\ttest-mlogloss:0.51039\n",
      "[530]\ttrain-mlogloss:0.418246\ttest-mlogloss:0.510085\n",
      "[540]\ttrain-mlogloss:0.416516\ttest-mlogloss:0.509708\n",
      "[550]\ttrain-mlogloss:0.414979\ttest-mlogloss:0.509406\n",
      "[560]\ttrain-mlogloss:0.413243\ttest-mlogloss:0.5092\n",
      "[570]\ttrain-mlogloss:0.411786\ttest-mlogloss:0.508892\n",
      "[580]\ttrain-mlogloss:0.41014\ttest-mlogloss:0.508692\n",
      "[590]\ttrain-mlogloss:0.408549\ttest-mlogloss:0.508433\n",
      "[600]\ttrain-mlogloss:0.406845\ttest-mlogloss:0.508255\n",
      "[610]\ttrain-mlogloss:0.405321\ttest-mlogloss:0.508132\n",
      "[620]\ttrain-mlogloss:0.403746\ttest-mlogloss:0.507912\n",
      "[630]\ttrain-mlogloss:0.402207\ttest-mlogloss:0.507705\n",
      "[640]\ttrain-mlogloss:0.400684\ttest-mlogloss:0.50744\n",
      "[650]\ttrain-mlogloss:0.399047\ttest-mlogloss:0.507206\n",
      "[660]\ttrain-mlogloss:0.397445\ttest-mlogloss:0.507072\n",
      "[670]\ttrain-mlogloss:0.396096\ttest-mlogloss:0.506859\n",
      "[680]\ttrain-mlogloss:0.394609\ttest-mlogloss:0.506688\n",
      "[690]\ttrain-mlogloss:0.393189\ttest-mlogloss:0.506565\n",
      "[700]\ttrain-mlogloss:0.391682\ttest-mlogloss:0.506393\n",
      "[710]\ttrain-mlogloss:0.390214\ttest-mlogloss:0.506242\n",
      "[720]\ttrain-mlogloss:0.388487\ttest-mlogloss:0.50606\n",
      "[730]\ttrain-mlogloss:0.387119\ttest-mlogloss:0.505918\n",
      "[740]\ttrain-mlogloss:0.385535\ttest-mlogloss:0.505676\n",
      "[750]\ttrain-mlogloss:0.384108\ttest-mlogloss:0.505562\n",
      "[760]\ttrain-mlogloss:0.382565\ttest-mlogloss:0.505403\n",
      "[770]\ttrain-mlogloss:0.380991\ttest-mlogloss:0.505313\n",
      "[780]\ttrain-mlogloss:0.379531\ttest-mlogloss:0.505252\n",
      "[790]\ttrain-mlogloss:0.378101\ttest-mlogloss:0.505164\n",
      "[800]\ttrain-mlogloss:0.37659\ttest-mlogloss:0.505102\n",
      "[810]\ttrain-mlogloss:0.375326\ttest-mlogloss:0.504999\n",
      "[820]\ttrain-mlogloss:0.373948\ttest-mlogloss:0.504893\n",
      "[830]\ttrain-mlogloss:0.372438\ttest-mlogloss:0.504823\n",
      "[840]\ttrain-mlogloss:0.371038\ttest-mlogloss:0.504783\n",
      "[850]\ttrain-mlogloss:0.369633\ttest-mlogloss:0.504791\n",
      "[860]\ttrain-mlogloss:0.368449\ttest-mlogloss:0.504693\n",
      "[870]\ttrain-mlogloss:0.36682\ttest-mlogloss:0.504605\n",
      "[880]\ttrain-mlogloss:0.365495\ttest-mlogloss:0.504461\n",
      "[890]\ttrain-mlogloss:0.364141\ttest-mlogloss:0.504335\n",
      "[900]\ttrain-mlogloss:0.362703\ttest-mlogloss:0.504256\n",
      "[910]\ttrain-mlogloss:0.361289\ttest-mlogloss:0.504174\n",
      "[920]\ttrain-mlogloss:0.35985\ttest-mlogloss:0.504157\n",
      "[930]\ttrain-mlogloss:0.358496\ttest-mlogloss:0.504123\n",
      "[940]\ttrain-mlogloss:0.35712\ttest-mlogloss:0.504123\n",
      "[950]\ttrain-mlogloss:0.35585\ttest-mlogloss:0.503947\n",
      "[960]\ttrain-mlogloss:0.354482\ttest-mlogloss:0.50386\n",
      "[970]\ttrain-mlogloss:0.353212\ttest-mlogloss:0.503693\n",
      "[980]\ttrain-mlogloss:0.352057\ttest-mlogloss:0.503661\n",
      "[990]\ttrain-mlogloss:0.35076\ttest-mlogloss:0.50362\n",
      "[1000]\ttrain-mlogloss:0.349441\ttest-mlogloss:0.503661\n",
      "[1010]\ttrain-mlogloss:0.348221\ttest-mlogloss:0.50358\n",
      "[1020]\ttrain-mlogloss:0.346936\ttest-mlogloss:0.503423\n",
      "[1030]\ttrain-mlogloss:0.345785\ttest-mlogloss:0.503333\n",
      "[1040]\ttrain-mlogloss:0.344463\ttest-mlogloss:0.503298\n",
      "[1050]\ttrain-mlogloss:0.343177\ttest-mlogloss:0.503327\n",
      "[1060]\ttrain-mlogloss:0.34201\ttest-mlogloss:0.503289\n",
      "[1070]\ttrain-mlogloss:0.34052\ttest-mlogloss:0.503162\n",
      "[1080]\ttrain-mlogloss:0.339406\ttest-mlogloss:0.503061\n",
      "[1090]\ttrain-mlogloss:0.338066\ttest-mlogloss:0.503007\n",
      "[1100]\ttrain-mlogloss:0.336862\ttest-mlogloss:0.502914\n",
      "[1110]\ttrain-mlogloss:0.335566\ttest-mlogloss:0.502852\n",
      "[1120]\ttrain-mlogloss:0.334394\ttest-mlogloss:0.502863\n",
      "[1130]\ttrain-mlogloss:0.333257\ttest-mlogloss:0.502818\n",
      "[1140]\ttrain-mlogloss:0.332067\ttest-mlogloss:0.502785\n",
      "[1150]\ttrain-mlogloss:0.33091\ttest-mlogloss:0.502732\n",
      "[1160]\ttrain-mlogloss:0.329743\ttest-mlogloss:0.502731\n",
      "[1170]\ttrain-mlogloss:0.328404\ttest-mlogloss:0.502662\n",
      "[1180]\ttrain-mlogloss:0.327137\ttest-mlogloss:0.502578\n",
      "[1190]\ttrain-mlogloss:0.325885\ttest-mlogloss:0.502564\n",
      "[1200]\ttrain-mlogloss:0.324808\ttest-mlogloss:0.502514\n",
      "[1210]\ttrain-mlogloss:0.323617\ttest-mlogloss:0.502475\n",
      "[1220]\ttrain-mlogloss:0.322482\ttest-mlogloss:0.502458\n",
      "[1230]\ttrain-mlogloss:0.321218\ttest-mlogloss:0.502528\n",
      "[1240]\ttrain-mlogloss:0.32008\ttest-mlogloss:0.502448\n",
      "[1250]\ttrain-mlogloss:0.318936\ttest-mlogloss:0.502387\n",
      "[1260]\ttrain-mlogloss:0.317765\ttest-mlogloss:0.502336\n",
      "[1270]\ttrain-mlogloss:0.316588\ttest-mlogloss:0.502435\n",
      "[1280]\ttrain-mlogloss:0.315452\ttest-mlogloss:0.502382\n",
      "[1290]\ttrain-mlogloss:0.314374\ttest-mlogloss:0.502434\n",
      "[1300]\ttrain-mlogloss:0.313293\ttest-mlogloss:0.502423\n",
      "Stopping. Best iteration:\n",
      "[1259]\ttrain-mlogloss:0.317915\ttest-mlogloss:0.502319\n",
      "\n",
      "[0.50231927851655944]\n",
      "[0]\ttrain-mlogloss:1.08439\ttest-mlogloss:1.08457\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "[10]\ttrain-mlogloss:0.963619\ttest-mlogloss:0.965419\n",
      "[20]\ttrain-mlogloss:0.872794\ttest-mlogloss:0.876263\n",
      "[30]\ttrain-mlogloss:0.802338\ttest-mlogloss:0.807591\n",
      "[40]\ttrain-mlogloss:0.747317\ttest-mlogloss:0.75442\n",
      "[50]\ttrain-mlogloss:0.702878\ttest-mlogloss:0.71163\n",
      "[60]\ttrain-mlogloss:0.667767\ttest-mlogloss:0.678086\n",
      "[70]\ttrain-mlogloss:0.639129\ttest-mlogloss:0.651207\n",
      "[80]\ttrain-mlogloss:0.615568\ttest-mlogloss:0.629255\n",
      "[90]\ttrain-mlogloss:0.59613\ttest-mlogloss:0.61159\n",
      "[100]\ttrain-mlogloss:0.579654\ttest-mlogloss:0.596904\n",
      "[110]\ttrain-mlogloss:0.565763\ttest-mlogloss:0.584588\n",
      "[120]\ttrain-mlogloss:0.553995\ttest-mlogloss:0.574522\n",
      "[130]\ttrain-mlogloss:0.543846\ttest-mlogloss:0.566202\n",
      "[140]\ttrain-mlogloss:0.535004\ttest-mlogloss:0.559139\n",
      "[150]\ttrain-mlogloss:0.527273\ttest-mlogloss:0.553229\n",
      "[160]\ttrain-mlogloss:0.520444\ttest-mlogloss:0.548019\n",
      "[170]\ttrain-mlogloss:0.514467\ttest-mlogloss:0.543632\n",
      "[180]\ttrain-mlogloss:0.508843\ttest-mlogloss:0.539643\n",
      "[190]\ttrain-mlogloss:0.503855\ttest-mlogloss:0.536366\n",
      "[200]\ttrain-mlogloss:0.499355\ttest-mlogloss:0.53358\n",
      "[210]\ttrain-mlogloss:0.495045\ttest-mlogloss:0.530975\n",
      "[220]\ttrain-mlogloss:0.491196\ttest-mlogloss:0.52881\n",
      "[230]\ttrain-mlogloss:0.487471\ttest-mlogloss:0.526805\n",
      "[240]\ttrain-mlogloss:0.483995\ttest-mlogloss:0.524957\n",
      "[250]\ttrain-mlogloss:0.480824\ttest-mlogloss:0.523396\n",
      "[260]\ttrain-mlogloss:0.477903\ttest-mlogloss:0.521986\n",
      "[270]\ttrain-mlogloss:0.474995\ttest-mlogloss:0.520691\n",
      "[280]\ttrain-mlogloss:0.472122\ttest-mlogloss:0.519391\n",
      "[290]\ttrain-mlogloss:0.469268\ttest-mlogloss:0.518269\n",
      "[300]\ttrain-mlogloss:0.466706\ttest-mlogloss:0.517304\n",
      "[310]\ttrain-mlogloss:0.464328\ttest-mlogloss:0.51648\n",
      "[320]\ttrain-mlogloss:0.461877\ttest-mlogloss:0.515571\n",
      "[330]\ttrain-mlogloss:0.459321\ttest-mlogloss:0.514687\n",
      "[340]\ttrain-mlogloss:0.457074\ttest-mlogloss:0.513887\n",
      "[350]\ttrain-mlogloss:0.454664\ttest-mlogloss:0.513115\n",
      "[360]\ttrain-mlogloss:0.452316\ttest-mlogloss:0.512411\n",
      "[370]\ttrain-mlogloss:0.450227\ttest-mlogloss:0.511837\n",
      "[380]\ttrain-mlogloss:0.448259\ttest-mlogloss:0.511244\n",
      "[390]\ttrain-mlogloss:0.446219\ttest-mlogloss:0.510718\n",
      "[400]\ttrain-mlogloss:0.44415\ttest-mlogloss:0.510173\n",
      "[410]\ttrain-mlogloss:0.442232\ttest-mlogloss:0.509663\n",
      "[420]\ttrain-mlogloss:0.440249\ttest-mlogloss:0.509195\n",
      "[430]\ttrain-mlogloss:0.438356\ttest-mlogloss:0.508704\n",
      "[440]\ttrain-mlogloss:0.436526\ttest-mlogloss:0.508377\n",
      "[450]\ttrain-mlogloss:0.434651\ttest-mlogloss:0.507914\n",
      "[460]\ttrain-mlogloss:0.43274\ttest-mlogloss:0.507485\n",
      "[470]\ttrain-mlogloss:0.430954\ttest-mlogloss:0.507131\n",
      "[480]\ttrain-mlogloss:0.429222\ttest-mlogloss:0.506762\n",
      "[490]\ttrain-mlogloss:0.427387\ttest-mlogloss:0.506406\n",
      "[500]\ttrain-mlogloss:0.42556\ttest-mlogloss:0.506058\n",
      "[510]\ttrain-mlogloss:0.423956\ttest-mlogloss:0.505748\n",
      "[520]\ttrain-mlogloss:0.422301\ttest-mlogloss:0.505498\n",
      "[530]\ttrain-mlogloss:0.420497\ttest-mlogloss:0.505148\n",
      "[540]\ttrain-mlogloss:0.419006\ttest-mlogloss:0.504895\n",
      "[550]\ttrain-mlogloss:0.417292\ttest-mlogloss:0.504625\n",
      "[560]\ttrain-mlogloss:0.415726\ttest-mlogloss:0.504336\n",
      "[570]\ttrain-mlogloss:0.414203\ttest-mlogloss:0.504106\n",
      "[580]\ttrain-mlogloss:0.41246\ttest-mlogloss:0.503762\n",
      "[590]\ttrain-mlogloss:0.410893\ttest-mlogloss:0.503582\n",
      "[600]\ttrain-mlogloss:0.409182\ttest-mlogloss:0.503361\n",
      "[610]\ttrain-mlogloss:0.40772\ttest-mlogloss:0.503231\n",
      "[620]\ttrain-mlogloss:0.406125\ttest-mlogloss:0.503052\n",
      "[630]\ttrain-mlogloss:0.404573\ttest-mlogloss:0.502829\n",
      "[640]\ttrain-mlogloss:0.403036\ttest-mlogloss:0.502635\n",
      "[650]\ttrain-mlogloss:0.401523\ttest-mlogloss:0.50245\n",
      "[660]\ttrain-mlogloss:0.400031\ttest-mlogloss:0.502231\n",
      "[670]\ttrain-mlogloss:0.398478\ttest-mlogloss:0.502024\n",
      "[680]\ttrain-mlogloss:0.396996\ttest-mlogloss:0.501896\n",
      "[690]\ttrain-mlogloss:0.39552\ttest-mlogloss:0.501757\n",
      "[700]\ttrain-mlogloss:0.394062\ttest-mlogloss:0.501609\n",
      "[710]\ttrain-mlogloss:0.392646\ttest-mlogloss:0.501482\n",
      "[720]\ttrain-mlogloss:0.391114\ttest-mlogloss:0.501371\n",
      "[730]\ttrain-mlogloss:0.389477\ttest-mlogloss:0.50125\n",
      "[740]\ttrain-mlogloss:0.387982\ttest-mlogloss:0.501136\n",
      "[750]\ttrain-mlogloss:0.386486\ttest-mlogloss:0.500993\n",
      "[760]\ttrain-mlogloss:0.385004\ttest-mlogloss:0.500863\n",
      "[770]\ttrain-mlogloss:0.383541\ttest-mlogloss:0.500759\n",
      "[780]\ttrain-mlogloss:0.382163\ttest-mlogloss:0.500619\n",
      "[790]\ttrain-mlogloss:0.380758\ttest-mlogloss:0.500487\n",
      "[800]\ttrain-mlogloss:0.379524\ttest-mlogloss:0.500451\n",
      "[810]\ttrain-mlogloss:0.378151\ttest-mlogloss:0.500372\n",
      "[820]\ttrain-mlogloss:0.376807\ttest-mlogloss:0.500223\n",
      "[830]\ttrain-mlogloss:0.375559\ttest-mlogloss:0.500143\n",
      "[840]\ttrain-mlogloss:0.373986\ttest-mlogloss:0.500082\n",
      "[850]\ttrain-mlogloss:0.372618\ttest-mlogloss:0.500018\n",
      "[860]\ttrain-mlogloss:0.371348\ttest-mlogloss:0.499958\n",
      "[870]\ttrain-mlogloss:0.369911\ttest-mlogloss:0.499881\n",
      "[880]\ttrain-mlogloss:0.368672\ttest-mlogloss:0.499813\n",
      "[890]\ttrain-mlogloss:0.367341\ttest-mlogloss:0.499765\n",
      "[900]\ttrain-mlogloss:0.366001\ttest-mlogloss:0.49965\n",
      "[910]\ttrain-mlogloss:0.364541\ttest-mlogloss:0.499531\n",
      "[920]\ttrain-mlogloss:0.363174\ttest-mlogloss:0.499505\n",
      "[930]\ttrain-mlogloss:0.361759\ttest-mlogloss:0.499427\n",
      "[940]\ttrain-mlogloss:0.360428\ttest-mlogloss:0.499464\n",
      "[950]\ttrain-mlogloss:0.359149\ttest-mlogloss:0.499385\n",
      "[960]\ttrain-mlogloss:0.357968\ttest-mlogloss:0.499391\n",
      "[970]\ttrain-mlogloss:0.356623\ttest-mlogloss:0.499255\n",
      "[980]\ttrain-mlogloss:0.355306\ttest-mlogloss:0.499207\n",
      "[990]\ttrain-mlogloss:0.353882\ttest-mlogloss:0.499222\n",
      "[1000]\ttrain-mlogloss:0.352617\ttest-mlogloss:0.499154\n",
      "[1010]\ttrain-mlogloss:0.351409\ttest-mlogloss:0.499156\n",
      "[1020]\ttrain-mlogloss:0.350147\ttest-mlogloss:0.499045\n",
      "[1030]\ttrain-mlogloss:0.34897\ttest-mlogloss:0.498973\n",
      "[1040]\ttrain-mlogloss:0.347758\ttest-mlogloss:0.498882\n",
      "[1050]\ttrain-mlogloss:0.346547\ttest-mlogloss:0.498855\n",
      "[1060]\ttrain-mlogloss:0.345534\ttest-mlogloss:0.498839\n",
      "[1070]\ttrain-mlogloss:0.344211\ttest-mlogloss:0.498829\n",
      "[1080]\ttrain-mlogloss:0.342947\ttest-mlogloss:0.498875\n",
      "[1090]\ttrain-mlogloss:0.341608\ttest-mlogloss:0.498814\n",
      "[1100]\ttrain-mlogloss:0.340413\ttest-mlogloss:0.498727\n",
      "[1110]\ttrain-mlogloss:0.339085\ttest-mlogloss:0.498691\n",
      "[1120]\ttrain-mlogloss:0.337854\ttest-mlogloss:0.498693\n",
      "[1130]\ttrain-mlogloss:0.336573\ttest-mlogloss:0.498627\n",
      "[1140]\ttrain-mlogloss:0.335439\ttest-mlogloss:0.498638\n",
      "[1150]\ttrain-mlogloss:0.334341\ttest-mlogloss:0.498565\n",
      "[1160]\ttrain-mlogloss:0.333201\ttest-mlogloss:0.498523\n",
      "[1170]\ttrain-mlogloss:0.331987\ttest-mlogloss:0.498471\n",
      "[1180]\ttrain-mlogloss:0.330784\ttest-mlogloss:0.498404\n",
      "[1190]\ttrain-mlogloss:0.329713\ttest-mlogloss:0.498332\n",
      "[1200]\ttrain-mlogloss:0.328568\ttest-mlogloss:0.498337\n",
      "[1210]\ttrain-mlogloss:0.327377\ttest-mlogloss:0.498299\n",
      "[1220]\ttrain-mlogloss:0.326227\ttest-mlogloss:0.498203\n",
      "[1230]\ttrain-mlogloss:0.325056\ttest-mlogloss:0.49817\n",
      "[1240]\ttrain-mlogloss:0.323964\ttest-mlogloss:0.498127\n",
      "[1250]\ttrain-mlogloss:0.322897\ttest-mlogloss:0.498058\n",
      "[1260]\ttrain-mlogloss:0.321775\ttest-mlogloss:0.498072\n",
      "[1270]\ttrain-mlogloss:0.320643\ttest-mlogloss:0.498034\n",
      "[1280]\ttrain-mlogloss:0.319485\ttest-mlogloss:0.498027\n",
      "[1290]\ttrain-mlogloss:0.318415\ttest-mlogloss:0.498002\n",
      "[1300]\ttrain-mlogloss:0.317275\ttest-mlogloss:0.49798\n",
      "[1310]\ttrain-mlogloss:0.31609\ttest-mlogloss:0.497851\n",
      "[1320]\ttrain-mlogloss:0.314926\ttest-mlogloss:0.497807\n",
      "[1330]\ttrain-mlogloss:0.313965\ttest-mlogloss:0.497786\n",
      "[1340]\ttrain-mlogloss:0.31287\ttest-mlogloss:0.497706\n",
      "[1350]\ttrain-mlogloss:0.311729\ttest-mlogloss:0.497748\n",
      "[1360]\ttrain-mlogloss:0.310562\ttest-mlogloss:0.497786\n",
      "[1370]\ttrain-mlogloss:0.309455\ttest-mlogloss:0.497731\n",
      "[1380]\ttrain-mlogloss:0.308319\ttest-mlogloss:0.497693\n",
      "[1390]\ttrain-mlogloss:0.30722\ttest-mlogloss:0.497694\n",
      "[1400]\ttrain-mlogloss:0.306219\ttest-mlogloss:0.497741\n",
      "[1410]\ttrain-mlogloss:0.305098\ttest-mlogloss:0.497743\n",
      "[1420]\ttrain-mlogloss:0.303938\ttest-mlogloss:0.497693\n",
      "Stopping. Best iteration:\n",
      "[1377]\ttrain-mlogloss:0.308642\ttest-mlogloss:0.49767\n",
      "\n",
      "[0.50231927851655944, 0.49766997270751701]\n",
      "[0]\ttrain-mlogloss:1.08431\ttest-mlogloss:1.08476\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "[10]\ttrain-mlogloss:0.962679\ttest-mlogloss:0.967227\n",
      "[20]\ttrain-mlogloss:0.871248\ttest-mlogloss:0.87946\n",
      "[30]\ttrain-mlogloss:0.800171\ttest-mlogloss:0.811984\n",
      "[40]\ttrain-mlogloss:0.744861\ttest-mlogloss:0.759692\n",
      "[50]\ttrain-mlogloss:0.700276\ttest-mlogloss:0.718042\n",
      "[60]\ttrain-mlogloss:0.664751\ttest-mlogloss:0.685303\n",
      "[70]\ttrain-mlogloss:0.635967\ttest-mlogloss:0.659208\n",
      "[80]\ttrain-mlogloss:0.612232\ttest-mlogloss:0.637944\n",
      "[90]\ttrain-mlogloss:0.592612\ttest-mlogloss:0.620556\n",
      "[100]\ttrain-mlogloss:0.576045\ttest-mlogloss:0.60633\n",
      "[110]\ttrain-mlogloss:0.562108\ttest-mlogloss:0.594724\n",
      "[120]\ttrain-mlogloss:0.550187\ttest-mlogloss:0.584971\n",
      "[130]\ttrain-mlogloss:0.540006\ttest-mlogloss:0.576895\n",
      "[140]\ttrain-mlogloss:0.53126\ttest-mlogloss:0.570185\n",
      "[150]\ttrain-mlogloss:0.523529\ttest-mlogloss:0.564433\n",
      "[160]\ttrain-mlogloss:0.516782\ttest-mlogloss:0.559692\n",
      "[170]\ttrain-mlogloss:0.51066\ttest-mlogloss:0.555525\n",
      "[180]\ttrain-mlogloss:0.505269\ttest-mlogloss:0.55196\n",
      "[190]\ttrain-mlogloss:0.500184\ttest-mlogloss:0.548891\n",
      "[200]\ttrain-mlogloss:0.495649\ttest-mlogloss:0.546101\n",
      "[210]\ttrain-mlogloss:0.491543\ttest-mlogloss:0.543685\n",
      "[220]\ttrain-mlogloss:0.487629\ttest-mlogloss:0.541495\n",
      "[230]\ttrain-mlogloss:0.483929\ttest-mlogloss:0.539578\n",
      "[240]\ttrain-mlogloss:0.480565\ttest-mlogloss:0.537846\n",
      "[250]\ttrain-mlogloss:0.477315\ttest-mlogloss:0.536392\n",
      "[260]\ttrain-mlogloss:0.474079\ttest-mlogloss:0.534995\n",
      "[270]\ttrain-mlogloss:0.4713\ttest-mlogloss:0.53378\n",
      "[280]\ttrain-mlogloss:0.468514\ttest-mlogloss:0.532712\n",
      "[290]\ttrain-mlogloss:0.465679\ttest-mlogloss:0.5316\n",
      "[300]\ttrain-mlogloss:0.463125\ttest-mlogloss:0.530688\n",
      "[310]\ttrain-mlogloss:0.460677\ttest-mlogloss:0.529862\n",
      "[320]\ttrain-mlogloss:0.458124\ttest-mlogloss:0.528929\n",
      "[330]\ttrain-mlogloss:0.455666\ttest-mlogloss:0.528093\n",
      "[340]\ttrain-mlogloss:0.453238\ttest-mlogloss:0.527408\n",
      "[350]\ttrain-mlogloss:0.451076\ttest-mlogloss:0.526774\n",
      "[360]\ttrain-mlogloss:0.448773\ttest-mlogloss:0.526122\n",
      "[370]\ttrain-mlogloss:0.446306\ttest-mlogloss:0.525499\n",
      "[380]\ttrain-mlogloss:0.444211\ttest-mlogloss:0.524858\n",
      "[390]\ttrain-mlogloss:0.442146\ttest-mlogloss:0.524324\n",
      "[400]\ttrain-mlogloss:0.440019\ttest-mlogloss:0.523839\n",
      "[410]\ttrain-mlogloss:0.437939\ttest-mlogloss:0.523295\n",
      "[420]\ttrain-mlogloss:0.43591\ttest-mlogloss:0.522826\n",
      "[430]\ttrain-mlogloss:0.434083\ttest-mlogloss:0.522367\n",
      "[440]\ttrain-mlogloss:0.432162\ttest-mlogloss:0.521984\n",
      "[450]\ttrain-mlogloss:0.430234\ttest-mlogloss:0.521555\n",
      "[460]\ttrain-mlogloss:0.428296\ttest-mlogloss:0.521172\n",
      "[470]\ttrain-mlogloss:0.426646\ttest-mlogloss:0.520874\n",
      "[480]\ttrain-mlogloss:0.424938\ttest-mlogloss:0.52059\n",
      "[490]\ttrain-mlogloss:0.423176\ttest-mlogloss:0.520193\n",
      "[500]\ttrain-mlogloss:0.421415\ttest-mlogloss:0.519923\n",
      "[510]\ttrain-mlogloss:0.41956\ttest-mlogloss:0.519607\n",
      "[520]\ttrain-mlogloss:0.417841\ttest-mlogloss:0.519278\n",
      "[530]\ttrain-mlogloss:0.416335\ttest-mlogloss:0.51906\n",
      "[540]\ttrain-mlogloss:0.414498\ttest-mlogloss:0.518725\n",
      "[550]\ttrain-mlogloss:0.412828\ttest-mlogloss:0.518444\n",
      "[560]\ttrain-mlogloss:0.411052\ttest-mlogloss:0.518177\n",
      "[570]\ttrain-mlogloss:0.409329\ttest-mlogloss:0.517917\n",
      "[580]\ttrain-mlogloss:0.40792\ttest-mlogloss:0.5176\n",
      "[590]\ttrain-mlogloss:0.40641\ttest-mlogloss:0.517341\n",
      "[600]\ttrain-mlogloss:0.404802\ttest-mlogloss:0.517247\n",
      "[610]\ttrain-mlogloss:0.403251\ttest-mlogloss:0.516944\n",
      "[620]\ttrain-mlogloss:0.401522\ttest-mlogloss:0.516704\n",
      "[630]\ttrain-mlogloss:0.399769\ttest-mlogloss:0.516512\n",
      "[640]\ttrain-mlogloss:0.398225\ttest-mlogloss:0.516293\n",
      "[650]\ttrain-mlogloss:0.396819\ttest-mlogloss:0.516079\n",
      "[660]\ttrain-mlogloss:0.395257\ttest-mlogloss:0.515928\n",
      "[670]\ttrain-mlogloss:0.393573\ttest-mlogloss:0.515687\n",
      "[680]\ttrain-mlogloss:0.392049\ttest-mlogloss:0.515454\n",
      "[690]\ttrain-mlogloss:0.39064\ttest-mlogloss:0.515271\n",
      "[700]\ttrain-mlogloss:0.389209\ttest-mlogloss:0.51512\n",
      "[710]\ttrain-mlogloss:0.387758\ttest-mlogloss:0.514951\n",
      "[720]\ttrain-mlogloss:0.386391\ttest-mlogloss:0.514868\n",
      "[730]\ttrain-mlogloss:0.384904\ttest-mlogloss:0.514735\n",
      "[740]\ttrain-mlogloss:0.383548\ttest-mlogloss:0.514565\n",
      "[750]\ttrain-mlogloss:0.382238\ttest-mlogloss:0.514546\n",
      "[760]\ttrain-mlogloss:0.380795\ttest-mlogloss:0.514414\n",
      "[770]\ttrain-mlogloss:0.379292\ttest-mlogloss:0.514202\n",
      "[780]\ttrain-mlogloss:0.377871\ttest-mlogloss:0.514171\n",
      "[790]\ttrain-mlogloss:0.376491\ttest-mlogloss:0.514084\n",
      "[800]\ttrain-mlogloss:0.375078\ttest-mlogloss:0.513971\n",
      "[810]\ttrain-mlogloss:0.373729\ttest-mlogloss:0.513871\n",
      "[820]\ttrain-mlogloss:0.372445\ttest-mlogloss:0.513703\n",
      "[830]\ttrain-mlogloss:0.3711\ttest-mlogloss:0.513552\n",
      "[840]\ttrain-mlogloss:0.369685\ttest-mlogloss:0.5134\n",
      "[850]\ttrain-mlogloss:0.368388\ttest-mlogloss:0.513258\n",
      "[860]\ttrain-mlogloss:0.366973\ttest-mlogloss:0.513127\n",
      "[870]\ttrain-mlogloss:0.365668\ttest-mlogloss:0.513066\n",
      "[880]\ttrain-mlogloss:0.364351\ttest-mlogloss:0.512976\n",
      "[890]\ttrain-mlogloss:0.362902\ttest-mlogloss:0.512801\n",
      "[900]\ttrain-mlogloss:0.361531\ttest-mlogloss:0.512694\n",
      "[910]\ttrain-mlogloss:0.36025\ttest-mlogloss:0.512546\n",
      "[920]\ttrain-mlogloss:0.358874\ttest-mlogloss:0.512512\n",
      "[930]\ttrain-mlogloss:0.357674\ttest-mlogloss:0.512463\n",
      "[940]\ttrain-mlogloss:0.356478\ttest-mlogloss:0.512463\n",
      "[950]\ttrain-mlogloss:0.355048\ttest-mlogloss:0.512386\n",
      "[960]\ttrain-mlogloss:0.353705\ttest-mlogloss:0.512266\n",
      "[970]\ttrain-mlogloss:0.352349\ttest-mlogloss:0.512253\n",
      "[980]\ttrain-mlogloss:0.350901\ttest-mlogloss:0.512164\n",
      "[990]\ttrain-mlogloss:0.349733\ttest-mlogloss:0.512075\n",
      "[1000]\ttrain-mlogloss:0.348403\ttest-mlogloss:0.512024\n",
      "[1010]\ttrain-mlogloss:0.346921\ttest-mlogloss:0.511923\n",
      "[1020]\ttrain-mlogloss:0.345635\ttest-mlogloss:0.511836\n",
      "[1030]\ttrain-mlogloss:0.344337\ttest-mlogloss:0.511741\n",
      "[1040]\ttrain-mlogloss:0.343103\ttest-mlogloss:0.511689\n",
      "[1050]\ttrain-mlogloss:0.341809\ttest-mlogloss:0.511631\n",
      "[1060]\ttrain-mlogloss:0.340664\ttest-mlogloss:0.511553\n",
      "[1070]\ttrain-mlogloss:0.339449\ttest-mlogloss:0.511442\n",
      "[1080]\ttrain-mlogloss:0.338213\ttest-mlogloss:0.511285\n",
      "[1090]\ttrain-mlogloss:0.336866\ttest-mlogloss:0.511274\n",
      "[1100]\ttrain-mlogloss:0.335756\ttest-mlogloss:0.511262\n",
      "[1110]\ttrain-mlogloss:0.33448\ttest-mlogloss:0.511151\n",
      "[1120]\ttrain-mlogloss:0.333339\ttest-mlogloss:0.510987\n",
      "[1130]\ttrain-mlogloss:0.3321\ttest-mlogloss:0.510897\n",
      "[1140]\ttrain-mlogloss:0.330988\ttest-mlogloss:0.51085\n",
      "[1150]\ttrain-mlogloss:0.3298\ttest-mlogloss:0.510789\n",
      "[1160]\ttrain-mlogloss:0.328664\ttest-mlogloss:0.510754\n",
      "[1170]\ttrain-mlogloss:0.327435\ttest-mlogloss:0.510674\n",
      "[1180]\ttrain-mlogloss:0.326348\ttest-mlogloss:0.510697\n",
      "[1190]\ttrain-mlogloss:0.325299\ttest-mlogloss:0.510653\n",
      "[1200]\ttrain-mlogloss:0.324052\ttest-mlogloss:0.510549\n",
      "[1210]\ttrain-mlogloss:0.322822\ttest-mlogloss:0.510566\n",
      "[1220]\ttrain-mlogloss:0.32163\ttest-mlogloss:0.510471\n",
      "[1230]\ttrain-mlogloss:0.32057\ttest-mlogloss:0.510434\n",
      "[1240]\ttrain-mlogloss:0.319367\ttest-mlogloss:0.510428\n",
      "[1250]\ttrain-mlogloss:0.318204\ttest-mlogloss:0.510389\n",
      "[1260]\ttrain-mlogloss:0.316989\ttest-mlogloss:0.510348\n",
      "[1270]\ttrain-mlogloss:0.315772\ttest-mlogloss:0.510302\n",
      "[1280]\ttrain-mlogloss:0.314591\ttest-mlogloss:0.510268\n",
      "[1290]\ttrain-mlogloss:0.313569\ttest-mlogloss:0.51025\n",
      "[1300]\ttrain-mlogloss:0.312384\ttest-mlogloss:0.510271\n",
      "[1310]\ttrain-mlogloss:0.311255\ttest-mlogloss:0.51023\n",
      "[1320]\ttrain-mlogloss:0.31003\ttest-mlogloss:0.510262\n",
      "[1330]\ttrain-mlogloss:0.308905\ttest-mlogloss:0.510158\n",
      "[1340]\ttrain-mlogloss:0.307737\ttest-mlogloss:0.510106\n",
      "[1350]\ttrain-mlogloss:0.306715\ttest-mlogloss:0.510003\n",
      "[1360]\ttrain-mlogloss:0.305657\ttest-mlogloss:0.510008\n",
      "[1370]\ttrain-mlogloss:0.304645\ttest-mlogloss:0.510041\n",
      "[1380]\ttrain-mlogloss:0.303579\ttest-mlogloss:0.510034\n",
      "[1390]\ttrain-mlogloss:0.302515\ttest-mlogloss:0.510048\n",
      "[1400]\ttrain-mlogloss:0.301491\ttest-mlogloss:0.510041\n",
      "Stopping. Best iteration:\n",
      "[1353]\ttrain-mlogloss:0.306367\ttest-mlogloss:0.509964\n",
      "\n",
      "[0.50231927851655944, 0.49766997270751701, 0.5099642237087797]\n",
      "[0]\ttrain-mlogloss:1.08433\ttest-mlogloss:1.08476\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "[10]\ttrain-mlogloss:0.962748\ttest-mlogloss:0.96671\n",
      "[20]\ttrain-mlogloss:0.871461\ttest-mlogloss:0.878693\n",
      "[30]\ttrain-mlogloss:0.800649\ttest-mlogloss:0.810915\n",
      "[40]\ttrain-mlogloss:0.745504\ttest-mlogloss:0.75844\n",
      "[50]\ttrain-mlogloss:0.701042\ttest-mlogloss:0.716552\n",
      "[60]\ttrain-mlogloss:0.66554\ttest-mlogloss:0.683544\n",
      "[70]\ttrain-mlogloss:0.636703\ttest-mlogloss:0.657203\n",
      "[80]\ttrain-mlogloss:0.612977\ttest-mlogloss:0.63568\n",
      "[90]\ttrain-mlogloss:0.593337\ttest-mlogloss:0.618297\n",
      "[100]\ttrain-mlogloss:0.576957\ttest-mlogloss:0.603997\n",
      "[110]\ttrain-mlogloss:0.563018\ttest-mlogloss:0.592214\n",
      "[120]\ttrain-mlogloss:0.551162\ttest-mlogloss:0.582563\n",
      "[130]\ttrain-mlogloss:0.541079\ttest-mlogloss:0.57441\n",
      "[140]\ttrain-mlogloss:0.532219\ttest-mlogloss:0.567428\n",
      "[150]\ttrain-mlogloss:0.524458\ttest-mlogloss:0.561566\n",
      "[160]\ttrain-mlogloss:0.517547\ttest-mlogloss:0.55645\n",
      "[170]\ttrain-mlogloss:0.51146\ttest-mlogloss:0.552194\n",
      "[180]\ttrain-mlogloss:0.505845\ttest-mlogloss:0.548246\n",
      "[190]\ttrain-mlogloss:0.500862\ttest-mlogloss:0.544935\n",
      "[200]\ttrain-mlogloss:0.496319\ttest-mlogloss:0.542131\n",
      "[210]\ttrain-mlogloss:0.492097\ttest-mlogloss:0.539601\n",
      "[220]\ttrain-mlogloss:0.488114\ttest-mlogloss:0.537266\n",
      "[230]\ttrain-mlogloss:0.484477\ttest-mlogloss:0.535261\n",
      "[240]\ttrain-mlogloss:0.480953\ttest-mlogloss:0.533349\n",
      "[250]\ttrain-mlogloss:0.47746\ttest-mlogloss:0.531733\n",
      "[260]\ttrain-mlogloss:0.474383\ttest-mlogloss:0.530274\n",
      "[270]\ttrain-mlogloss:0.471326\ttest-mlogloss:0.5289\n",
      "[280]\ttrain-mlogloss:0.46838\ttest-mlogloss:0.527656\n",
      "[290]\ttrain-mlogloss:0.465498\ttest-mlogloss:0.526366\n",
      "[300]\ttrain-mlogloss:0.46298\ttest-mlogloss:0.525298\n",
      "[310]\ttrain-mlogloss:0.460268\ttest-mlogloss:0.524332\n",
      "[320]\ttrain-mlogloss:0.457838\ttest-mlogloss:0.523477\n",
      "[330]\ttrain-mlogloss:0.455382\ttest-mlogloss:0.522607\n",
      "[340]\ttrain-mlogloss:0.453\ttest-mlogloss:0.521816\n",
      "[350]\ttrain-mlogloss:0.450671\ttest-mlogloss:0.521079\n",
      "[360]\ttrain-mlogloss:0.448362\ttest-mlogloss:0.52036\n",
      "[370]\ttrain-mlogloss:0.4463\ttest-mlogloss:0.519733\n",
      "[380]\ttrain-mlogloss:0.444035\ttest-mlogloss:0.519131\n",
      "[390]\ttrain-mlogloss:0.441939\ttest-mlogloss:0.518571\n",
      "[400]\ttrain-mlogloss:0.439903\ttest-mlogloss:0.51795\n",
      "[410]\ttrain-mlogloss:0.437905\ttest-mlogloss:0.517414\n",
      "[420]\ttrain-mlogloss:0.436219\ttest-mlogloss:0.516978\n",
      "[430]\ttrain-mlogloss:0.434052\ttest-mlogloss:0.516486\n",
      "[440]\ttrain-mlogloss:0.432409\ttest-mlogloss:0.516111\n",
      "[450]\ttrain-mlogloss:0.430518\ttest-mlogloss:0.515748\n",
      "[460]\ttrain-mlogloss:0.428714\ttest-mlogloss:0.515346\n",
      "[470]\ttrain-mlogloss:0.42698\ttest-mlogloss:0.514948\n",
      "[480]\ttrain-mlogloss:0.425183\ttest-mlogloss:0.514619\n",
      "[490]\ttrain-mlogloss:0.423458\ttest-mlogloss:0.514345\n",
      "[500]\ttrain-mlogloss:0.421784\ttest-mlogloss:0.514103\n",
      "[510]\ttrain-mlogloss:0.420056\ttest-mlogloss:0.513821\n",
      "[520]\ttrain-mlogloss:0.41844\ttest-mlogloss:0.513531\n",
      "[530]\ttrain-mlogloss:0.416718\ttest-mlogloss:0.513186\n",
      "[540]\ttrain-mlogloss:0.415009\ttest-mlogloss:0.512999\n",
      "[550]\ttrain-mlogloss:0.413359\ttest-mlogloss:0.512798\n",
      "[560]\ttrain-mlogloss:0.411898\ttest-mlogloss:0.512549\n",
      "[570]\ttrain-mlogloss:0.410377\ttest-mlogloss:0.512329\n",
      "[580]\ttrain-mlogloss:0.40884\ttest-mlogloss:0.512164\n",
      "[590]\ttrain-mlogloss:0.407151\ttest-mlogloss:0.51187\n",
      "[600]\ttrain-mlogloss:0.405435\ttest-mlogloss:0.511684\n",
      "[610]\ttrain-mlogloss:0.403744\ttest-mlogloss:0.511495\n",
      "[620]\ttrain-mlogloss:0.402174\ttest-mlogloss:0.51124\n",
      "[630]\ttrain-mlogloss:0.400461\ttest-mlogloss:0.510938\n",
      "[640]\ttrain-mlogloss:0.39912\ttest-mlogloss:0.510784\n",
      "[650]\ttrain-mlogloss:0.39752\ttest-mlogloss:0.510675\n",
      "[660]\ttrain-mlogloss:0.395932\ttest-mlogloss:0.510508\n",
      "[670]\ttrain-mlogloss:0.394301\ttest-mlogloss:0.510314\n",
      "[680]\ttrain-mlogloss:0.392689\ttest-mlogloss:0.51009\n",
      "[690]\ttrain-mlogloss:0.391332\ttest-mlogloss:0.509955\n",
      "[700]\ttrain-mlogloss:0.389811\ttest-mlogloss:0.509815\n",
      "[710]\ttrain-mlogloss:0.3884\ttest-mlogloss:0.509633\n",
      "[720]\ttrain-mlogloss:0.386935\ttest-mlogloss:0.509419\n",
      "[730]\ttrain-mlogloss:0.385467\ttest-mlogloss:0.509249\n",
      "[740]\ttrain-mlogloss:0.384023\ttest-mlogloss:0.509163\n",
      "[750]\ttrain-mlogloss:0.382436\ttest-mlogloss:0.509072\n",
      "[760]\ttrain-mlogloss:0.381079\ttest-mlogloss:0.509066\n",
      "[770]\ttrain-mlogloss:0.379512\ttest-mlogloss:0.508912\n",
      "[780]\ttrain-mlogloss:0.378103\ttest-mlogloss:0.508882\n",
      "[790]\ttrain-mlogloss:0.376825\ttest-mlogloss:0.508838\n",
      "[800]\ttrain-mlogloss:0.375472\ttest-mlogloss:0.508686\n",
      "[810]\ttrain-mlogloss:0.374047\ttest-mlogloss:0.508622\n",
      "[820]\ttrain-mlogloss:0.372582\ttest-mlogloss:0.508598\n",
      "[830]\ttrain-mlogloss:0.371177\ttest-mlogloss:0.508523\n",
      "[840]\ttrain-mlogloss:0.369861\ttest-mlogloss:0.508415\n",
      "[850]\ttrain-mlogloss:0.368525\ttest-mlogloss:0.508296\n",
      "[860]\ttrain-mlogloss:0.367123\ttest-mlogloss:0.508224\n",
      "[870]\ttrain-mlogloss:0.365687\ttest-mlogloss:0.508083\n",
      "[880]\ttrain-mlogloss:0.364201\ttest-mlogloss:0.508083\n",
      "[890]\ttrain-mlogloss:0.362956\ttest-mlogloss:0.507978\n",
      "[900]\ttrain-mlogloss:0.361549\ttest-mlogloss:0.507922\n",
      "[910]\ttrain-mlogloss:0.360211\ttest-mlogloss:0.507883\n",
      "[920]\ttrain-mlogloss:0.358853\ttest-mlogloss:0.507873\n",
      "[930]\ttrain-mlogloss:0.357512\ttest-mlogloss:0.507843\n",
      "[940]\ttrain-mlogloss:0.356231\ttest-mlogloss:0.507711\n",
      "[950]\ttrain-mlogloss:0.354701\ttest-mlogloss:0.507662\n",
      "[960]\ttrain-mlogloss:0.353535\ttest-mlogloss:0.507627\n",
      "[970]\ttrain-mlogloss:0.352137\ttest-mlogloss:0.507585\n",
      "[980]\ttrain-mlogloss:0.350884\ttest-mlogloss:0.507515\n",
      "[990]\ttrain-mlogloss:0.349557\ttest-mlogloss:0.507432\n",
      "[1000]\ttrain-mlogloss:0.348172\ttest-mlogloss:0.507319\n",
      "[1010]\ttrain-mlogloss:0.347053\ttest-mlogloss:0.50728\n",
      "[1020]\ttrain-mlogloss:0.345889\ttest-mlogloss:0.507252\n",
      "[1030]\ttrain-mlogloss:0.344605\ttest-mlogloss:0.507209\n",
      "[1040]\ttrain-mlogloss:0.343288\ttest-mlogloss:0.507135\n",
      "[1050]\ttrain-mlogloss:0.342108\ttest-mlogloss:0.507105\n",
      "[1060]\ttrain-mlogloss:0.340714\ttest-mlogloss:0.507049\n",
      "[1070]\ttrain-mlogloss:0.339415\ttest-mlogloss:0.506957\n",
      "[1080]\ttrain-mlogloss:0.338229\ttest-mlogloss:0.506884\n",
      "[1090]\ttrain-mlogloss:0.336974\ttest-mlogloss:0.506867\n",
      "[1100]\ttrain-mlogloss:0.335772\ttest-mlogloss:0.506836\n",
      "[1110]\ttrain-mlogloss:0.334584\ttest-mlogloss:0.506809\n",
      "[1120]\ttrain-mlogloss:0.333479\ttest-mlogloss:0.506865\n",
      "[1130]\ttrain-mlogloss:0.33225\ttest-mlogloss:0.506887\n",
      "[1140]\ttrain-mlogloss:0.331156\ttest-mlogloss:0.506822\n",
      "[1150]\ttrain-mlogloss:0.32992\ttest-mlogloss:0.506728\n",
      "[1160]\ttrain-mlogloss:0.328791\ttest-mlogloss:0.506662\n",
      "[1170]\ttrain-mlogloss:0.327573\ttest-mlogloss:0.506783\n",
      "[1180]\ttrain-mlogloss:0.326393\ttest-mlogloss:0.506756\n",
      "[1190]\ttrain-mlogloss:0.325177\ttest-mlogloss:0.506689\n",
      "[1200]\ttrain-mlogloss:0.324096\ttest-mlogloss:0.506631\n",
      "[1210]\ttrain-mlogloss:0.323058\ttest-mlogloss:0.506584\n",
      "[1220]\ttrain-mlogloss:0.321941\ttest-mlogloss:0.50659\n",
      "[1230]\ttrain-mlogloss:0.320755\ttest-mlogloss:0.50655\n",
      "[1240]\ttrain-mlogloss:0.319688\ttest-mlogloss:0.506486\n",
      "[1250]\ttrain-mlogloss:0.318475\ttest-mlogloss:0.506502\n",
      "[1260]\ttrain-mlogloss:0.317272\ttest-mlogloss:0.50649\n",
      "[1270]\ttrain-mlogloss:0.316161\ttest-mlogloss:0.506547\n",
      "[1280]\ttrain-mlogloss:0.314983\ttest-mlogloss:0.506554\n",
      "[1290]\ttrain-mlogloss:0.313868\ttest-mlogloss:0.506527\n",
      "Stopping. Best iteration:\n",
      "[1240]\ttrain-mlogloss:0.319688\ttest-mlogloss:0.506486\n",
      "\n",
      "[0.50231927851655944, 0.49766997270751701, 0.5099642237087797, 0.50648552464250396]\n",
      "[0]\ttrain-mlogloss:1.08439\ttest-mlogloss:1.08469\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "[10]\ttrain-mlogloss:0.961763\ttest-mlogloss:0.964962\n",
      "[20]\ttrain-mlogloss:0.86983\ttest-mlogloss:0.875708\n",
      "[30]\ttrain-mlogloss:0.799133\ttest-mlogloss:0.807596\n",
      "[40]\ttrain-mlogloss:0.743816\ttest-mlogloss:0.754619\n",
      "[50]\ttrain-mlogloss:0.700009\ttest-mlogloss:0.713118\n",
      "[60]\ttrain-mlogloss:0.66465\ttest-mlogloss:0.679967\n",
      "[70]\ttrain-mlogloss:0.635934\ttest-mlogloss:0.653364\n",
      "[80]\ttrain-mlogloss:0.612554\ttest-mlogloss:0.63195\n",
      "[90]\ttrain-mlogloss:0.59329\ttest-mlogloss:0.614689\n",
      "[100]\ttrain-mlogloss:0.577075\ttest-mlogloss:0.600401\n",
      "[110]\ttrain-mlogloss:0.563476\ttest-mlogloss:0.588731\n",
      "[120]\ttrain-mlogloss:0.551952\ttest-mlogloss:0.579258\n",
      "[130]\ttrain-mlogloss:0.541904\ttest-mlogloss:0.571102\n",
      "[140]\ttrain-mlogloss:0.533338\ttest-mlogloss:0.564232\n",
      "[150]\ttrain-mlogloss:0.525642\ttest-mlogloss:0.558483\n",
      "[160]\ttrain-mlogloss:0.518692\ttest-mlogloss:0.553535\n",
      "[170]\ttrain-mlogloss:0.512618\ttest-mlogloss:0.549323\n",
      "[180]\ttrain-mlogloss:0.507059\ttest-mlogloss:0.545593\n",
      "[190]\ttrain-mlogloss:0.502205\ttest-mlogloss:0.542321\n",
      "[200]\ttrain-mlogloss:0.497499\ttest-mlogloss:0.53946\n",
      "[210]\ttrain-mlogloss:0.492969\ttest-mlogloss:0.536829\n",
      "[220]\ttrain-mlogloss:0.488905\ttest-mlogloss:0.534577\n",
      "[230]\ttrain-mlogloss:0.485234\ttest-mlogloss:0.532503\n",
      "[240]\ttrain-mlogloss:0.481695\ttest-mlogloss:0.530787\n",
      "[250]\ttrain-mlogloss:0.478267\ttest-mlogloss:0.529051\n",
      "[260]\ttrain-mlogloss:0.47514\ttest-mlogloss:0.527598\n",
      "[270]\ttrain-mlogloss:0.472021\ttest-mlogloss:0.526266\n",
      "[280]\ttrain-mlogloss:0.469212\ttest-mlogloss:0.52505\n",
      "[290]\ttrain-mlogloss:0.466354\ttest-mlogloss:0.523834\n",
      "[300]\ttrain-mlogloss:0.463726\ttest-mlogloss:0.522698\n",
      "[310]\ttrain-mlogloss:0.461037\ttest-mlogloss:0.521664\n",
      "[320]\ttrain-mlogloss:0.458714\ttest-mlogloss:0.520766\n",
      "[330]\ttrain-mlogloss:0.456135\ttest-mlogloss:0.519919\n",
      "[340]\ttrain-mlogloss:0.453767\ttest-mlogloss:0.519173\n",
      "[350]\ttrain-mlogloss:0.451674\ttest-mlogloss:0.518406\n",
      "[360]\ttrain-mlogloss:0.44936\ttest-mlogloss:0.517727\n",
      "[370]\ttrain-mlogloss:0.447179\ttest-mlogloss:0.517009\n",
      "[380]\ttrain-mlogloss:0.445077\ttest-mlogloss:0.516464\n",
      "[390]\ttrain-mlogloss:0.443175\ttest-mlogloss:0.515944\n",
      "[400]\ttrain-mlogloss:0.441008\ttest-mlogloss:0.515414\n",
      "[410]\ttrain-mlogloss:0.43905\ttest-mlogloss:0.514857\n",
      "[420]\ttrain-mlogloss:0.437215\ttest-mlogloss:0.51439\n",
      "[430]\ttrain-mlogloss:0.435336\ttest-mlogloss:0.513944\n",
      "[440]\ttrain-mlogloss:0.433378\ttest-mlogloss:0.513517\n",
      "[450]\ttrain-mlogloss:0.431606\ttest-mlogloss:0.513123\n",
      "[460]\ttrain-mlogloss:0.429753\ttest-mlogloss:0.512726\n",
      "[470]\ttrain-mlogloss:0.427968\ttest-mlogloss:0.512298\n",
      "[480]\ttrain-mlogloss:0.426168\ttest-mlogloss:0.511962\n",
      "[490]\ttrain-mlogloss:0.424461\ttest-mlogloss:0.51162\n",
      "[500]\ttrain-mlogloss:0.422726\ttest-mlogloss:0.511296\n",
      "[510]\ttrain-mlogloss:0.42083\ttest-mlogloss:0.51097\n",
      "[520]\ttrain-mlogloss:0.419019\ttest-mlogloss:0.510717\n",
      "[530]\ttrain-mlogloss:0.417332\ttest-mlogloss:0.510482\n",
      "[540]\ttrain-mlogloss:0.415671\ttest-mlogloss:0.51027\n",
      "[550]\ttrain-mlogloss:0.413972\ttest-mlogloss:0.510009\n",
      "[560]\ttrain-mlogloss:0.412114\ttest-mlogloss:0.509819\n",
      "[570]\ttrain-mlogloss:0.410561\ttest-mlogloss:0.509561\n",
      "[580]\ttrain-mlogloss:0.409032\ttest-mlogloss:0.509359\n",
      "[590]\ttrain-mlogloss:0.407571\ttest-mlogloss:0.509171\n",
      "[600]\ttrain-mlogloss:0.405984\ttest-mlogloss:0.508981\n",
      "[610]\ttrain-mlogloss:0.404389\ttest-mlogloss:0.508767\n",
      "[620]\ttrain-mlogloss:0.402918\ttest-mlogloss:0.50856\n",
      "[630]\ttrain-mlogloss:0.401216\ttest-mlogloss:0.508346\n",
      "[640]\ttrain-mlogloss:0.399696\ttest-mlogloss:0.508192\n",
      "[650]\ttrain-mlogloss:0.398104\ttest-mlogloss:0.508066\n",
      "[660]\ttrain-mlogloss:0.396624\ttest-mlogloss:0.507965\n",
      "[670]\ttrain-mlogloss:0.395009\ttest-mlogloss:0.507796\n",
      "[680]\ttrain-mlogloss:0.393421\ttest-mlogloss:0.507642\n",
      "[690]\ttrain-mlogloss:0.391855\ttest-mlogloss:0.507472\n",
      "[700]\ttrain-mlogloss:0.390385\ttest-mlogloss:0.507345\n",
      "[710]\ttrain-mlogloss:0.388909\ttest-mlogloss:0.507208\n",
      "[720]\ttrain-mlogloss:0.387488\ttest-mlogloss:0.507042\n",
      "[730]\ttrain-mlogloss:0.385955\ttest-mlogloss:0.506958\n",
      "[740]\ttrain-mlogloss:0.384654\ttest-mlogloss:0.506837\n",
      "[750]\ttrain-mlogloss:0.383121\ttest-mlogloss:0.506729\n",
      "[760]\ttrain-mlogloss:0.38165\ttest-mlogloss:0.506681\n",
      "[770]\ttrain-mlogloss:0.380222\ttest-mlogloss:0.506562\n",
      "[780]\ttrain-mlogloss:0.378887\ttest-mlogloss:0.50639\n",
      "[790]\ttrain-mlogloss:0.377508\ttest-mlogloss:0.50627\n",
      "[800]\ttrain-mlogloss:0.376167\ttest-mlogloss:0.506164\n",
      "[810]\ttrain-mlogloss:0.374784\ttest-mlogloss:0.506068\n",
      "[820]\ttrain-mlogloss:0.37328\ttest-mlogloss:0.505936\n",
      "[830]\ttrain-mlogloss:0.371932\ttest-mlogloss:0.505861\n",
      "[840]\ttrain-mlogloss:0.370401\ttest-mlogloss:0.505729\n",
      "[850]\ttrain-mlogloss:0.369008\ttest-mlogloss:0.50561\n",
      "[860]\ttrain-mlogloss:0.367692\ttest-mlogloss:0.505551\n",
      "[870]\ttrain-mlogloss:0.366245\ttest-mlogloss:0.505442\n",
      "[880]\ttrain-mlogloss:0.36469\ttest-mlogloss:0.50531\n",
      "[890]\ttrain-mlogloss:0.363321\ttest-mlogloss:0.505178\n",
      "[900]\ttrain-mlogloss:0.361997\ttest-mlogloss:0.505048\n",
      "[910]\ttrain-mlogloss:0.360528\ttest-mlogloss:0.504943\n",
      "[920]\ttrain-mlogloss:0.359156\ttest-mlogloss:0.504859\n",
      "[930]\ttrain-mlogloss:0.357739\ttest-mlogloss:0.504788\n",
      "[940]\ttrain-mlogloss:0.356497\ttest-mlogloss:0.504796\n",
      "[950]\ttrain-mlogloss:0.355223\ttest-mlogloss:0.504774\n",
      "[960]\ttrain-mlogloss:0.353913\ttest-mlogloss:0.504751\n",
      "[970]\ttrain-mlogloss:0.352541\ttest-mlogloss:0.504705\n",
      "[980]\ttrain-mlogloss:0.351241\ttest-mlogloss:0.504627\n",
      "[990]\ttrain-mlogloss:0.350095\ttest-mlogloss:0.504546\n",
      "[1000]\ttrain-mlogloss:0.348938\ttest-mlogloss:0.504416\n",
      "[1010]\ttrain-mlogloss:0.34771\ttest-mlogloss:0.504301\n",
      "[1020]\ttrain-mlogloss:0.346502\ttest-mlogloss:0.504229\n",
      "[1030]\ttrain-mlogloss:0.345224\ttest-mlogloss:0.504126\n",
      "[1040]\ttrain-mlogloss:0.343934\ttest-mlogloss:0.504113\n",
      "[1050]\ttrain-mlogloss:0.34274\ttest-mlogloss:0.504059\n",
      "[1060]\ttrain-mlogloss:0.341443\ttest-mlogloss:0.503963\n",
      "[1070]\ttrain-mlogloss:0.340282\ttest-mlogloss:0.503928\n",
      "[1080]\ttrain-mlogloss:0.339084\ttest-mlogloss:0.503823\n",
      "[1090]\ttrain-mlogloss:0.337854\ttest-mlogloss:0.503796\n",
      "[1100]\ttrain-mlogloss:0.336574\ttest-mlogloss:0.503813\n",
      "[1110]\ttrain-mlogloss:0.335512\ttest-mlogloss:0.503744\n",
      "[1120]\ttrain-mlogloss:0.334375\ttest-mlogloss:0.503704\n",
      "[1130]\ttrain-mlogloss:0.333203\ttest-mlogloss:0.503658\n",
      "[1140]\ttrain-mlogloss:0.332019\ttest-mlogloss:0.503675\n",
      "[1150]\ttrain-mlogloss:0.330797\ttest-mlogloss:0.503687\n",
      "[1160]\ttrain-mlogloss:0.329572\ttest-mlogloss:0.503707\n",
      "[1170]\ttrain-mlogloss:0.328338\ttest-mlogloss:0.503718\n",
      "Stopping. Best iteration:\n",
      "[1128]\ttrain-mlogloss:0.333446\ttest-mlogloss:0.503646\n",
      "\n",
      "[0.50231927851655944, 0.49766997270751701, 0.5099642237087797, 0.50648552464250396, 0.50364610942838239]\n",
      "0.504017044348\n"
     ]
    }
   ],
   "source": [
    "rv3 = run_cv(train_df, cv_test, kf, fl) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfs3 = run3_to_stackdf(rv3)\n",
    "pickle.dump(dfs3, open('modeloutput-xgb-clf-r2.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_to_stackdf(run):\n",
    "    df_testpreds = pd.DataFrame(run[2].mean(axis=0))\n",
    "    df_testpreds.columns = ['level']\n",
    "    df_testpreds['listing_id'] = cv_test[0].listing_id\n",
    "    df_allpreds = pd.concat([run[1][['level', 'listing_id']], df_testpreds])\n",
    "\n",
    "    df_allpreds.sort_values('listing_id', inplace=True)\n",
    "    df_allpreds.set_index('listing_id', inplace=True)\n",
    "\n",
    "    df_fold = []\n",
    "    for f in range(run[2].shape[0]):\n",
    "        df_fold.append(pd.DataFrame(run[2][f]))\n",
    "        df_fold[-1]['listing_id'] = test_df.listing_id\n",
    "        df_fold[-1].sort_values('listing_id', inplace=True)\n",
    "        df_fold[-1].set_index('listing_id', inplace=True)\n",
    "\n",
    "    return (df_allpreds, df_fold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def runXGB1(train_X, train_y, test_X, test_y=None, feature_names=None, seed_val=0, num_rounds=4000):\n",
    "    param = {}\n",
    "    param['objective'] = 'reg:logistic'\n",
    "    #param['tree_method'] = 'hist'\n",
    "    param['eta'] = 0.02\n",
    "    param['max_depth'] = 6\n",
    "    param['silent'] = 1\n",
    "    param['num_class'] = 1\n",
    "    param['eval_metric'] = \"rmse\"\n",
    "    param['min_child_weight'] = 1\n",
    "    param['subsample'] = 0.7\n",
    "    param['colsample_bytree'] = 0.7\n",
    "    param['seed'] = seed_val\n",
    "    param['base_score'] = train_y.mean()\n",
    "    num_rounds = num_rounds\n",
    "\n",
    "    plst = list(param.items())\n",
    "    xgtrain = xgb.DMatrix(train_X, label=train_y)\n",
    "\n",
    "    if test_y is not None:\n",
    "        xgtest = xgb.DMatrix(test_X, label=test_y)\n",
    "        watchlist = [ (xgtrain,'train'), (xgtest, 'test') ]\n",
    "        model = xgb.train(plst, xgtrain, num_rounds, watchlist, early_stopping_rounds=50, verbose_eval=10)\n",
    "    else:\n",
    "        xgtest = xgb.DMatrix(test_X)\n",
    "        model = xgb.train(plst, xgtrain, num_rounds)\n",
    "\n",
    "    pred_test_y = model.predict(xgtest, ntree_limit=model.best_ntree_limit)\n",
    "    return pred_test_y, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "medium_regression_tgt = (.5 + (9/13)) / 2\n",
    "\n",
    "def run_cv1(train_df, cv_test, kf, features_to_use):\n",
    "    \n",
    "    train_X = train_df[features_to_use] #sparse.hstack([train_df[features_to_use], tr_sparse]).tocsr()\n",
    "    train_y3 = np.array(train_df['interest_level'].apply(lambda x: target_num_map[x]))\n",
    "    \n",
    "    train_y = np.zeros_like(train_y3, dtype=np.float32)\n",
    "    train_y[train_y3 == 1] = medium_regression_tgt\n",
    "    train_y[train_y3 == 2] = 1\n",
    "\n",
    "    cv_preds = []\n",
    "    cv_scores = []\n",
    "    models = []\n",
    "    test_preds = []\n",
    "    \n",
    "    fold = 0\n",
    "\n",
    "    for dev_index, val_index in kf.split(range(train_X.shape[0]), train_y):\n",
    "\n",
    "        dev_X, val_X = train_X.iloc[dev_index], train_X.iloc[val_index]\n",
    "        dev_y, val_y = train_y[dev_index], train_y[val_index]\n",
    "        preds, model = runXGB1(dev_X, dev_y, val_X, val_y)\n",
    "        models.append(model)\n",
    "\n",
    "        cv_scores.append(model.best_score)\n",
    "        print(cv_scores)\n",
    "\n",
    "        cut_df = train_df.iloc[val_index]\n",
    "        \n",
    "        out_df = pd.DataFrame(preds)\n",
    "        out_df.columns = [\"level\"]\n",
    "        out_df[\"listing_id\"] = cut_df.listing_id.values\n",
    "        out_df['interest_tgt'] = val_y # cut_df.interest.values\n",
    "\n",
    "        cv_preds.append(out_df)\n",
    "\n",
    "        xgtest = xgb.DMatrix(cv_test[fold][features_to_use])\n",
    "        test_preds.append(model.predict(xgtest, ntree_limit=model.best_ntree_limit))\n",
    "\n",
    "    df_cv = pd.concat(cv_preds)\n",
    "    print(np.sqrt(sklearn.metrics.mean_squared_error(df_cv.interest_tgt, df_cv.level)))\n",
    "    \n",
    "    apreds = np.array(test_preds)\n",
    "    \n",
    "    return models, df_cv, apreds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:0.334233\ttest-rmse:0.334264\n",
      "Multiple eval metrics have been passed: 'test-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until test-rmse hasn't improved in 50 rounds.\n",
      "[10]\ttrain-rmse:0.314012\ttest-rmse:0.314653\n",
      "[20]\ttrain-rmse:0.298041\ttest-rmse:0.299375\n",
      "[30]\ttrain-rmse:0.285641\ttest-rmse:0.287604\n",
      "[40]\ttrain-rmse:0.275962\ttest-rmse:0.278544\n",
      "[50]\ttrain-rmse:0.268646\ttest-rmse:0.27187\n",
      "[60]\ttrain-rmse:0.262838\ttest-rmse:0.26663\n",
      "[70]\ttrain-rmse:0.258499\ttest-rmse:0.262806\n",
      "[80]\ttrain-rmse:0.254907\ttest-rmse:0.259728\n",
      "[90]\ttrain-rmse:0.251964\ttest-rmse:0.257245\n",
      "[100]\ttrain-rmse:0.249505\ttest-rmse:0.255299\n",
      "[110]\ttrain-rmse:0.247396\ttest-rmse:0.253605\n",
      "[120]\ttrain-rmse:0.245677\ttest-rmse:0.252278\n",
      "[130]\ttrain-rmse:0.244128\ttest-rmse:0.251089\n",
      "[140]\ttrain-rmse:0.242778\ttest-rmse:0.250065\n",
      "[150]\ttrain-rmse:0.241542\ttest-rmse:0.249207\n",
      "[160]\ttrain-rmse:0.240455\ttest-rmse:0.248543\n",
      "[170]\ttrain-rmse:0.239464\ttest-rmse:0.247846\n",
      "[180]\ttrain-rmse:0.238531\ttest-rmse:0.247266\n",
      "[190]\ttrain-rmse:0.237702\ttest-rmse:0.246759\n",
      "[200]\ttrain-rmse:0.236784\ttest-rmse:0.246259\n",
      "[210]\ttrain-rmse:0.235908\ttest-rmse:0.24583\n",
      "[220]\ttrain-rmse:0.235131\ttest-rmse:0.245453\n",
      "[230]\ttrain-rmse:0.234462\ttest-rmse:0.245093\n",
      "[240]\ttrain-rmse:0.233854\ttest-rmse:0.244763\n",
      "[250]\ttrain-rmse:0.233231\ttest-rmse:0.244458\n",
      "[260]\ttrain-rmse:0.23261\ttest-rmse:0.244196\n",
      "[270]\ttrain-rmse:0.232083\ttest-rmse:0.243964\n",
      "[280]\ttrain-rmse:0.231555\ttest-rmse:0.243665\n",
      "[290]\ttrain-rmse:0.230909\ttest-rmse:0.243473\n",
      "[300]\ttrain-rmse:0.230425\ttest-rmse:0.243253\n",
      "[310]\ttrain-rmse:0.22994\ttest-rmse:0.243054\n",
      "[320]\ttrain-rmse:0.229343\ttest-rmse:0.242865\n",
      "[330]\ttrain-rmse:0.228855\ttest-rmse:0.242692\n",
      "[340]\ttrain-rmse:0.228492\ttest-rmse:0.242553\n",
      "[350]\ttrain-rmse:0.227986\ttest-rmse:0.242406\n",
      "[360]\ttrain-rmse:0.22745\ttest-rmse:0.242221\n",
      "[370]\ttrain-rmse:0.226923\ttest-rmse:0.242043\n",
      "[380]\ttrain-rmse:0.226426\ttest-rmse:0.241914\n",
      "[390]\ttrain-rmse:0.226024\ttest-rmse:0.24181\n",
      "[400]\ttrain-rmse:0.225432\ttest-rmse:0.241647\n",
      "[410]\ttrain-rmse:0.224855\ttest-rmse:0.241483\n",
      "[420]\ttrain-rmse:0.22429\ttest-rmse:0.241382\n",
      "[430]\ttrain-rmse:0.223848\ttest-rmse:0.241254\n",
      "[440]\ttrain-rmse:0.223427\ttest-rmse:0.241125\n",
      "[450]\ttrain-rmse:0.222934\ttest-rmse:0.240989\n",
      "[460]\ttrain-rmse:0.222489\ttest-rmse:0.240886\n",
      "[470]\ttrain-rmse:0.221944\ttest-rmse:0.240768\n",
      "[480]\ttrain-rmse:0.221483\ttest-rmse:0.240672\n",
      "[490]\ttrain-rmse:0.221089\ttest-rmse:0.240528\n",
      "[500]\ttrain-rmse:0.220645\ttest-rmse:0.240443\n",
      "[510]\ttrain-rmse:0.220311\ttest-rmse:0.240416\n",
      "[520]\ttrain-rmse:0.219752\ttest-rmse:0.240345\n",
      "[530]\ttrain-rmse:0.219321\ttest-rmse:0.24027\n",
      "[540]\ttrain-rmse:0.218855\ttest-rmse:0.240197\n",
      "[550]\ttrain-rmse:0.218269\ttest-rmse:0.240145\n",
      "[560]\ttrain-rmse:0.217705\ttest-rmse:0.240061\n",
      "[570]\ttrain-rmse:0.217317\ttest-rmse:0.240014\n",
      "[580]\ttrain-rmse:0.216752\ttest-rmse:0.239903\n",
      "[590]\ttrain-rmse:0.216381\ttest-rmse:0.239835\n",
      "[600]\ttrain-rmse:0.215899\ttest-rmse:0.239772\n",
      "[610]\ttrain-rmse:0.215545\ttest-rmse:0.239722\n",
      "[620]\ttrain-rmse:0.215098\ttest-rmse:0.239646\n",
      "[630]\ttrain-rmse:0.214699\ttest-rmse:0.239586\n",
      "[640]\ttrain-rmse:0.214299\ttest-rmse:0.239493\n",
      "[650]\ttrain-rmse:0.213847\ttest-rmse:0.239457\n",
      "[660]\ttrain-rmse:0.213376\ttest-rmse:0.239434\n",
      "[670]\ttrain-rmse:0.212935\ttest-rmse:0.239386\n",
      "[680]\ttrain-rmse:0.21257\ttest-rmse:0.239323\n",
      "[690]\ttrain-rmse:0.212101\ttest-rmse:0.23929\n",
      "[700]\ttrain-rmse:0.211616\ttest-rmse:0.2392\n",
      "[710]\ttrain-rmse:0.21128\ttest-rmse:0.239163\n",
      "[720]\ttrain-rmse:0.210823\ttest-rmse:0.239117\n",
      "[730]\ttrain-rmse:0.2104\ttest-rmse:0.23905\n",
      "[740]\ttrain-rmse:0.209955\ttest-rmse:0.238969\n",
      "[750]\ttrain-rmse:0.209529\ttest-rmse:0.238917\n",
      "[760]\ttrain-rmse:0.209099\ttest-rmse:0.238877\n",
      "[770]\ttrain-rmse:0.20865\ttest-rmse:0.23882\n",
      "[780]\ttrain-rmse:0.208293\ttest-rmse:0.238789\n",
      "[790]\ttrain-rmse:0.207822\ttest-rmse:0.238711\n",
      "[800]\ttrain-rmse:0.207506\ttest-rmse:0.238657\n",
      "[810]\ttrain-rmse:0.207126\ttest-rmse:0.238652\n",
      "[820]\ttrain-rmse:0.206701\ttest-rmse:0.238632\n",
      "[830]\ttrain-rmse:0.206261\ttest-rmse:0.23859\n",
      "[840]\ttrain-rmse:0.205852\ttest-rmse:0.238579\n",
      "[850]\ttrain-rmse:0.205446\ttest-rmse:0.238589\n",
      "[860]\ttrain-rmse:0.205028\ttest-rmse:0.238548\n",
      "[870]\ttrain-rmse:0.204652\ttest-rmse:0.238524\n",
      "[880]\ttrain-rmse:0.204244\ttest-rmse:0.238462\n",
      "[890]\ttrain-rmse:0.203967\ttest-rmse:0.238446\n",
      "[900]\ttrain-rmse:0.203478\ttest-rmse:0.238393\n",
      "[910]\ttrain-rmse:0.203124\ttest-rmse:0.238364\n",
      "[920]\ttrain-rmse:0.202743\ttest-rmse:0.238333\n",
      "[930]\ttrain-rmse:0.20228\ttest-rmse:0.238299\n",
      "[940]\ttrain-rmse:0.201933\ttest-rmse:0.238286\n",
      "[950]\ttrain-rmse:0.20149\ttest-rmse:0.238266\n",
      "[960]\ttrain-rmse:0.201056\ttest-rmse:0.238251\n",
      "[970]\ttrain-rmse:0.200724\ttest-rmse:0.238244\n",
      "[980]\ttrain-rmse:0.200276\ttest-rmse:0.238277\n",
      "[990]\ttrain-rmse:0.199802\ttest-rmse:0.238251\n",
      "[1000]\ttrain-rmse:0.199409\ttest-rmse:0.238218\n",
      "[1010]\ttrain-rmse:0.199095\ttest-rmse:0.238182\n",
      "[1020]\ttrain-rmse:0.198726\ttest-rmse:0.238174\n",
      "[1030]\ttrain-rmse:0.198415\ttest-rmse:0.238151\n",
      "[1040]\ttrain-rmse:0.198099\ttest-rmse:0.23811\n",
      "[1050]\ttrain-rmse:0.19771\ttest-rmse:0.238082\n",
      "[1060]\ttrain-rmse:0.197313\ttest-rmse:0.238053\n",
      "[1070]\ttrain-rmse:0.196985\ttest-rmse:0.238035\n",
      "[1080]\ttrain-rmse:0.196588\ttest-rmse:0.237977\n",
      "[1090]\ttrain-rmse:0.196283\ttest-rmse:0.237991\n",
      "[1100]\ttrain-rmse:0.195856\ttest-rmse:0.237978\n",
      "[1110]\ttrain-rmse:0.195496\ttest-rmse:0.23792\n",
      "[1120]\ttrain-rmse:0.195102\ttest-rmse:0.237923\n",
      "[1130]\ttrain-rmse:0.194697\ttest-rmse:0.237918\n",
      "[1140]\ttrain-rmse:0.194325\ttest-rmse:0.237919\n",
      "[1150]\ttrain-rmse:0.193948\ttest-rmse:0.237883\n",
      "[1160]\ttrain-rmse:0.193557\ttest-rmse:0.23787\n",
      "[1170]\ttrain-rmse:0.193156\ttest-rmse:0.237819\n",
      "[1180]\ttrain-rmse:0.192772\ttest-rmse:0.237783\n",
      "[1190]\ttrain-rmse:0.192395\ttest-rmse:0.237775\n",
      "[1200]\ttrain-rmse:0.191983\ttest-rmse:0.237735\n",
      "[1210]\ttrain-rmse:0.191628\ttest-rmse:0.237723\n",
      "[1220]\ttrain-rmse:0.1913\ttest-rmse:0.237704\n",
      "[1230]\ttrain-rmse:0.190886\ttest-rmse:0.23769\n",
      "[1240]\ttrain-rmse:0.190491\ttest-rmse:0.237648\n",
      "[1250]\ttrain-rmse:0.190118\ttest-rmse:0.237631\n",
      "[1260]\ttrain-rmse:0.189807\ttest-rmse:0.237623\n",
      "[1270]\ttrain-rmse:0.189374\ttest-rmse:0.237621\n",
      "[1280]\ttrain-rmse:0.189034\ttest-rmse:0.237573\n",
      "[1290]\ttrain-rmse:0.188687\ttest-rmse:0.237553\n",
      "[1300]\ttrain-rmse:0.188328\ttest-rmse:0.23752\n",
      "[1310]\ttrain-rmse:0.187944\ttest-rmse:0.237524\n",
      "[1320]\ttrain-rmse:0.18759\ttest-rmse:0.237499\n",
      "[1330]\ttrain-rmse:0.187232\ttest-rmse:0.237499\n",
      "[1340]\ttrain-rmse:0.186852\ttest-rmse:0.237487\n",
      "[1350]\ttrain-rmse:0.18655\ttest-rmse:0.237485\n",
      "[1360]\ttrain-rmse:0.186206\ttest-rmse:0.237498\n",
      "[1370]\ttrain-rmse:0.185813\ttest-rmse:0.237488\n",
      "[1380]\ttrain-rmse:0.185409\ttest-rmse:0.23751\n",
      "[1390]\ttrain-rmse:0.185028\ttest-rmse:0.23749\n",
      "[1400]\ttrain-rmse:0.184726\ttest-rmse:0.23747\n",
      "[1410]\ttrain-rmse:0.184387\ttest-rmse:0.237464\n",
      "[1420]\ttrain-rmse:0.184027\ttest-rmse:0.237457\n",
      "[1430]\ttrain-rmse:0.183658\ttest-rmse:0.237445\n",
      "[1440]\ttrain-rmse:0.183328\ttest-rmse:0.237449\n",
      "[1450]\ttrain-rmse:0.183\ttest-rmse:0.237411\n",
      "[1460]\ttrain-rmse:0.182675\ttest-rmse:0.237413\n",
      "[1470]\ttrain-rmse:0.182375\ttest-rmse:0.23739\n",
      "[1480]\ttrain-rmse:0.182008\ttest-rmse:0.237402\n",
      "[1490]\ttrain-rmse:0.181676\ttest-rmse:0.237406\n",
      "[1500]\ttrain-rmse:0.181379\ttest-rmse:0.237405\n",
      "[1510]\ttrain-rmse:0.181114\ttest-rmse:0.23738\n",
      "[1520]\ttrain-rmse:0.180806\ttest-rmse:0.237349\n",
      "[1530]\ttrain-rmse:0.180455\ttest-rmse:0.237374\n",
      "[1540]\ttrain-rmse:0.180107\ttest-rmse:0.237366\n",
      "[1550]\ttrain-rmse:0.179854\ttest-rmse:0.237372\n",
      "[1560]\ttrain-rmse:0.179525\ttest-rmse:0.237353\n",
      "[1570]\ttrain-rmse:0.179166\ttest-rmse:0.237361\n",
      "[1580]\ttrain-rmse:0.178845\ttest-rmse:0.237331\n",
      "[1590]\ttrain-rmse:0.178518\ttest-rmse:0.237296\n",
      "[1600]\ttrain-rmse:0.178245\ttest-rmse:0.237274\n",
      "[1610]\ttrain-rmse:0.177913\ttest-rmse:0.23725\n",
      "[1620]\ttrain-rmse:0.177645\ttest-rmse:0.237214\n",
      "[1630]\ttrain-rmse:0.177377\ttest-rmse:0.237203\n",
      "[1640]\ttrain-rmse:0.17712\ttest-rmse:0.237211\n",
      "[1650]\ttrain-rmse:0.176779\ttest-rmse:0.237205\n",
      "[1660]\ttrain-rmse:0.176445\ttest-rmse:0.237192\n",
      "[1670]\ttrain-rmse:0.176067\ttest-rmse:0.237167\n",
      "[1680]\ttrain-rmse:0.175757\ttest-rmse:0.237144\n",
      "[1690]\ttrain-rmse:0.175455\ttest-rmse:0.23714\n",
      "[1700]\ttrain-rmse:0.175116\ttest-rmse:0.237155\n",
      "[1710]\ttrain-rmse:0.174834\ttest-rmse:0.237139\n",
      "[1720]\ttrain-rmse:0.17453\ttest-rmse:0.23712\n",
      "[1730]\ttrain-rmse:0.174263\ttest-rmse:0.237133\n",
      "[1740]\ttrain-rmse:0.173905\ttest-rmse:0.237113\n",
      "[1750]\ttrain-rmse:0.173612\ttest-rmse:0.23712\n",
      "[1760]\ttrain-rmse:0.173283\ttest-rmse:0.237126\n",
      "[1770]\ttrain-rmse:0.172928\ttest-rmse:0.237119\n",
      "[1780]\ttrain-rmse:0.172637\ttest-rmse:0.237109\n",
      "[1790]\ttrain-rmse:0.17235\ttest-rmse:0.237122\n",
      "[1800]\ttrain-rmse:0.171931\ttest-rmse:0.237121\n",
      "[1810]\ttrain-rmse:0.171647\ttest-rmse:0.237117\n",
      "[1820]\ttrain-rmse:0.171315\ttest-rmse:0.237091\n",
      "[1830]\ttrain-rmse:0.171059\ttest-rmse:0.237098\n",
      "[1840]\ttrain-rmse:0.170676\ttest-rmse:0.237112\n",
      "[1850]\ttrain-rmse:0.170377\ttest-rmse:0.237092\n",
      "[1860]\ttrain-rmse:0.169992\ttest-rmse:0.237073\n",
      "[1870]\ttrain-rmse:0.169709\ttest-rmse:0.237039\n",
      "[1880]\ttrain-rmse:0.169413\ttest-rmse:0.237044\n",
      "[1890]\ttrain-rmse:0.16915\ttest-rmse:0.237021\n",
      "[1900]\ttrain-rmse:0.168791\ttest-rmse:0.236989\n",
      "[1910]\ttrain-rmse:0.168474\ttest-rmse:0.236955\n",
      "[1920]\ttrain-rmse:0.168183\ttest-rmse:0.236972\n",
      "[1930]\ttrain-rmse:0.167964\ttest-rmse:0.236955\n",
      "[1940]\ttrain-rmse:0.167628\ttest-rmse:0.236923\n",
      "[1950]\ttrain-rmse:0.167316\ttest-rmse:0.236951\n",
      "[1960]\ttrain-rmse:0.166973\ttest-rmse:0.236955\n",
      "[1970]\ttrain-rmse:0.166656\ttest-rmse:0.236956\n",
      "[1980]\ttrain-rmse:0.16638\ttest-rmse:0.236967\n",
      "[1990]\ttrain-rmse:0.166086\ttest-rmse:0.236955\n",
      "Stopping. Best iteration:\n",
      "[1941]\ttrain-rmse:0.167584\ttest-rmse:0.236917\n",
      "\n",
      "[0.236917]\n",
      "[0]\ttrain-rmse:0.334184\ttest-rmse:0.334238\n",
      "Multiple eval metrics have been passed: 'test-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until test-rmse hasn't improved in 50 rounds.\n",
      "[10]\ttrain-rmse:0.314015\ttest-rmse:0.314393\n",
      "[20]\ttrain-rmse:0.298107\ttest-rmse:0.298861\n",
      "[30]\ttrain-rmse:0.285832\ttest-rmse:0.287077\n",
      "[40]\ttrain-rmse:0.27621\ttest-rmse:0.277946\n",
      "[50]\ttrain-rmse:0.268934\ttest-rmse:0.271077\n",
      "[60]\ttrain-rmse:0.263256\ttest-rmse:0.265902\n",
      "[70]\ttrain-rmse:0.258898\ttest-rmse:0.261936\n",
      "[80]\ttrain-rmse:0.255268\ttest-rmse:0.258771\n",
      "[90]\ttrain-rmse:0.25233\ttest-rmse:0.256298\n",
      "[100]\ttrain-rmse:0.249881\ttest-rmse:0.254297\n",
      "[110]\ttrain-rmse:0.247855\ttest-rmse:0.25266\n",
      "[120]\ttrain-rmse:0.245988\ttest-rmse:0.251295\n",
      "[130]\ttrain-rmse:0.24433\ttest-rmse:0.250095\n",
      "[140]\ttrain-rmse:0.242932\ttest-rmse:0.249067\n",
      "[150]\ttrain-rmse:0.241769\ttest-rmse:0.248284\n",
      "[160]\ttrain-rmse:0.240664\ttest-rmse:0.247489\n",
      "[170]\ttrain-rmse:0.2397\ttest-rmse:0.246856\n",
      "[180]\ttrain-rmse:0.238754\ttest-rmse:0.246291\n",
      "[190]\ttrain-rmse:0.237718\ttest-rmse:0.245707\n",
      "[200]\ttrain-rmse:0.236778\ttest-rmse:0.245219\n",
      "[210]\ttrain-rmse:0.235981\ttest-rmse:0.244786\n",
      "[220]\ttrain-rmse:0.235201\ttest-rmse:0.24437\n",
      "[230]\ttrain-rmse:0.234397\ttest-rmse:0.244046\n",
      "[240]\ttrain-rmse:0.233706\ttest-rmse:0.243718\n",
      "[250]\ttrain-rmse:0.233044\ttest-rmse:0.243418\n",
      "[260]\ttrain-rmse:0.232418\ttest-rmse:0.243181\n",
      "[270]\ttrain-rmse:0.231958\ttest-rmse:0.242946\n",
      "[280]\ttrain-rmse:0.231526\ttest-rmse:0.242746\n",
      "[290]\ttrain-rmse:0.230937\ttest-rmse:0.242534\n",
      "[300]\ttrain-rmse:0.230442\ttest-rmse:0.24236\n",
      "[310]\ttrain-rmse:0.229842\ttest-rmse:0.242147\n",
      "[320]\ttrain-rmse:0.229281\ttest-rmse:0.242004\n",
      "[330]\ttrain-rmse:0.228775\ttest-rmse:0.24182\n",
      "[340]\ttrain-rmse:0.228274\ttest-rmse:0.241671\n",
      "[350]\ttrain-rmse:0.227668\ttest-rmse:0.241502\n",
      "[360]\ttrain-rmse:0.227203\ttest-rmse:0.24141\n",
      "[370]\ttrain-rmse:0.22664\ttest-rmse:0.241309\n",
      "[380]\ttrain-rmse:0.226218\ttest-rmse:0.241193\n",
      "[390]\ttrain-rmse:0.225723\ttest-rmse:0.241101\n",
      "[400]\ttrain-rmse:0.22533\ttest-rmse:0.240988\n",
      "[410]\ttrain-rmse:0.224732\ttest-rmse:0.240869\n",
      "[420]\ttrain-rmse:0.224203\ttest-rmse:0.240801\n",
      "[430]\ttrain-rmse:0.223614\ttest-rmse:0.240703\n",
      "[440]\ttrain-rmse:0.2231\ttest-rmse:0.240614\n",
      "[450]\ttrain-rmse:0.222677\ttest-rmse:0.240509\n",
      "[460]\ttrain-rmse:0.222234\ttest-rmse:0.240423\n",
      "[470]\ttrain-rmse:0.22164\ttest-rmse:0.240349\n",
      "[480]\ttrain-rmse:0.221155\ttest-rmse:0.240245\n",
      "[490]\ttrain-rmse:0.220672\ttest-rmse:0.240181\n",
      "[500]\ttrain-rmse:0.220094\ttest-rmse:0.240064\n",
      "[510]\ttrain-rmse:0.219663\ttest-rmse:0.240029\n",
      "[520]\ttrain-rmse:0.21922\ttest-rmse:0.239952\n",
      "[530]\ttrain-rmse:0.218783\ttest-rmse:0.239908\n",
      "[540]\ttrain-rmse:0.218281\ttest-rmse:0.239847\n",
      "[550]\ttrain-rmse:0.217801\ttest-rmse:0.239797\n",
      "[560]\ttrain-rmse:0.217358\ttest-rmse:0.239747\n",
      "[570]\ttrain-rmse:0.216915\ttest-rmse:0.2397\n",
      "[580]\ttrain-rmse:0.216619\ttest-rmse:0.239689\n",
      "[590]\ttrain-rmse:0.216102\ttest-rmse:0.239621\n",
      "[600]\ttrain-rmse:0.215654\ttest-rmse:0.239598\n",
      "[610]\ttrain-rmse:0.215218\ttest-rmse:0.239517\n",
      "[620]\ttrain-rmse:0.2148\ttest-rmse:0.239461\n",
      "[630]\ttrain-rmse:0.214447\ttest-rmse:0.239413\n",
      "[640]\ttrain-rmse:0.213951\ttest-rmse:0.239374\n",
      "[650]\ttrain-rmse:0.21346\ttest-rmse:0.239346\n",
      "[660]\ttrain-rmse:0.212991\ttest-rmse:0.239288\n",
      "[670]\ttrain-rmse:0.21257\ttest-rmse:0.23922\n",
      "[680]\ttrain-rmse:0.212035\ttest-rmse:0.239131\n",
      "[690]\ttrain-rmse:0.211556\ttest-rmse:0.23911\n",
      "[700]\ttrain-rmse:0.211132\ttest-rmse:0.239045\n",
      "[710]\ttrain-rmse:0.210781\ttest-rmse:0.23901\n",
      "[720]\ttrain-rmse:0.210356\ttest-rmse:0.238977\n",
      "[730]\ttrain-rmse:0.209969\ttest-rmse:0.238947\n",
      "[740]\ttrain-rmse:0.209516\ttest-rmse:0.238888\n",
      "[750]\ttrain-rmse:0.209099\ttest-rmse:0.238839\n",
      "[760]\ttrain-rmse:0.208756\ttest-rmse:0.238809\n",
      "[770]\ttrain-rmse:0.208323\ttest-rmse:0.238749\n",
      "[780]\ttrain-rmse:0.207921\ttest-rmse:0.238737\n",
      "[790]\ttrain-rmse:0.207541\ttest-rmse:0.238707\n",
      "[800]\ttrain-rmse:0.207147\ttest-rmse:0.238708\n",
      "[810]\ttrain-rmse:0.206685\ttest-rmse:0.238664\n",
      "[820]\ttrain-rmse:0.206319\ttest-rmse:0.238626\n",
      "[830]\ttrain-rmse:0.20588\ttest-rmse:0.238567\n",
      "[840]\ttrain-rmse:0.205486\ttest-rmse:0.238556\n",
      "[850]\ttrain-rmse:0.205072\ttest-rmse:0.238495\n",
      "[860]\ttrain-rmse:0.204668\ttest-rmse:0.238495\n",
      "[870]\ttrain-rmse:0.204147\ttest-rmse:0.238466\n",
      "[880]\ttrain-rmse:0.203759\ttest-rmse:0.238438\n",
      "[890]\ttrain-rmse:0.203383\ttest-rmse:0.238457\n",
      "[900]\ttrain-rmse:0.202942\ttest-rmse:0.238418\n",
      "[910]\ttrain-rmse:0.202559\ttest-rmse:0.238439\n",
      "[920]\ttrain-rmse:0.202109\ttest-rmse:0.238419\n",
      "[930]\ttrain-rmse:0.201662\ttest-rmse:0.238394\n",
      "[940]\ttrain-rmse:0.20124\ttest-rmse:0.238347\n",
      "[950]\ttrain-rmse:0.20075\ttest-rmse:0.238273\n",
      "[960]\ttrain-rmse:0.200377\ttest-rmse:0.238207\n",
      "[970]\ttrain-rmse:0.199931\ttest-rmse:0.238194\n",
      "[980]\ttrain-rmse:0.199536\ttest-rmse:0.23817\n",
      "[990]\ttrain-rmse:0.199121\ttest-rmse:0.238127\n",
      "[1000]\ttrain-rmse:0.198773\ttest-rmse:0.238098\n",
      "[1010]\ttrain-rmse:0.198432\ttest-rmse:0.238094\n",
      "[1020]\ttrain-rmse:0.198086\ttest-rmse:0.2381\n",
      "[1030]\ttrain-rmse:0.197676\ttest-rmse:0.238114\n",
      "[1040]\ttrain-rmse:0.197302\ttest-rmse:0.238107\n",
      "[1050]\ttrain-rmse:0.196956\ttest-rmse:0.238085\n",
      "[1060]\ttrain-rmse:0.196592\ttest-rmse:0.238106\n",
      "[1070]\ttrain-rmse:0.196281\ttest-rmse:0.23809\n",
      "[1080]\ttrain-rmse:0.195854\ttest-rmse:0.238087\n",
      "[1090]\ttrain-rmse:0.195516\ttest-rmse:0.238041\n",
      "[1100]\ttrain-rmse:0.195189\ttest-rmse:0.238032\n",
      "[1110]\ttrain-rmse:0.194821\ttest-rmse:0.238005\n",
      "[1120]\ttrain-rmse:0.194416\ttest-rmse:0.238008\n",
      "[1130]\ttrain-rmse:0.194082\ttest-rmse:0.237981\n",
      "[1140]\ttrain-rmse:0.193689\ttest-rmse:0.237963\n",
      "[1150]\ttrain-rmse:0.193251\ttest-rmse:0.237936\n",
      "[1160]\ttrain-rmse:0.192918\ttest-rmse:0.237911\n",
      "[1170]\ttrain-rmse:0.192614\ttest-rmse:0.237917\n",
      "[1180]\ttrain-rmse:0.192316\ttest-rmse:0.237933\n",
      "[1190]\ttrain-rmse:0.191991\ttest-rmse:0.237915\n",
      "[1200]\ttrain-rmse:0.191717\ttest-rmse:0.237927\n",
      "[1210]\ttrain-rmse:0.191356\ttest-rmse:0.237939\n",
      "Stopping. Best iteration:\n",
      "[1161]\ttrain-rmse:0.192894\ttest-rmse:0.237903\n",
      "\n",
      "[0.236917, 0.237903]\n",
      "[0]\ttrain-rmse:0.334063\ttest-rmse:0.334205\n",
      "Multiple eval metrics have been passed: 'test-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until test-rmse hasn't improved in 50 rounds.\n",
      "[10]\ttrain-rmse:0.313525\ttest-rmse:0.315191\n",
      "[20]\ttrain-rmse:0.297398\ttest-rmse:0.300585\n",
      "[30]\ttrain-rmse:0.284925\ttest-rmse:0.289381\n",
      "[40]\ttrain-rmse:0.275164\ttest-rmse:0.280754\n",
      "[50]\ttrain-rmse:0.267825\ttest-rmse:0.2744\n",
      "[60]\ttrain-rmse:0.262022\ttest-rmse:0.26952\n",
      "[70]\ttrain-rmse:0.257595\ttest-rmse:0.265922\n",
      "[80]\ttrain-rmse:0.253955\ttest-rmse:0.262993\n",
      "[90]\ttrain-rmse:0.250952\ttest-rmse:0.26066\n",
      "[100]\ttrain-rmse:0.248557\ttest-rmse:0.258846\n",
      "[110]\ttrain-rmse:0.246562\ttest-rmse:0.257325\n",
      "[120]\ttrain-rmse:0.244837\ttest-rmse:0.256149\n",
      "[130]\ttrain-rmse:0.243289\ttest-rmse:0.254997\n",
      "[140]\ttrain-rmse:0.241908\ttest-rmse:0.254044\n",
      "[150]\ttrain-rmse:0.240748\ttest-rmse:0.253272\n",
      "[160]\ttrain-rmse:0.239621\ttest-rmse:0.252581\n",
      "[170]\ttrain-rmse:0.238604\ttest-rmse:0.251937\n",
      "[180]\ttrain-rmse:0.237642\ttest-rmse:0.251372\n",
      "[190]\ttrain-rmse:0.236721\ttest-rmse:0.250821\n",
      "[200]\ttrain-rmse:0.235851\ttest-rmse:0.25037\n",
      "[210]\ttrain-rmse:0.235195\ttest-rmse:0.24999\n",
      "[220]\ttrain-rmse:0.234573\ttest-rmse:0.249585\n",
      "[230]\ttrain-rmse:0.233825\ttest-rmse:0.249217\n",
      "[240]\ttrain-rmse:0.233037\ttest-rmse:0.248826\n",
      "[250]\ttrain-rmse:0.232471\ttest-rmse:0.248556\n",
      "[260]\ttrain-rmse:0.231764\ttest-rmse:0.248267\n",
      "[270]\ttrain-rmse:0.23112\ttest-rmse:0.247993\n",
      "[280]\ttrain-rmse:0.230509\ttest-rmse:0.247719\n",
      "[290]\ttrain-rmse:0.229985\ttest-rmse:0.247495\n",
      "[300]\ttrain-rmse:0.229403\ttest-rmse:0.247231\n",
      "[310]\ttrain-rmse:0.229059\ttest-rmse:0.247079\n",
      "[320]\ttrain-rmse:0.228585\ttest-rmse:0.246928\n",
      "[330]\ttrain-rmse:0.228095\ttest-rmse:0.246728\n",
      "[340]\ttrain-rmse:0.227678\ttest-rmse:0.246566\n",
      "[350]\ttrain-rmse:0.227159\ttest-rmse:0.246462\n",
      "[360]\ttrain-rmse:0.226723\ttest-rmse:0.246322\n",
      "[370]\ttrain-rmse:0.226161\ttest-rmse:0.246169\n",
      "[380]\ttrain-rmse:0.225706\ttest-rmse:0.24605\n",
      "[390]\ttrain-rmse:0.225132\ttest-rmse:0.245885\n",
      "[400]\ttrain-rmse:0.224592\ttest-rmse:0.245742\n",
      "[410]\ttrain-rmse:0.224043\ttest-rmse:0.245613\n",
      "[420]\ttrain-rmse:0.223501\ttest-rmse:0.245463\n",
      "[430]\ttrain-rmse:0.222934\ttest-rmse:0.245284\n",
      "[440]\ttrain-rmse:0.222426\ttest-rmse:0.245123\n",
      "[450]\ttrain-rmse:0.22199\ttest-rmse:0.245041\n",
      "[460]\ttrain-rmse:0.221529\ttest-rmse:0.24491\n",
      "[470]\ttrain-rmse:0.220931\ttest-rmse:0.244827\n",
      "[480]\ttrain-rmse:0.220465\ttest-rmse:0.244727\n",
      "[490]\ttrain-rmse:0.220009\ttest-rmse:0.244577\n",
      "[500]\ttrain-rmse:0.219582\ttest-rmse:0.244533\n",
      "[510]\ttrain-rmse:0.219119\ttest-rmse:0.244477\n",
      "[520]\ttrain-rmse:0.218762\ttest-rmse:0.24438\n",
      "[530]\ttrain-rmse:0.218267\ttest-rmse:0.244257\n",
      "[540]\ttrain-rmse:0.217807\ttest-rmse:0.244189\n",
      "[550]\ttrain-rmse:0.21729\ttest-rmse:0.244056\n",
      "[560]\ttrain-rmse:0.216892\ttest-rmse:0.243971\n",
      "[570]\ttrain-rmse:0.216512\ttest-rmse:0.243893\n",
      "[580]\ttrain-rmse:0.216008\ttest-rmse:0.243847\n",
      "[590]\ttrain-rmse:0.215599\ttest-rmse:0.243797\n",
      "[600]\ttrain-rmse:0.215197\ttest-rmse:0.243688\n",
      "[610]\ttrain-rmse:0.214729\ttest-rmse:0.243622\n",
      "[620]\ttrain-rmse:0.214287\ttest-rmse:0.2436\n",
      "[630]\ttrain-rmse:0.21375\ttest-rmse:0.24352\n",
      "[640]\ttrain-rmse:0.213376\ttest-rmse:0.243462\n",
      "[650]\ttrain-rmse:0.212914\ttest-rmse:0.243358\n",
      "[660]\ttrain-rmse:0.212526\ttest-rmse:0.243306\n",
      "[670]\ttrain-rmse:0.2121\ttest-rmse:0.243273\n",
      "[680]\ttrain-rmse:0.211753\ttest-rmse:0.243218\n",
      "[690]\ttrain-rmse:0.211196\ttest-rmse:0.243158\n",
      "[700]\ttrain-rmse:0.210818\ttest-rmse:0.243108\n",
      "[710]\ttrain-rmse:0.21031\ttest-rmse:0.243034\n",
      "[720]\ttrain-rmse:0.209883\ttest-rmse:0.242965\n",
      "[730]\ttrain-rmse:0.209518\ttest-rmse:0.242922\n",
      "[740]\ttrain-rmse:0.209098\ttest-rmse:0.242887\n",
      "[750]\ttrain-rmse:0.208743\ttest-rmse:0.242847\n",
      "[760]\ttrain-rmse:0.20831\ttest-rmse:0.242761\n",
      "[770]\ttrain-rmse:0.207914\ttest-rmse:0.242716\n",
      "[780]\ttrain-rmse:0.207449\ttest-rmse:0.242661\n",
      "[790]\ttrain-rmse:0.207034\ttest-rmse:0.242613\n",
      "[800]\ttrain-rmse:0.206615\ttest-rmse:0.242582\n",
      "[810]\ttrain-rmse:0.206155\ttest-rmse:0.242569\n",
      "[820]\ttrain-rmse:0.205766\ttest-rmse:0.242545\n",
      "[830]\ttrain-rmse:0.205385\ttest-rmse:0.242542\n",
      "[840]\ttrain-rmse:0.204952\ttest-rmse:0.242495\n",
      "[850]\ttrain-rmse:0.204579\ttest-rmse:0.242442\n",
      "[860]\ttrain-rmse:0.204238\ttest-rmse:0.24241\n",
      "[870]\ttrain-rmse:0.203852\ttest-rmse:0.242421\n",
      "[880]\ttrain-rmse:0.203499\ttest-rmse:0.242415\n",
      "[890]\ttrain-rmse:0.203002\ttest-rmse:0.242345\n",
      "[900]\ttrain-rmse:0.202587\ttest-rmse:0.242283\n",
      "[910]\ttrain-rmse:0.202203\ttest-rmse:0.242266\n",
      "[920]\ttrain-rmse:0.201797\ttest-rmse:0.242268\n",
      "[930]\ttrain-rmse:0.201392\ttest-rmse:0.242245\n",
      "[940]\ttrain-rmse:0.201078\ttest-rmse:0.242223\n",
      "[950]\ttrain-rmse:0.200636\ttest-rmse:0.242214\n",
      "[960]\ttrain-rmse:0.200269\ttest-rmse:0.242189\n",
      "[970]\ttrain-rmse:0.199849\ttest-rmse:0.242138\n",
      "[980]\ttrain-rmse:0.199404\ttest-rmse:0.242085\n",
      "[990]\ttrain-rmse:0.19899\ttest-rmse:0.242075\n",
      "[1000]\ttrain-rmse:0.198611\ttest-rmse:0.242071\n",
      "[1010]\ttrain-rmse:0.198285\ttest-rmse:0.242041\n",
      "[1020]\ttrain-rmse:0.19793\ttest-rmse:0.242014\n",
      "[1030]\ttrain-rmse:0.197524\ttest-rmse:0.242008\n",
      "[1040]\ttrain-rmse:0.197101\ttest-rmse:0.241996\n",
      "[1050]\ttrain-rmse:0.196764\ttest-rmse:0.241975\n",
      "[1060]\ttrain-rmse:0.196369\ttest-rmse:0.241941\n",
      "[1070]\ttrain-rmse:0.196033\ttest-rmse:0.24191\n",
      "[1080]\ttrain-rmse:0.195688\ttest-rmse:0.241894\n",
      "[1090]\ttrain-rmse:0.195353\ttest-rmse:0.24191\n",
      "[1100]\ttrain-rmse:0.195059\ttest-rmse:0.241877\n",
      "[1110]\ttrain-rmse:0.194712\ttest-rmse:0.24189\n",
      "[1120]\ttrain-rmse:0.194296\ttest-rmse:0.241908\n",
      "[1130]\ttrain-rmse:0.193944\ttest-rmse:0.241876\n",
      "[1140]\ttrain-rmse:0.193627\ttest-rmse:0.241866\n",
      "[1150]\ttrain-rmse:0.193192\ttest-rmse:0.241824\n",
      "[1160]\ttrain-rmse:0.192791\ttest-rmse:0.241765\n",
      "[1170]\ttrain-rmse:0.192392\ttest-rmse:0.24177\n",
      "[1180]\ttrain-rmse:0.192046\ttest-rmse:0.241788\n",
      "[1190]\ttrain-rmse:0.19164\ttest-rmse:0.241733\n",
      "[1200]\ttrain-rmse:0.19121\ttest-rmse:0.24177\n",
      "[1210]\ttrain-rmse:0.190831\ttest-rmse:0.241776\n",
      "[1220]\ttrain-rmse:0.190466\ttest-rmse:0.241733\n",
      "[1230]\ttrain-rmse:0.190158\ttest-rmse:0.241718\n",
      "[1240]\ttrain-rmse:0.189785\ttest-rmse:0.241694\n",
      "[1250]\ttrain-rmse:0.189386\ttest-rmse:0.241653\n",
      "[1260]\ttrain-rmse:0.189065\ttest-rmse:0.241622\n",
      "[1270]\ttrain-rmse:0.188707\ttest-rmse:0.2416\n",
      "[1280]\ttrain-rmse:0.188393\ttest-rmse:0.241598\n",
      "[1290]\ttrain-rmse:0.188062\ttest-rmse:0.241624\n",
      "[1300]\ttrain-rmse:0.187737\ttest-rmse:0.241574\n",
      "[1310]\ttrain-rmse:0.187374\ttest-rmse:0.241539\n",
      "[1320]\ttrain-rmse:0.187057\ttest-rmse:0.241524\n",
      "[1330]\ttrain-rmse:0.18679\ttest-rmse:0.241496\n",
      "[1340]\ttrain-rmse:0.186368\ttest-rmse:0.241454\n",
      "[1350]\ttrain-rmse:0.18603\ttest-rmse:0.241418\n",
      "[1360]\ttrain-rmse:0.185676\ttest-rmse:0.241396\n",
      "[1370]\ttrain-rmse:0.185279\ttest-rmse:0.241362\n",
      "[1380]\ttrain-rmse:0.184928\ttest-rmse:0.241337\n",
      "[1390]\ttrain-rmse:0.184553\ttest-rmse:0.241352\n",
      "[1400]\ttrain-rmse:0.184219\ttest-rmse:0.241357\n",
      "[1410]\ttrain-rmse:0.183919\ttest-rmse:0.241342\n",
      "[1420]\ttrain-rmse:0.183587\ttest-rmse:0.241329\n",
      "[1430]\ttrain-rmse:0.183225\ttest-rmse:0.241306\n",
      "[1440]\ttrain-rmse:0.182893\ttest-rmse:0.241321\n",
      "[1450]\ttrain-rmse:0.182505\ttest-rmse:0.2413\n",
      "[1460]\ttrain-rmse:0.182212\ttest-rmse:0.241312\n",
      "[1470]\ttrain-rmse:0.181832\ttest-rmse:0.241267\n",
      "[1480]\ttrain-rmse:0.18149\ttest-rmse:0.241237\n",
      "[1490]\ttrain-rmse:0.181233\ttest-rmse:0.241228\n",
      "[1500]\ttrain-rmse:0.18091\ttest-rmse:0.24121\n",
      "[1510]\ttrain-rmse:0.180588\ttest-rmse:0.241214\n",
      "[1520]\ttrain-rmse:0.180233\ttest-rmse:0.241176\n",
      "[1530]\ttrain-rmse:0.179908\ttest-rmse:0.241156\n",
      "[1540]\ttrain-rmse:0.179541\ttest-rmse:0.24117\n",
      "[1550]\ttrain-rmse:0.179161\ttest-rmse:0.241143\n",
      "[1560]\ttrain-rmse:0.178862\ttest-rmse:0.241137\n",
      "[1570]\ttrain-rmse:0.178551\ttest-rmse:0.241136\n",
      "[1580]\ttrain-rmse:0.178269\ttest-rmse:0.241126\n",
      "[1590]\ttrain-rmse:0.177993\ttest-rmse:0.241145\n",
      "[1600]\ttrain-rmse:0.177657\ttest-rmse:0.241112\n",
      "[1610]\ttrain-rmse:0.177379\ttest-rmse:0.241116\n",
      "[1620]\ttrain-rmse:0.177043\ttest-rmse:0.241133\n",
      "[1630]\ttrain-rmse:0.176786\ttest-rmse:0.241105\n",
      "[1640]\ttrain-rmse:0.1765\ttest-rmse:0.241098\n",
      "[1650]\ttrain-rmse:0.176154\ttest-rmse:0.241119\n",
      "[1660]\ttrain-rmse:0.175793\ttest-rmse:0.241134\n",
      "[1670]\ttrain-rmse:0.175467\ttest-rmse:0.241099\n",
      "[1680]\ttrain-rmse:0.175183\ttest-rmse:0.241113\n",
      "Stopping. Best iteration:\n",
      "[1634]\ttrain-rmse:0.176661\ttest-rmse:0.241082\n",
      "\n",
      "[0.236917, 0.237903, 0.241082]\n",
      "[0]\ttrain-rmse:0.334174\ttest-rmse:0.334305\n",
      "Multiple eval metrics have been passed: 'test-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until test-rmse hasn't improved in 50 rounds.\n",
      "[10]\ttrain-rmse:0.313902\ttest-rmse:0.314999\n",
      "[20]\ttrain-rmse:0.297838\ttest-rmse:0.299845\n",
      "[30]\ttrain-rmse:0.285369\ttest-rmse:0.288216\n",
      "[40]\ttrain-rmse:0.275706\ttest-rmse:0.279376\n",
      "[50]\ttrain-rmse:0.268343\ttest-rmse:0.272814\n",
      "[60]\ttrain-rmse:0.262616\ttest-rmse:0.267786\n",
      "[70]\ttrain-rmse:0.258222\ttest-rmse:0.264003\n",
      "[80]\ttrain-rmse:0.254555\ttest-rmse:0.260993\n",
      "[90]\ttrain-rmse:0.251595\ttest-rmse:0.258638\n",
      "[100]\ttrain-rmse:0.249068\ttest-rmse:0.256712\n",
      "[110]\ttrain-rmse:0.246978\ttest-rmse:0.255114\n",
      "[120]\ttrain-rmse:0.245168\ttest-rmse:0.253812\n",
      "[130]\ttrain-rmse:0.243527\ttest-rmse:0.252706\n",
      "[140]\ttrain-rmse:0.242164\ttest-rmse:0.251822\n",
      "[150]\ttrain-rmse:0.240996\ttest-rmse:0.251039\n",
      "[160]\ttrain-rmse:0.239942\ttest-rmse:0.250292\n",
      "[170]\ttrain-rmse:0.239006\ttest-rmse:0.249678\n",
      "[180]\ttrain-rmse:0.238119\ttest-rmse:0.249212\n",
      "[190]\ttrain-rmse:0.237242\ttest-rmse:0.248755\n",
      "[200]\ttrain-rmse:0.236347\ttest-rmse:0.24827\n",
      "[210]\ttrain-rmse:0.235594\ttest-rmse:0.247819\n",
      "[220]\ttrain-rmse:0.234902\ttest-rmse:0.247456\n",
      "[230]\ttrain-rmse:0.234307\ttest-rmse:0.247152\n",
      "[240]\ttrain-rmse:0.233557\ttest-rmse:0.246856\n",
      "[250]\ttrain-rmse:0.232824\ttest-rmse:0.246559\n",
      "[260]\ttrain-rmse:0.232262\ttest-rmse:0.246333\n",
      "[270]\ttrain-rmse:0.231668\ttest-rmse:0.246006\n",
      "[280]\ttrain-rmse:0.231081\ttest-rmse:0.245759\n",
      "[290]\ttrain-rmse:0.2306\ttest-rmse:0.245521\n",
      "[300]\ttrain-rmse:0.230032\ttest-rmse:0.245287\n",
      "[310]\ttrain-rmse:0.229422\ttest-rmse:0.245049\n",
      "[320]\ttrain-rmse:0.228894\ttest-rmse:0.244844\n",
      "[330]\ttrain-rmse:0.22844\ttest-rmse:0.244667\n",
      "[340]\ttrain-rmse:0.227889\ttest-rmse:0.244482\n",
      "[350]\ttrain-rmse:0.227376\ttest-rmse:0.244292\n",
      "[360]\ttrain-rmse:0.226825\ttest-rmse:0.244127\n",
      "[370]\ttrain-rmse:0.226391\ttest-rmse:0.243948\n",
      "[380]\ttrain-rmse:0.225768\ttest-rmse:0.243798\n",
      "[390]\ttrain-rmse:0.225398\ttest-rmse:0.243696\n",
      "[400]\ttrain-rmse:0.224841\ttest-rmse:0.243533\n",
      "[410]\ttrain-rmse:0.224471\ttest-rmse:0.243421\n",
      "[420]\ttrain-rmse:0.224018\ttest-rmse:0.243319\n",
      "[430]\ttrain-rmse:0.223474\ttest-rmse:0.243177\n",
      "[440]\ttrain-rmse:0.223017\ttest-rmse:0.243064\n",
      "[450]\ttrain-rmse:0.22253\ttest-rmse:0.242972\n",
      "[460]\ttrain-rmse:0.222012\ttest-rmse:0.242831\n",
      "[470]\ttrain-rmse:0.221533\ttest-rmse:0.242677\n",
      "[480]\ttrain-rmse:0.221113\ttest-rmse:0.242612\n",
      "[490]\ttrain-rmse:0.220716\ttest-rmse:0.242517\n",
      "[500]\ttrain-rmse:0.220324\ttest-rmse:0.242452\n",
      "[510]\ttrain-rmse:0.219827\ttest-rmse:0.242355\n",
      "[520]\ttrain-rmse:0.21942\ttest-rmse:0.242287\n",
      "[530]\ttrain-rmse:0.218875\ttest-rmse:0.242201\n",
      "[540]\ttrain-rmse:0.218416\ttest-rmse:0.242125\n",
      "[550]\ttrain-rmse:0.217923\ttest-rmse:0.242036\n",
      "[560]\ttrain-rmse:0.217414\ttest-rmse:0.241983\n",
      "[570]\ttrain-rmse:0.216867\ttest-rmse:0.241931\n",
      "[580]\ttrain-rmse:0.216476\ttest-rmse:0.241865\n",
      "[590]\ttrain-rmse:0.216038\ttest-rmse:0.241803\n",
      "[600]\ttrain-rmse:0.215578\ttest-rmse:0.241758\n",
      "[610]\ttrain-rmse:0.215206\ttest-rmse:0.241702\n",
      "[620]\ttrain-rmse:0.214775\ttest-rmse:0.241616\n",
      "[630]\ttrain-rmse:0.214351\ttest-rmse:0.241543\n",
      "[640]\ttrain-rmse:0.2139\ttest-rmse:0.24149\n",
      "[650]\ttrain-rmse:0.213579\ttest-rmse:0.241466\n",
      "[660]\ttrain-rmse:0.213067\ttest-rmse:0.241467\n",
      "[670]\ttrain-rmse:0.212669\ttest-rmse:0.241413\n",
      "[680]\ttrain-rmse:0.212174\ttest-rmse:0.241265\n",
      "[690]\ttrain-rmse:0.211663\ttest-rmse:0.241275\n",
      "[700]\ttrain-rmse:0.211179\ttest-rmse:0.241217\n",
      "[710]\ttrain-rmse:0.210764\ttest-rmse:0.241172\n",
      "[720]\ttrain-rmse:0.210291\ttest-rmse:0.241142\n",
      "[730]\ttrain-rmse:0.209852\ttest-rmse:0.241112\n",
      "[740]\ttrain-rmse:0.209428\ttest-rmse:0.241095\n",
      "[750]\ttrain-rmse:0.209036\ttest-rmse:0.241017\n",
      "[760]\ttrain-rmse:0.20858\ttest-rmse:0.240993\n",
      "[770]\ttrain-rmse:0.208189\ttest-rmse:0.240951\n",
      "[780]\ttrain-rmse:0.2078\ttest-rmse:0.240903\n",
      "[790]\ttrain-rmse:0.207366\ttest-rmse:0.240872\n",
      "[800]\ttrain-rmse:0.207039\ttest-rmse:0.240834\n",
      "[810]\ttrain-rmse:0.206656\ttest-rmse:0.240816\n",
      "[820]\ttrain-rmse:0.206255\ttest-rmse:0.240817\n",
      "[830]\ttrain-rmse:0.205857\ttest-rmse:0.240778\n",
      "[840]\ttrain-rmse:0.205482\ttest-rmse:0.240743\n",
      "[850]\ttrain-rmse:0.20514\ttest-rmse:0.240729\n",
      "[860]\ttrain-rmse:0.204796\ttest-rmse:0.240706\n",
      "[870]\ttrain-rmse:0.204356\ttest-rmse:0.240709\n",
      "[880]\ttrain-rmse:0.203959\ttest-rmse:0.240673\n",
      "[890]\ttrain-rmse:0.203482\ttest-rmse:0.240639\n",
      "[900]\ttrain-rmse:0.203066\ttest-rmse:0.240621\n",
      "[910]\ttrain-rmse:0.202656\ttest-rmse:0.240581\n",
      "[920]\ttrain-rmse:0.202166\ttest-rmse:0.240553\n",
      "[930]\ttrain-rmse:0.201792\ttest-rmse:0.240506\n",
      "[940]\ttrain-rmse:0.201464\ttest-rmse:0.240487\n",
      "[950]\ttrain-rmse:0.201108\ttest-rmse:0.240461\n",
      "[960]\ttrain-rmse:0.200743\ttest-rmse:0.240433\n",
      "[970]\ttrain-rmse:0.200381\ttest-rmse:0.240391\n",
      "[980]\ttrain-rmse:0.200037\ttest-rmse:0.240374\n",
      "[990]\ttrain-rmse:0.199645\ttest-rmse:0.240369\n",
      "[1000]\ttrain-rmse:0.199288\ttest-rmse:0.24033\n",
      "[1010]\ttrain-rmse:0.19893\ttest-rmse:0.240291\n",
      "[1020]\ttrain-rmse:0.198615\ttest-rmse:0.240279\n",
      "[1030]\ttrain-rmse:0.198251\ttest-rmse:0.240254\n",
      "[1040]\ttrain-rmse:0.197927\ttest-rmse:0.240234\n",
      "[1050]\ttrain-rmse:0.197566\ttest-rmse:0.24021\n",
      "[1060]\ttrain-rmse:0.197217\ttest-rmse:0.24016\n",
      "[1070]\ttrain-rmse:0.196809\ttest-rmse:0.240144\n",
      "[1080]\ttrain-rmse:0.196438\ttest-rmse:0.240119\n",
      "[1090]\ttrain-rmse:0.196058\ttest-rmse:0.240054\n",
      "[1100]\ttrain-rmse:0.195762\ttest-rmse:0.240034\n",
      "[1110]\ttrain-rmse:0.195379\ttest-rmse:0.240017\n",
      "[1120]\ttrain-rmse:0.19498\ttest-rmse:0.240014\n",
      "[1130]\ttrain-rmse:0.194639\ttest-rmse:0.240022\n",
      "[1140]\ttrain-rmse:0.194256\ttest-rmse:0.240022\n",
      "[1150]\ttrain-rmse:0.193868\ttest-rmse:0.240008\n",
      "[1160]\ttrain-rmse:0.193475\ttest-rmse:0.240016\n",
      "[1170]\ttrain-rmse:0.193095\ttest-rmse:0.239977\n",
      "[1180]\ttrain-rmse:0.19279\ttest-rmse:0.239969\n",
      "[1190]\ttrain-rmse:0.192485\ttest-rmse:0.239953\n",
      "[1200]\ttrain-rmse:0.192193\ttest-rmse:0.239942\n",
      "[1210]\ttrain-rmse:0.191774\ttest-rmse:0.239935\n",
      "[1220]\ttrain-rmse:0.191359\ttest-rmse:0.239914\n",
      "[1230]\ttrain-rmse:0.19103\ttest-rmse:0.239913\n",
      "[1240]\ttrain-rmse:0.19062\ttest-rmse:0.239908\n",
      "[1250]\ttrain-rmse:0.190279\ttest-rmse:0.239885\n",
      "[1260]\ttrain-rmse:0.189997\ttest-rmse:0.239871\n",
      "[1270]\ttrain-rmse:0.18961\ttest-rmse:0.239834\n",
      "[1280]\ttrain-rmse:0.189285\ttest-rmse:0.239792\n",
      "[1290]\ttrain-rmse:0.188924\ttest-rmse:0.239737\n",
      "[1300]\ttrain-rmse:0.188549\ttest-rmse:0.239731\n",
      "[1310]\ttrain-rmse:0.188163\ttest-rmse:0.239776\n",
      "[1320]\ttrain-rmse:0.187886\ttest-rmse:0.239746\n",
      "[1330]\ttrain-rmse:0.187599\ttest-rmse:0.239774\n",
      "[1340]\ttrain-rmse:0.187323\ttest-rmse:0.239768\n",
      "Stopping. Best iteration:\n",
      "[1298]\ttrain-rmse:0.188641\ttest-rmse:0.239728\n",
      "\n",
      "[0.236917, 0.237903, 0.241082, 0.239728]\n",
      "[0]\ttrain-rmse:0.334197\ttest-rmse:0.334181\n",
      "Multiple eval metrics have been passed: 'test-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until test-rmse hasn't improved in 50 rounds.\n",
      "[10]\ttrain-rmse:0.3137\ttest-rmse:0.314467\n",
      "[20]\ttrain-rmse:0.297592\ttest-rmse:0.298971\n",
      "[30]\ttrain-rmse:0.285156\ttest-rmse:0.287158\n",
      "[40]\ttrain-rmse:0.275657\ttest-rmse:0.278319\n",
      "[50]\ttrain-rmse:0.268419\ttest-rmse:0.271616\n",
      "[60]\ttrain-rmse:0.26263\ttest-rmse:0.26647\n",
      "[70]\ttrain-rmse:0.258137\ttest-rmse:0.26244\n",
      "[80]\ttrain-rmse:0.254595\ttest-rmse:0.259391\n",
      "[90]\ttrain-rmse:0.251762\ttest-rmse:0.257018\n",
      "[100]\ttrain-rmse:0.249368\ttest-rmse:0.255084\n",
      "[110]\ttrain-rmse:0.247438\ttest-rmse:0.253542\n",
      "[120]\ttrain-rmse:0.245655\ttest-rmse:0.252226\n",
      "[130]\ttrain-rmse:0.244135\ttest-rmse:0.251043\n",
      "[140]\ttrain-rmse:0.242673\ttest-rmse:0.250014\n",
      "[150]\ttrain-rmse:0.24139\ttest-rmse:0.249142\n",
      "[160]\ttrain-rmse:0.240305\ttest-rmse:0.248431\n",
      "[170]\ttrain-rmse:0.239308\ttest-rmse:0.247741\n",
      "[180]\ttrain-rmse:0.238378\ttest-rmse:0.247156\n",
      "[190]\ttrain-rmse:0.237493\ttest-rmse:0.246591\n",
      "[200]\ttrain-rmse:0.236548\ttest-rmse:0.246042\n",
      "[210]\ttrain-rmse:0.235829\ttest-rmse:0.245645\n",
      "[220]\ttrain-rmse:0.23509\ttest-rmse:0.245283\n",
      "[230]\ttrain-rmse:0.234344\ttest-rmse:0.244922\n",
      "[240]\ttrain-rmse:0.233581\ttest-rmse:0.244592\n",
      "[250]\ttrain-rmse:0.232959\ttest-rmse:0.244311\n",
      "[260]\ttrain-rmse:0.232375\ttest-rmse:0.244017\n",
      "[270]\ttrain-rmse:0.23181\ttest-rmse:0.243784\n",
      "[280]\ttrain-rmse:0.231231\ttest-rmse:0.243544\n",
      "[290]\ttrain-rmse:0.230676\ttest-rmse:0.24338\n",
      "[300]\ttrain-rmse:0.230062\ttest-rmse:0.243159\n",
      "[310]\ttrain-rmse:0.229459\ttest-rmse:0.242955\n",
      "[320]\ttrain-rmse:0.228974\ttest-rmse:0.242775\n",
      "[330]\ttrain-rmse:0.228381\ttest-rmse:0.242591\n",
      "[340]\ttrain-rmse:0.227911\ttest-rmse:0.242392\n",
      "[350]\ttrain-rmse:0.227316\ttest-rmse:0.242238\n",
      "[360]\ttrain-rmse:0.226753\ttest-rmse:0.242105\n",
      "[370]\ttrain-rmse:0.226295\ttest-rmse:0.241969\n",
      "[380]\ttrain-rmse:0.225747\ttest-rmse:0.241822\n",
      "[390]\ttrain-rmse:0.225242\ttest-rmse:0.241719\n",
      "[400]\ttrain-rmse:0.224791\ttest-rmse:0.241594\n",
      "[410]\ttrain-rmse:0.224242\ttest-rmse:0.241473\n",
      "[420]\ttrain-rmse:0.223807\ttest-rmse:0.241395\n",
      "[430]\ttrain-rmse:0.223354\ttest-rmse:0.241284\n",
      "[440]\ttrain-rmse:0.222918\ttest-rmse:0.241178\n",
      "[450]\ttrain-rmse:0.222414\ttest-rmse:0.24107\n",
      "[460]\ttrain-rmse:0.221997\ttest-rmse:0.241002\n",
      "[470]\ttrain-rmse:0.221497\ttest-rmse:0.240912\n",
      "[480]\ttrain-rmse:0.221012\ttest-rmse:0.240851\n",
      "[490]\ttrain-rmse:0.220556\ttest-rmse:0.240751\n",
      "[500]\ttrain-rmse:0.220106\ttest-rmse:0.240689\n",
      "[510]\ttrain-rmse:0.219683\ttest-rmse:0.240635\n",
      "[520]\ttrain-rmse:0.219229\ttest-rmse:0.24057\n",
      "[530]\ttrain-rmse:0.218733\ttest-rmse:0.240506\n",
      "[540]\ttrain-rmse:0.218241\ttest-rmse:0.240432\n",
      "[550]\ttrain-rmse:0.217806\ttest-rmse:0.240351\n",
      "[560]\ttrain-rmse:0.217408\ttest-rmse:0.24029\n",
      "[570]\ttrain-rmse:0.216963\ttest-rmse:0.240221\n",
      "[580]\ttrain-rmse:0.21651\ttest-rmse:0.240186\n",
      "[590]\ttrain-rmse:0.21615\ttest-rmse:0.24016\n",
      "[600]\ttrain-rmse:0.215748\ttest-rmse:0.240121\n",
      "[610]\ttrain-rmse:0.215208\ttest-rmse:0.240063\n",
      "[620]\ttrain-rmse:0.214673\ttest-rmse:0.240027\n",
      "[630]\ttrain-rmse:0.214264\ttest-rmse:0.239981\n",
      "[640]\ttrain-rmse:0.213741\ttest-rmse:0.239942\n",
      "[650]\ttrain-rmse:0.213372\ttest-rmse:0.239886\n",
      "[660]\ttrain-rmse:0.213027\ttest-rmse:0.239803\n",
      "[670]\ttrain-rmse:0.212634\ttest-rmse:0.239775\n",
      "[680]\ttrain-rmse:0.212186\ttest-rmse:0.239767\n",
      "[690]\ttrain-rmse:0.211781\ttest-rmse:0.239745\n",
      "[700]\ttrain-rmse:0.211437\ttest-rmse:0.239699\n",
      "[710]\ttrain-rmse:0.210975\ttest-rmse:0.239706\n",
      "[720]\ttrain-rmse:0.210567\ttest-rmse:0.239662\n",
      "[730]\ttrain-rmse:0.210079\ttest-rmse:0.239633\n",
      "[740]\ttrain-rmse:0.209702\ttest-rmse:0.239581\n",
      "[750]\ttrain-rmse:0.209276\ttest-rmse:0.239538\n",
      "[760]\ttrain-rmse:0.208815\ttest-rmse:0.23951\n",
      "[770]\ttrain-rmse:0.208346\ttest-rmse:0.239458\n",
      "[780]\ttrain-rmse:0.207914\ttest-rmse:0.239385\n",
      "[790]\ttrain-rmse:0.207545\ttest-rmse:0.239335\n",
      "[800]\ttrain-rmse:0.207089\ttest-rmse:0.23929\n",
      "[810]\ttrain-rmse:0.206759\ttest-rmse:0.239285\n",
      "[820]\ttrain-rmse:0.206338\ttest-rmse:0.239255\n",
      "[830]\ttrain-rmse:0.205965\ttest-rmse:0.23924\n",
      "[840]\ttrain-rmse:0.20559\ttest-rmse:0.239258\n",
      "[850]\ttrain-rmse:0.205231\ttest-rmse:0.239197\n",
      "[860]\ttrain-rmse:0.204899\ttest-rmse:0.23919\n",
      "[870]\ttrain-rmse:0.20447\ttest-rmse:0.239143\n",
      "[880]\ttrain-rmse:0.204032\ttest-rmse:0.23909\n",
      "[890]\ttrain-rmse:0.20376\ttest-rmse:0.239065\n",
      "[900]\ttrain-rmse:0.203338\ttest-rmse:0.239047\n",
      "[910]\ttrain-rmse:0.202984\ttest-rmse:0.239055\n",
      "[920]\ttrain-rmse:0.202576\ttest-rmse:0.239037\n",
      "[930]\ttrain-rmse:0.202185\ttest-rmse:0.239028\n",
      "[940]\ttrain-rmse:0.201783\ttest-rmse:0.239015\n",
      "[950]\ttrain-rmse:0.201425\ttest-rmse:0.239005\n",
      "[960]\ttrain-rmse:0.201072\ttest-rmse:0.238987\n",
      "[970]\ttrain-rmse:0.200657\ttest-rmse:0.238969\n",
      "[980]\ttrain-rmse:0.200298\ttest-rmse:0.238942\n",
      "[990]\ttrain-rmse:0.199908\ttest-rmse:0.23894\n",
      "[1000]\ttrain-rmse:0.199505\ttest-rmse:0.23895\n",
      "[1010]\ttrain-rmse:0.199153\ttest-rmse:0.238943\n",
      "[1020]\ttrain-rmse:0.198767\ttest-rmse:0.238928\n",
      "[1030]\ttrain-rmse:0.198393\ttest-rmse:0.23894\n",
      "[1040]\ttrain-rmse:0.198007\ttest-rmse:0.238934\n",
      "[1050]\ttrain-rmse:0.197561\ttest-rmse:0.238905\n",
      "[1060]\ttrain-rmse:0.197231\ttest-rmse:0.238898\n",
      "[1070]\ttrain-rmse:0.196874\ttest-rmse:0.238874\n",
      "[1080]\ttrain-rmse:0.196534\ttest-rmse:0.238869\n",
      "[1090]\ttrain-rmse:0.196143\ttest-rmse:0.238838\n",
      "[1100]\ttrain-rmse:0.195784\ttest-rmse:0.23884\n",
      "[1110]\ttrain-rmse:0.195372\ttest-rmse:0.238827\n",
      "[1120]\ttrain-rmse:0.194991\ttest-rmse:0.238753\n",
      "[1130]\ttrain-rmse:0.194687\ttest-rmse:0.238748\n",
      "[1140]\ttrain-rmse:0.194261\ttest-rmse:0.238753\n",
      "[1150]\ttrain-rmse:0.193865\ttest-rmse:0.238758\n",
      "[1160]\ttrain-rmse:0.193477\ttest-rmse:0.238746\n",
      "[1170]\ttrain-rmse:0.193084\ttest-rmse:0.23872\n",
      "[1180]\ttrain-rmse:0.19266\ttest-rmse:0.23868\n",
      "[1190]\ttrain-rmse:0.192264\ttest-rmse:0.238703\n",
      "[1200]\ttrain-rmse:0.19194\ttest-rmse:0.238671\n",
      "[1210]\ttrain-rmse:0.191586\ttest-rmse:0.238638\n",
      "[1220]\ttrain-rmse:0.191276\ttest-rmse:0.238613\n",
      "[1230]\ttrain-rmse:0.190867\ttest-rmse:0.238626\n",
      "[1240]\ttrain-rmse:0.190535\ttest-rmse:0.23862\n",
      "[1250]\ttrain-rmse:0.190215\ttest-rmse:0.238623\n",
      "[1260]\ttrain-rmse:0.189808\ttest-rmse:0.238614\n",
      "[1270]\ttrain-rmse:0.189531\ttest-rmse:0.238644\n",
      "Stopping. Best iteration:\n",
      "[1222]\ttrain-rmse:0.19118\ttest-rmse:0.23859\n",
      "\n",
      "[0.236917, 0.237903, 0.241082, 0.239728, 0.23859]\n",
      "0.238848\n"
     ]
    }
   ],
   "source": [
    "rv1 = run_cv1(train_df, cv_test, kf, fl) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfs1 = run_to_stackdf(rv1)\n",
    "pickle.dump(dfs1, open('modeloutput-xgb-reg-r2.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "_change_revision": 410,
  "_is_fork": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
